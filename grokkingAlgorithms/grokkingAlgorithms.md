Прочитаем книгу Грокаем алгоритмы и сделаем для себя выводы. 

Алгоритмом называется набор инструкций для выполнения некоторой задачи. 
Алгоритмы - это во многом про эффективность.

Первая тема, с которой автор книги предлагает познакомиться - Бинарный поиск. 

Предположим, мы ищем фамилию человека в телефонной книге. Фамилия начинается на К.
Конечно, можно поступить самым очевидным способом, говорит автор, и начать листать телефонную книгу с самого начала. Но тут же предлагает второй способ - раскрыть книгу на середине. Такое решение скорее всего продиктовано такой логикой: если буква К в середине алфавита, а телефонная книга содержит имена в алфавитном порядке - то можно провести параллель между этими двумя сущностями и экстраполировать наше знание о положении буквы К в алфавите на ее предполагаемое положение в телефонной книге: в середине в алфавите - в середине в телефонной книге. И аналогичные примеры, например поиск никнейма в базе данных социальной сети - тот же принцип. 

Такого рода задачи названы автором Типичной задачей поиска. На примере таких задач нам предлагают познакомиться с алгоритмом, который может быть использован для их решения: Бинарный поиск. 

Бинарный поиск - это алгоритм. На входе он получает __ОТСОРТИРОВАННЫЙ__ список элементов. На данном этапе автор не объясняет, почему он должен быть отсортирован, но я предположу, что дело как раз в том, чтобы можно было соотносить список элементов с некой последовательностью (так, если телефонная книга отсортирована по алфавиту, то на нее можно проецировать некоторые свойства алфавита - в частности расположение конкретных букв относительно общего объема алфавита - а значит и телефонной книги)
Принцип Бинарного поиска заключается в том, что если элемент, который мы ищем, найден - в качестве ответа нам должен вернуться _порядковый номер_, _позицию_ данного элемента в предоставленном для поиска отсортированном списке. А значит каждый элемент списка должен обладать информацией о своем местоположении в списке, чтобы ее вернуть. Если элемент не найден - то алгоритм бинарного поиска возвращает __null__ (ну или -1). Таким образом эти условия уже помогают познакомиться со стандартами: если мы реализуем бинарный поиск, значит должны организовать код так, чтобы в случае успеха возвращался тип данных, содержащих позицию элемента в списке, а не булевое значение или строка типа _"Успех!"_. И также вводится стандарт для ответа в случае, если элемент не найден.
Для примера приводится поиск загаданного числа от 1 до 100. Список таких чисел - уже __упорядоченный__ список, где каждый элемент самим своим значением содержит информацию о своем __положении__ в этом списке. Тоесть подходит для условий Бинарного поиска. Далее автор рассматривает концепцию Простого поиска - тоесть перебора значений по порядку, пока не будет достигнуто загаданное число. Этот подход, в теории, для данного списка, может содержать число проверок, равных длинне списка - например, если загадано 99. 
В качестве альтернативы автор предлагает Бинарный поиск - начинать поиск с середины списка - и ждать ответа. Загадавший может дать ответ 3 типов: Меньше, Больше и Попал. Не совсем то, что мы встретим в реальном поиске на ПК, но для модели сойдет. Итак, начав с середины, и даже не получив ответ Попал, а получив Больше или Меньше, мы добьемся невероятного результата - а именно сократим наш изначальный список в 2 раза! По сравнению с простым поиском это невероятный прогресс! Всего первый шаг, а мы уже сократили исходный список в 2 раза! А значит стоит придерживаться означенной логики далее: понимая, какая половина списка осталась, мы вновь выбираем _среднее_ значение, чтобы получив ответ сократить новый список опять вдвое. Или на 75% от исходного! Всего за 2 вопроса, за 2 итерации - мы сократили исходный список на три четверти! А это значит, что даже если бы мы вдруг прибегли теперь к простому поиску, он теоретически будет быстрее на 75%. Но нам нет нужды - мы вновь продолжим пользоваться Бинарным поиском. Это напоминает мне складывание листа бумаги пополам - каждый раз размер уменьшается вдвое. А так как любой список конечен, сколь бы велик не был исходный список - потребуется _небольшой_ (относительно его размера) набор шагов, а главное - _конечный_ набор шагов - чтобы в любом случае достичь искомого элемента списка. 

Далее автор декларирует: для поиска элемента в списке из 100 позиций потребуется не более 7 шагов Бинарного поиска. И уже сдесь мы можем попытаться предположить, что существует логика, по которой мы можем рассчитать: сколько шагов нужно, чтобы провести однозначно успешный поиск для списка конкретной длинны. Тоесть - зная длинну списка мы можем сказать, сколько максимум шагов Бинарного поиска потребуется, чтобы получить результат. 

Для списка из 240 000 элементов потребуется 18 шагов. 

В итоге для списка из n элементов потребуется $log_2n$ шагов, тогда как простой поиск будет выполнен за $n$ шагов. 

Логарифм - операция, обратная возведению в степень. Тоесть, если мы говорим о логарифме по основанию (число $а$) от числа $б$, то мы задаем вопрос: в какую степень мы должны возвести число $а$, чтобы получить число $б$. 
Это значит, что когда мы говорим о списке элементов определенной длинны $а$, и хотим узнать, сколько шагов потребуется Бинарному поиску чтобы однозначно найти в нем ответ, мы должны ответить на вопрос: в какую степень нужно возвести число 2, чтобы получить число $а$. 

#### Время выполнения - еще один важный фактор. 
Так, если мы будем искать элемент в списке из 100 позиций последовательным перебором, это займет у нас до 100 итераций. Если в списке из 240 000 - столько же итераций. Говоря о времени выполнения алгоритма, мы в данном случае говорим, что оно линейно: сколько элементов в списке, столько же и итераций.

Когда мы говорим о Бинарном поиске, то можем явно заметить, что списку из 240 000 позиций потребуется всего 18 итераций - что несопоставимо меньше размера списка. 
Говорят, что бинарный поиск выполняется за _логарифмическое время_. 

Итак, для описания скорости работы любого алгоритма используют специальную нотацию под названием $O-большое$.
$O-большое$ позволяет провести оценку скорости работы алгоритма. 
Автор приводит интересный пример: если одна итерация поиска занимает у компьютера 1мс, то для списка из 100 элементов линейный поиск составит 100мс, а бинарный поиск составит 7мс - потому что нужно 7 итераций. 
Если взять список размером 10 000 элементов, то линейный поиск займет 10с, а бинарный поиск 14мс! Уже колоссальная разница. Но когда мы берем список из 1 000 000 000 элементов, то для линейного поиска это займет 11 дней, а для бинарного поиска - 30мс. 
Впринципе, если мы выразим линейный поиск в виде функции $y = x$, где $у$ - это число итераций, необходимых для проверки списка размером x элементов, то для бинарного поиска мы получим функцию \[ y = \log_2 x \]. 
Если бы нам захотелось составить графики этих функций, то мы бы увидели, что график логарифмической функции с увеличением x становится почти параллельным оси $Ox$, в то время как линейная функция всегда будет проходить под углом в 45 градусов.

Вот почему недостаточно знать, сколько времени займет выполнение алгоритма для данного конкретного случая. Важно понимать, как время выполнения меняется с ростом размера списка элементов. Для такого понимания $O-большое$ и нужно. 
$O-большое$ описывает то, насколько быстро работает алгоритм. Для линейного поиска из n элементов $O-большое$ будет иметь вид $О(n)$. Для Бинарного поиска это значение будет \[ O(\log_2 n)\]

$O-большое$ не может однозначно предсказать количество операций, которые придется выполнить для решения поставленной задачи. Но оно поможет понять общую эффективность алгоритма:
$O(n)$ - приемлемо, $O(\log_2 n)$ - очень хорошо, $O(n^2)$ - прям совсем плохо, неприемлемо уже при n = 20.

Нужно понимать, что $O-большое$ определяет количество итераций при _**наихудшем**_ сценарии - тоесть если нам совсем не повезет, и ни одна итерация не приведет к правильному ответу, кроме последней. 

```
Наряду с временем худшего случая 
полезно бывает учитывать и среднее время 
выполнения. Не всегда все наши алгоритмы 
будут выполняться по худшему сценарию
```

##### Типичные примеры $O-большого$:
- $O(\log n)$ - или _Логарифмическое время_ - Бинраный поиск
- $O(n)$ - или _Линейное время_ - Простой поиск
- $O(n * \log n)$ - эффективные алгоритмы сортировки, например - _Быстрая сортировка_
- $O(n^2)$ - медленные алгоритмы сортировки - _Сортировка выбором_
- $O(n!)$ - очень медленные алгоритмы - Задача о коммивояжере

Существуют и другие варианты времени выполнения, но эти встречаются чаще всего. 

#### Существенные итоги:
- Скорость алгоритмов измеряется не в секундах, а в темпе роста количества операций
- Время выполнения алгоритма выражается как $O-большое$

Далее автор дает ряд задач для самостоятельного решения, но отдельно хочется выделить последнюю: Найти $O-большое$ для операции прочтения всех номеров людей в телефонной книге, чья фамилия начинается на А. 
_Решение_: Тут есть небольшой подводный камень - наш алгоритм не знает, что телефонная книга начинается фамилиями на А. Поэтому первой нашей задачей станет найти самую первую фамилию на А в телефонной книге. Тоесть задача найти фамилию - а ее время выполнения выражается как $O(\log_2n)$. А далее нужно последовательно прочитать столько номеров, сколько людей с фамилией на А. Значит вермя выполнения $O(k)$ - не n, потому что n - число всех фамилий в книге. Ну а потом просто сложим эти два времени выполнения и получим $O(\log_2 n + k)$. Где собственно основное время занимает $O(k)$ - последовательное чтение всех фамилий на А.

### Задача о коммивояжере

Никому не хотелось бы столкнуться с самым лютым верменем выполнения алгоритма, выражающимся $O(n!)$.
Говорят: __n факториал__.
__Факториал__ - это произведение всех целых чисел от 1 до n. Главная его особенность - он невероятно быстро растет. График $y=x!$ почти с самого начала идет практически параллельно оси y. Задача посчитать $20!$ уже фактически неподъемна.
Сама задача коммивояжера состоит в том, что коммивояжер хочет объехать 5 городов по самому короткому маршруту между ними. Для этого ему надо _перебрать_ все варианты маршрутов, а значит $5! = 1*2*3*4*5 = 120$ перестановок, вариантов маршрутов. Для 6 городов потребуется уже 720 перестановок на карте, а для 7 городов 5040. Время выполнения такого алгоритма называется __факториальным__, выражается с помощью $O-большого$ как $O(n!)$. 
Так, если мы попытаемся решить задачу для 100 городов - сделать это не удастся - Солнце погаснет раньше. 

Коммивояжер мог бы попытаться найти другое решение - но у него ничего не получится. Это одна из знаменитых нерешенных задач в теории вычислений. Для нее не существует известного быстрого алгоритма. Более того, математики считают, что такой алгоритм врядли когда-нибудь будет найден. В лучшем случае для нее можно поискать приближенное решение. 

### 2. СОРТИРОВКА ВЫБОРОМ

* Эта глава познакомит нас с массивами и связанными списками - двумя структрурами данных, которые используются практически повсеместно.
* Глава научит первому алгоритму сортировки (_мы ведь помним, что многие алгоритмы работают только с отсортированными данными_). В большинстве языков существуют встроенные алгоритмы сортировки, но принцип понимать надо.

#### Как работает память

Память физически разделена на ячейки. Каждая ячейка может хранить фиксированный объем информации. Каждая ячейка имеет свой адрес, чтобы к ней можно было обратиться. 
Каждый раз, когда мы хотим сохранить в памяти отдельное значение, нам предоставляется ячейка. А когда мы хотим хранить несколько значений, нам может потербоваться _массив_ или _список_.

#### Массивы и Связанные списки

Иногда в памяти требуется сохранить список элементов. 
Предположим, мы пишем приложение для управления текущими делами. Описания задач должны храниться в виде списка в памяти.
При использовании __массива__ все задачи хранятся в памяти _непрерывно_, тоесть рядом друг с другом.
Предположим, мы захотим добавить новую задачу - но выделенное под наш массив место - _непрерывная область памяти_ - уже закончилось. Потому что за нашим массивом расположились другие данные. А значит придется запросить у компьютера блок непрерывной памяти, куда влезет наш новый список, и переместить его на новое место. И так всякий раз, когда добавляется новая задача. Если каждый раз придется переносить все возрастающий массив в новую, пока еще свободную непрерывную область памяти, то добавление новых элементов станет крайне медленной операцией.
Одно из решений - _**Бронирование места**_. Мы заранее просим выделять под наши массивы место с запасом, например не 3 ячейки а сразу 10. И тогда добавление новых элементов будет производиться в незанятую, зарезервированную для этого массива непрерывную область памяти. Но у данного подхода есть несколько вполне очевидных недостатков:
* Лишнее место может и не понадобиться - тогда память будет расходоваться неэффективно. Много свободного места, которым нельзя воспользоваться. 
* Если в массив будет добавлено более 10 задач - перемещать все равно придется.

##### Связанные списки

Элементы связанных списков не требуют непрерывной области памяти - они могут размещаться где угодно. 
Каждый элемент памяти выделяет немного свободного места для хранения у себя адреса следующего за ним элемента памяти. Таким образом, набор произвольных адресов памяти объединяется в _цепочку_. Со связанными списками ничего перемещать в памяти не нужно. Нет нужды так же выделять непрерывную область памяти - данные могуть занять свободные места везде, где они есть. 
Но у связанных списков есть одна объективная проблема: Допустим, мы хотим получить _последний_ элемент всего спска. Но получить его сразу не получится - мы не знаем, по какому адресу хранится последний элемент. Поэтому нап придется двигаться по всей цепочке от первого элемента ко второму и далее, пока мы не дойдем до последнего элемента. 
Отсюда выходит главная особенность связанных списков: __Связанные списки отлично подходят для ситуаций, когда данные должны читаться последоватьельно__. Сначала один элемент, потом следующий и так далее. 

Но если мы намерены прыгать по элементам туда-сюда - связанные списки нам не подходят. 

С __массивами__ дела обстоят иначе - работая с массивом мы сразу знаем адрес каждого элемента. 

Говоря про эти типы данных, мы конечно же будем иметь в виду базовые операции с ними: а именно чтение и добавление элементов. И нас будет интересовать время выполнения операции - $O-большое$. 

__Для массива__
_Чтение_ будет иметь $O-большое$ $O(1)$ для списка из n элементов: не важно, какой длинны массив. Чтобы обратиться к любому его элементу нужно выполнить операцию доступа по известному индексу - а значит фиксированное время, условная еденица, для любого элемента. 

_Вставка_. Для определения времени выполнения операции нам нужно взять самый, условно говоря, неблагоприятный случай. В случае массива это вставка элемента в начало списка, что вынужденно приведет к переиндексации всех остальных элементов на +1. Таким образом, при добавлении одного элемента в _начало_, нам приходится переиндексировать _каждый_ элемент массива, а значит $O-большое$ для операций добавления в массив для массива длинной n - элементов составит $O(n)$.

__Для связанного списка__
_Чтение_ составит $O(n)$ - потому что если мы захотим прочитать последний элемент, нам придется последовательно продвигаться по _каждому_ элементу связанного списка длинною n, чтобы добраться до последнего

_Вставка_ составит $O(1)$ - нам нет нужды ничего перезаписывать для каждого элемента связанного списка длинною n. Нам достаточно изменить адрес _следующего_ элемента в предыдущем элементе на адрес нового элемента, а новому элементу указать тот самый адрес, который мы изменяли. 

Для операции удаления, при прочих равных, значения $O-большое$ будут аналогичны таковому для операции вставки. 

Еще нам необходимо ввести термин __доступ__ к элементу
Всего существует 2 типа доступа: __*Последовательный*__ и __*Произвольный*__. Последовательный мы разобрали на примере _связанного списка_, а произвольный доступ видели у _массива_.

#### Какая структура данных используется чаще

В JS используются массивы, всегда. Они крайне хорошо оптимизированы, лишены многих критических недостатков по сравнению с другими языками программирования. А используя приемы Кучи: Последний пришел Первый ушел мы буквально сводим операции чтения и записи к $O(1)$. Но даже __дорогостоящие__ для классических массивов операции в JS реализованы лучше.

В остальном - многие задачи реального программирования требуют произвольного доступа, поэтому массивы используются очень часто. 

Однако, даже безотносительно произвольного доступа, массивы работают быстрее потому что используют __*кеширование*__. 

###### Кеширование

Почему некое кеширование делает массивы еще быстрее?

Тут мы немного отвлечемся на архитектуру ЭВМ.
Процессор работает __Очень быстро__. А вот данные для обработки он получает из памяти RAM. Получение данных из RAM по-сравнению со скоростью работы процессора можно назвать медленным. 
Чтобы несколько сгладить этот разрыв, существует встроенная в процессор очень быстрая память: __CPU cache__ - _кэш ЦПУ_. 
Этот кэш очень быстрый, но маленький по объему. 
Когда процессор собирается обработать какой-то элемент массива, он загружает не только сам этот элемент, но и несколько соседних - целый __cache line__ - обычно это 64 байта. Это такакя оптимизация - программисты знали, что с большой вероятностью, при работе с массивом, потребуется не только конкретный элемент но и близлежащие - поэтому и настроили такое поведение памяти при загрузке элемента массива. 

Вот тут и раскрывается в полной мере тот факт, что массивы хранятся в непрерывной области памяти: подгрузив некоторою область массива процессор очень быстро может обработать несколько элементов подряд. В случае же со связанными списками каждые элемент может находиться в отдельной области памяти, а значит для обработки каждого из них придется лезть в RAM. 

Еще одним преимуществом массивав может быть тот факт, что при прочих равных хранить данные в массиве экономичнее, даже не смотря на то, что массив резервирует под себя определенную область памяти и могут оставаться незанятые куски, недоступные для хранения других данных. Дело в том, что пока массив хранит последовательность элементов, каждый элемент связанного списка должен хранить в себе еще и ссылку на следующий элемент. А значит для хранение небольших элементов однозначно выгоднее в массиве. С другой стороны хранение очень тяжелых элементов в массиве может привести к тому, что моссив потеряет свои преимущества и объем неиспользуемой, но зарезервированной под него памяти будет _существенным_.

##### А что в JS?

А в JS в дело вступает талант разработчиков, прекрасно организовавших работу с _массивами_ даже в мелочах. 

Движки JavaScript и многие языки выделяют массиву блок памяти с запасом, чтобы избежать частого перераспределения при добавлении элементов.
Это действительно может приводить к неиспользуемым, но зарезервированным участкам.
Но, этот запас обычно __не огромный__ и растёт динамически (например, в V8 массив может удваивать выделенную память при нехватке). Даже с этим запасом массив часто всё равно компактнее, чем связанный список, если элементы мелкие.

Что касается __тяжелых элементов__, то тут есть нюанс:
В JS, если элемент — это _объект_, в массиве хранится не сам _объект_, а _ссылка_ на него.
Поэтому размер элемента в массиве всегда фиксирован (размер ссылки, например 8 байт), а не зависит от «тяжести» объекта.
Объекты сами хранятся в __куче__ (__heap__) отдельно, и массив лишь хранит на них _указатели-ссылки_.

То есть тяжёлые элементы не делают массив хуже с точки зрения памяти, если речь идёт о JS.
В языках вроде C++ или Java с массивами объектов внутри — там да, объект может храниться прямо в массиве, и тогда «тяжёлый» элемент может увеличить блок памяти.
Но в JS — нет.

Автор книги в упражнениях приводит очень интересную, гибридную структуру данных. Для примера он предлагает нам представить процесс, по которому социальная сеть работала бы со списком имен пользователей. В частности, если необходимо провести быстрый поиск имени по большому набору элементов, то нам было бы сподручнее воспользоваться бинарным поиском - а значит нужен упорядоченный массив. А вот если нужно быстро добавлять или удалять данные, то тут связанный список с его $O(1)$ выглядит очень привлекательно. Но когда надо делать все виды операций, причем быстро, то невозможно удовлетвориться какой-то одной структурой данных. И тут на помощь может придти _гибридная структура_: _В упрощенном виде_: Пусть массив хранит связанные списки имен на одну букув. Теперь когда мы ищем конкретное имя вначале выполняется бинарный поиск буквы в массиве, а это очень быстро. Переходя к работе со связанным списком имен на конкретную букву мы теряем скорость, но при этом наша скорость не $O(n)$, где n - количество всех имен вообще, а $O(k)$, где k - количество имен на конкретную букву. Условно, если в алфавите больше 20 букв и условно принять, что имена примерно одинаково распределены между всеми буквами, то k это порядка 5% от n, а 
значит мы ускорили поиск на 95%. Ну а операция добавления/удаления уже найденного элемента для связанного списка составляет $O(1)$, самый благоприятный вариант. А значит получаем: поиск в массиве из z букв + поиск в списке + добавление/удаление найденного элемента в списке = $O(\log z) + O(k) + O(1)$. Да, линейный поиск это не самых удачный вариант, а поэтому мы стремимся максимально сократить его, разбив исходный пакет данных на мини-подгруппы, которые хранятся в удобной для поиска структуре - упорядоченном списке. Таким образом, разделив структуру данных, мы разделили операции между удобной для каждой операции структурой. 

#### Coртировка выбором

Допустим, у нас на компьютере хранится музыка. Для каждого исполнителя ведется счетчик воспроизведений. 

| Исполнитель   | Счётчик |
| ------------- | ------- |
| The Doors     | 450     |
| Black Sabbath | 1500    |
| Юрий Антонов  | 600     |
| Газманов      | 0       |

Допустим, мы хотим отсортировать исполнителей по количеству прослушиваний так, чтобы самые любимые стояли на первых местах.

Для выполнения этой задачи попробуем представить себе следующий алгоритм действий:
* Пройдемся по списку в поисках исполнителя с самым большим количеством прослушиваний. Список еще не отсортирован, поэтому проверить необходимо каждый элемент списка, чтобы иметь возможность сравнивать прослушивания и найти самое большое число. После нахождения такового занесем этого исполнителя первым номером в новый список, который будет отражать результаты сортировки. В итоге, учитывая необходимость для обнаружения самого прослушиваемого исполнитьеля "просмотреть" __каждый__ элемент списка n, получаем время выполнения как $O(n)$
* Теперь нам нужно найти следующего по популярности исполнителя - тот же алгоритм действий, то же время выполнения $O(n)$. 
* Начинает складываться понимание - чтобы произвести сортировку (по заданному параметру) списка элементов длинною n, нам необходимо пройтись по __каждому__ элементу списка $O(n)$ такое число раз, которое точно равно количеству элементов в списке - n раз, а значит время выполнения $O(n)$. 

Получается, что для сортировки списка мы потратим
 \[O(n) * O(n) = O(n*n) = O(n^2)\]

Алгоритмы сортировки очень полезны. 
Они могут помочь отсортировать:
- Имена в телефонной книге
- Даты событий
- Сообщения электронной почты по дате
  
__Уменьшение количества проверяемых элементов__
Нельзя не заметить одну особенность приведенной выше последовательности действий: На каждом новом цикле поиска по элементам число тех элементов, по которым нужно проводить поиск уменьшается. Если мы уже прошли пару раз по списку, значит нашли первых двух наиболее часть прослушиваемых исполнителей, а значит их проверять уже не нужно при поиске третьего, а значит список неотсортированных элементов условно сократился на 2. Тоесть чем больше итераций поиска мы провели - тем меньше стал наш исходный список: сначала шла проверка по n-списку, потом по n-1 списку, n-2, n-3 и т.д. В итоге будет проверен список из $\frac{1}{2} n$ элементов. 
Но мы все равно указываем при оценке времени этого алгоритма $O(n^2)$, как-будто не учитываем вышеозначенную особенность и каждый раз проводим проверку по полному списку n-элементов, хотя на самом деле время выполнения можно оценить как:
\[
  O(n\times \frac{1}{2} \times n)
\]

Но коэфициенты наподобие $\frac{1}{2}$ при оценке $O-большое$ не учитываются.

Алгоритм __сортировки выбором__ работает _медленно_. 

##### Пример кода 

Для примера мы создадим логику, которая будет исследовать массив и сортировать его в порядке возрастания элементов - тоесть сначала ищем наименший элемент, потом следующий за ним и завершается сортировка нахождением наибольшего элемента.

Для начала мы создадим функцию, которая будет искать наименьший элемент в предоставленном массиве. 
Внутри этой функции объявляется 2 переменные. Первая, smallest, принимает в себя исследуемый элемент массива. 
Вторая, smallestIndex, хранит индекс этого элемента. Функция запускает цикл, который проходит последовательно по всем элементам массива. 


И тут возникает вопрос: в книге автор пользуется циклом for...in, что позволят ему перебирать элементы по показателю индекса, так как сам цикл перебирает индексы. Но в JS для массивов и вообще итерируемых объектов существует цикл for...of, который перебирает не индексы, а сами элементы. Этот цикл лучше оптимизирован для перебора итерируемых объектов, поэтому является правильным выбором для массивов. При попытке перебрать массив с помощью for...in мы будем работать с ним как с обычным JS объектом и потераяем главное преимущество массива - скорость. Отсюда вытекает и его ограничение - цикл не предоставляет доступа к индексу, только к самому элементу. Поэтому мы воспользуемся классическим циклом for, который будет перебирать элементы по индексам.

```js
// Напишем функцию для поиска НАИМЕНЬШЕГО
// элемента в предоставленном массиве
function findSmallest(arr) {
  // Ведем 2 переменные:
  // smallest - для наименьшего элемента
  // smallestIndex - для его индекса
  // по-умолчанию зададим значения переменных
  // как первый элемент исследуемого массива
  let smallest = arr[0];
  let smallestIndex = 0;
  // Пройдем циклом по всем элементам массива
  // начиная со второго, и будем сравнивать 
  // каждый элемент с тем, что хранится в 
  // переменной smallest
  for (let i = 1; i < arr.length; i++) {
    // если ислледуемый элемент меньше того,
    // что хранится в smallest, то перезапишем
    // smallest новым, наименьшим значением
    if (arr[i] < smallest) {
      smallest = arr[i];
      smallestIndex = i;
    }
  }
  // после завершения цикла вернем индекс 
  // наименьшего найденного элемента
  return smallestIndex;
}
```

Далее наша задача - перейти к созданию самой функции сортировки, которая будет принимать массив и возвращать отсортированный массив. Будем возвращать __новый__ массив, чтобы избежать побочных эффектов, позаботиться о чистоте кода. Но вообще иногда имеет смысл изменять исходный массив, это экономит память. 

Создадим фукцию selectionSort, которая принимае массив. Внутри функции создадим новый, пустой массив, который будет на каждой итерации пополняться новым элементом в порядке возрастания из величины. И создадим копию исходного массива - нам ведь придется удалять из него по одному найденному элементу, чтобы вести поиск наименьшего значения только среди тех, которые еще не попали в отсортированный массив. 

```js
// Функция сортировки выбором
function selectionSort(arr) {
  // Копия исходного массива
  let arrCopy = arr.slice();
  // Массив для отсортированных данных
  let sortedArr = [];
  // Сортируем массив, удаляя найденные элементы
  // пока элементы для сортировки не кончатся
  while (arrCopy.length > 0) {
    let smallestElemIndex = findSmallest(arrCopy);
    sortedArr.push(arrCopy[smallestElemIndex]);
    arrCopy.splice(smallestElemIndex, 1);
  }
  return sortedArr;
}
```

### 3. Рекурсия

Рекурсия - элегантный метод решения задач. (_По мнению автора_)

Итак, допустим, нам нужно найти колюч от чемодана. 
Ключ от чемодана лежит в большой коробке с вещами. 
Большая коробка содержит в себе коробки поменьше.
А те, в свою очередь, может быть содержат еще меньшие коробки, а может и нет. 
Для решения задачи по поиску ключа автор предлагает 2 варианта:
1. Выделим место, назовем его _кучей коробок_. Задача _кучи коробок_ - хранить в себе все имеющиеся у нас неоткрытые коробки. Пока у нас только одна такая - первая большая коробка. Положим ее в _кучу_. Теперь перейдем к куче и возьмем нашу неоткрытую коробку с целью ее открыть. После открытия нас интересуют только 2 варианта: найдем ключ или найдем новые неоткрытые коробки. Если найдем ключ - поиск закончен. Если найдем новые, меньшие, неоткрытые коробки - сложим их в _кучу коробок_, чтобы открыть позже. Когда с первой коробкой покончено а ключа нет, идем к куче коробок, берем новую коробку и открываем ее - повторяем так до тех пор, пока не найдем ключ. 
Если мы говорим о реализации этой логики с помощью языка программирования, то нам необходимо: создать _кучу коробок_: переменную, которая будет хранить структуру данных, содержащую коробки. Задать условие: _пока куча не пуста_. И пока куча не пуста брать из нее по одной коробке, открывать ее и последовательно анализировать каждый лежащий в ней элемент: Если это коробка - добавить ее в _кучу коробок_. Если это ключ - завершить поиск. Когда элементы в коробке закончатся а ключ не найден повторять все, потому что _куча не пуста_. 

```js
// Аналог рекурсии с помощью классических циклов
function findAKey(data) {
  //тут будем хранить все неисследованные элементы
  let boxesToCheck = [];
  // первым элементом добавим наши исходные данные
  boxesToCheck.push(data);

  while (boxesToCheck.length > 0) {
    //берем последнюю коробку
    let box = boxesToCheck.pop();

    for (let item of box) {
      if (item === 'ключ') {
        return "Ключ найден!"
      } else if (Array.isArray(item)) {
        // это вложенная коробка, 
        // кладем ее в стек
        boxesToCheck.push(item);
      }
      // другие предметы игнорируем
    }
  }

  // если цикл закончился, значит ключа нет
  return "Ключ не найден"
}
```

Второй способ основан на рекурсии. __Рекурсией__ называют вызов функцией самой себя. 

```js
//Решение с помощью рекурсии
function findKeyUsingRecursion(bigBox) {
  for (let item of bigBox) {
    if (Array.isArray(item)) {
      let result = findKeyUsingRecursion(item);
      if (result === "Ключ найден!") {
        return result;
      }
    } else if (item === 'ключ') {
      return "Ключ найден!"
    }
    //другие предметы игнорируем
  }
  return "Ключ не найден"
}
```

Оба варианта решения задачи выдают один и тот же результат. Но автор полагает, что решение с помощью рекурсии выглядит более понятным. 

__Рекурсия__ используется во многих нужных алгоритмах, поэтому важно понимать ее концепцию. 

#### Базовый случай и рекурсивный случай

Так как рекурсивная функция вызывает сама себя, легко ошибиться и написать функцию так, что возникает бесконечный цикл. 

Приведем пример. Допустим, мы хотим написать функцию для вывода обратного отсчета:
\[3, 2, 1\]
Ее можно написать в рекурсивном стиле

```js
function countdown(i) {
  console.log(i);
  countdown(i - 1);
}
countdown(3)
// Приведет к бесконечному циклу и 
// переполнению стека
```

Когда мы пишем __рекурсивную__ функцию в ней необходимо указать в какой момент прервать рекурсию. 
Вот почему _каждая рекурсивная функция состоит из двух частей: __базового__ случая и __рекурсивного__ случая_.

В __рекурсивном__ случае функция вызывает сама себя. 
В __базовом__ случае функция себя не вызывает. Чтобы исключить зацикливание. 

Добавим базовый случай в функцию countdown:
```js
// исправленный вариант
function countdown(i) {
  console.log(i);
  if (i <= 1) {
    return
  } else {
    countdown(i - 1);
  }
}
```

#### Стек

В этом разделе мы поговорим про _стек вызовов_. 
Концепция стека вызовов играет важную роль в программировании вообще и при использовании рекурсии в частности. 
Предположим, мы устраиваем вечеринку. Планируя все заранее, мы составляем список дел и пишем их на небольших листках. Листки мы складываем в стопку. Наша стопка работает по очень простому принципу: новые элементы добавляются в начало стопки - на верх. И чтобы прочитать о каком-то запланированном деле нам надо взять листок, но взять его мы можем только сверху. Таким образом, наша структура данных поддерживает _занесение_ (вставка элемента в список) и _извлечение_ (чтение элемента с его последующим удалением), и все с одного края стопки. 

Такая структура данных называется __стеком__. 
__Стек__ - это простая структура данных. 

#### Стек вызовов

Компьютеры используют стек вызовов. 

Чтобы познакомиться с принципом его работы напишем функцию приветствия:

```js
// функция приветствия и стек
function greet(name) {
  console.log(`hello, ${name}!`);
  greet2(name);
  console.log(`getting ready to say bye...`);
  bye();
}
```
Эта функция выводит приветствие 'hello, ... !', а потом вызывает еще 2 функции прямо из себя. Вот эти функции:

```js
function greet2(name) {
  console.log(`how are you, ${name}?`)
}

function bye() {
  console.log(`ok bye!`)
}
```

Разберемся, что происходит при вызове функции

Примечание: для простоты опустм механику вывода сообщений в консоль

Допустим, мы вызвали функцию greet("maggie")
Сначала компьютер выделяет блок памяти для этого вызова.
Затем выделенная память заполняется данными, которые потребуются функции чтобы корректно выполнить код своего тела. В нашем случае функция ожидает аргумент __name__, который нужен ей для вывода сообщений в консоль. В выделенной для функции области памяти создается переменная __name__, которой присваивается значение переданного при вызове аргумента, а именно "maggie":

- Память для вызова __greet__: name = _"maggie"_;

Каждый раз, когда мы вызываем функцию, компьютер сохраняет в памяти значения всех переменных, используемых при данном вызове. Все все аргументы, с которыми была вызвана функция, становятся переменными в контексте выполнения этой функции и сохраняются в отдельной, выделенной для функции области памяти. 

Далее следует показ сообщения в консоли: hello, maggie!

После чего следует вызов другой функции приветствия, greet2("maggie")

Произошел вызов новой функции - значит компьютер обязан выделить блок памяти для этого вызова. 
Причем, так как первая функция еще не завершена, ее персональный блок памяти никуда не исчезает:

- Память для вызова __greet__: name = _"maggie"_;
- Память для вызова __greet2__: name = _"maggie"_;

И так как вторая функция приветствия подразумевает, что ей передадут параметр name, то в ее персональном блоке памяти тоже создается переменная, которая хранит значение переданного при вызове аргумента. В данном случае он такой же, как и для первой функции, но это не имеет значения. 
Теперь у нас два блока памяти для вызовов функций. Компьютер объединяет их в __стек__. Причем блок той функции, что была вызвана последней, попадает на самый верх. 
У нас вызвалась функция greet2, а значит поток выполнения перешел в ее тело. Функция воспользуется переданной ей переменной name и выведет в консоль сообщение:
_how are you, maggie?_
После чего функция greet2 завершает свое выполнение и возвращает поток выполнения в первую функцию. 

Когда поток выполнения возвращается в первую функцию, то в стеке, с его вершины убирается блок памяти, выделенный под функцию greet2, и самым верхним блоком стека вновь становится относящийся к greet. Сама функция продолжает выполняться с того места, где она была прервана. А значит ей пора вывести в консоль сообщение
_getting ready to say bye..._
А после поток выполнения наткнется на вызов функции bye. Тогда выполнение функции greet будет опять приостановлено, для выполнения функции bye будет выделено место в памяти. Этот блок памяти, выделенный для bye, попадет на вершину стека. Начнется выполнение функции bye, мы увидим сообщение
_ok bye!_
Блок данных для функции bye будет удален с вершины стека, управление вновь вернется в greet, а так как в теле greet больше нет команд то выполнение и этой функции завершится и ее контекст выполнения будет удален из стека. 

##### Стек вызовов с рекурсией

Рекурсивные функции исполизуют стек вызовов. 

Рассмотрим функцию вычисления факториала
```js
function fact(x) {
  if (x === 1) {
    return x
  }
  return x * fact(x - 1)
}
```

Допусим, мы хотим посчитать факториал числа 3. Посмотрим, что будет происходить, если за дело вазьмется наша рекурсивная функция. 

Мы вызываем функцию и передаем ей аргумент 3. 
* В _стеке вызовов_ создается контекст выполнения функции fact(3).
* Условная проверка не проходит, так как 3!==0
* Выполнение идет в _return x * fact(x - 1)_
А это значит, что директива return запускает функцию fact с аргументом x-1, тоесть 2.

* В _стеке вызовов_ создается контекст выполнения функции fact(2)
* Условная проверка вновь не проходит
* Выполнение опять идет в директиву return
А это значит, что директива вновь рекурсивно вызывает fact(x-1), что в данном случае будет fact(1)

* В _стеке вызовов_ создается контекст выполнения функции fact(1)
* Условная проверка проходит! 1===1 - true, а значит функция возвращает текущий x, тоесть 1.

Теперь посмотрим, что произошло с нашим стеком вызовов к текущему моменту:

fact(1)
fact(2)
fact(3)

На вершине стека у нас контекст выполнения функции fact(1). Под ним - контекст выполнения fact(2) - функция ожидает завершения. В самом низу - контекст выполнения fact(3) - функция ожидает завершения. 

Таким образом, у нас стек содержит 3 контекста, так как 3 функции еще не завершили свою работу.

Теперь функция fact(1) возвращает 1. Эта единица попадает в функцию fact(2), где выполнение зависло на строке return 2 * 1. Вычисляется результат умножения, 2, этот функция завершается, контекст ее удаляется из стека вызовов, результат отправляется в исходную функцию (которая и запустила цепочку рекурсивных вызовов) fact(3). Там выполнение кода зависло на строке return 3 * 2, вычисляется результат 6 - функция его возвращает, ее работа завершена, ее контекст выполнения удаляется из стека вызовов. 

Каждый рекурсивный вызов функции fact создает свою копию x, которая хранится в собственном контексте выполнения, индивидуальном для каждого вызова, а значит переменная x индивидуальна для каждой рекурсивно вызванной функции. 

Если мы вернемся к примеру с кучей коробок, то заметим, что в случае рекурсивного решения этой задачи мы не создавали особую струкру _куча коробок_, куда при итеративном решении складывали все неоткрытые коробки. В рекурсивном решении это не нужно - сама структура _стека вызовов_ выполняет эту роль кучи. Проверка открытой коробки не завершается, но откладывается в _стек вызовов_ до тех пор, пока в ней находятся другие коробки. 
А когда коробки кончатся - закрытие уже открытых коробок лавинообразно пойдет в обратном их открытию порядке. 
Это несомненно элегантный способ решения задач. Единственное, чем он ограничен - это размером _стека вызовов_. Для каждого языка, для каждой среды исполнения он разный. А значит ограничена и глубина рекурсии. 

И если мы понимаем, что решение конкретной задачи может привести к переполнению стека, у нас всегда остается вариант воспользоваться итеративным подходом: переписать рекурсию в виде цикла. Или попробовать создать комбинированный вариант. Или понадеяться на хвостовую рекурсию - но в случае с JavaScript хвостовые рекурсии хоть и заявлены как поддерживаемые, на практике работают плохо.

### 4. Быстрая сортировка

#### Разделяй и властвуй

Говоря о стратегии "Разделяй и властвуй" разберем несколько примеров. 

Представим, что мы - фермер. У нас есть участок, его длинна 1680м, а ширина 640м. Мы должны разделить эту землю на квадратные участки, но с условием: мы должны определить максимальный размер такого квадратного участка. Тоесть, стратегия разделить поле на кучу мелких участков не пройдет. 

Решение данной задачи методом "Разделяй и властвуй" состоит из 2 шагов:
1. Сначала определим _базовый_ случай. Это должен быть простейший случай из всех возможных. 
2. Задача будет разбиваться и сокращаться до тех пор, пока не сведется к базовому случаю. 

Для начала определимся с базовым случаем для нашей задачи. Для этого взглянем на наш участок и констатируем, что у него одна сторона больше другой. Следовательно, когда мы хотим разделить участок подобной конфигурации, мы можем принять _меньшую_ сторону за сторону квадрата и посмотреть, сколько таких квадратов содержит наш прямоугольный участок. 
А __базовым__ случаем будет такой, при котором одна сторона кратна другой, тоесть когда прямоугольник можно разбить на ряд квадратов без остатка. 

Теперь нужно вычислить __рекурсивный__ случай. 
Тут нам поможет стратегия _разделяй и властвуй_. Попробуем разбить имеющийся у нас участок на раяд квадратов: посмотрим, не сведется ли наша задача сразу к базовому случаю. При длинне участка в 1680м при разбиении его на квадраты со стороной 640м получим 2 квадрата и нераспределенную площадь размером 640м на 400м.
Итак, задача не свелась к базе, но теперь у нас есть новый участок, к которому мы можем применить тот же подход: попробуем разбить его на квадраты, сторона которых будет равна меньшей стороне прямоугольника. Придерживаясь этого принципа, будем производить деление на квадраты отстатков до тех пор, пока остаток не пропадет - что значит, что мы достигли __базового__ случая - стороны кратны. 
И эта сторона кврадрата будет нашим ответом. 

__Алгоритм Евклида__
_Если мы найдем самый большой участок, подходящий для такого размера, это будет значить, что мы нашли самый большой участок, подходящий и для всей фермы_

В итоге, выполнияя шаги вышеозначенного алгоритма мы придем к прямоугольному участку размером 160*80
Это наша __база рекурсии__
И этот прямоугольник с кратными сторонами! Его можно разделить на 2 квадрата по 80м без остатка. А это значит, что для всейго большого участка самый большой размер кврдрата составляет 80м.

Еще раз про стратегию __"Разделяй и Властвуй"__ применительно к данной задаче:
1. Определим простейший, базовый случай. 
2. Придумаем, как свести задачу к этому базовому случаю.

__"Разделяй и Властвуй"__ - не простой алгоритм, с помощью которого можно решить задачу. Скорее это подход к решению задачи. 
```js
function surveyor(data) {
  let length = data.length;
  let width = data.width;
  let remainder = length % width;
  console.log(`
  length: ${length}, 
  width: ${width}, 
  remainder: ${remainder}`)
  if (remainder === 0) {
    length = width;
    return { length, width }
  } else if (length <= 0 || width <= 0) {
    return "нет рационального решения"
  }
  length = width;
  width = remainder
  return surveyor({ length, width })
}
```

Рассмотрим еще один пример
Имеется массив чисел [2, 4, 6]

Нужно __суммировать__ все числа и вернуть __сумму__
Сделать это в цикле просто
```js
function cycleSum(arr) {
  let sum = 0;
  for (let int of arr) {
    sum += int
  }
  return sum
}
```
Но наша задача сделать то же самое с помощью рекурсии

Если мы попробуем воспользоваться стратегией __разделяй и властвуй__, то нам, во-первых, необходимо будет определить _базовый случай_, базу рекурсии. 
Какой самый простой, самый базовый случай, когда мы говорим о массиве с числами? Либо пустой массив, либо массив с одним элементом. Когда мы говорим про массив чисел, то базовым случаем для него вполне может стать пустой массив: элементов нет, их сумма равна 0. Можно рассмотреть как базовый случай, когда в массиве всего один элемент, но как тогда быть, если попросят найти сумму элементов пустого массива?

Далее мы должны определить, как __рекурсивный вызов__ будет приближать нас к __базовому случаю__ - тоесть к пустому массиву. 

Чтобы размер задачи постепенно уменьшался, введем логику:
Пусть если размер массива больше нуля, то возьмем элемент массива и прибавим к нему сумму остальных элементов массива:

$sum( [2, 4, 6] ) = 2 + sum( [4, 6] )$

Логично? Вроде да. Продолжим эту логику, чтобы посмотреть, к чему она нас приведет

sum( [2, 4, 6] ) = 
2 + sum( [4, 6] ) = 
2 + (4 + sum( [6] )) =
2 + (4 + (6 + sum( [] )))

И вот мы добрались до нашего __базового случая__, до _базы рекурсии_ - пустой массив, сумма элементов которого вернет 0.

Примененную схему можно попытаться описать так: 

__Логика суммы элементов полученного массива__:
1. Если полученный массив пуст - вернуть 0
2. Если он не пуст - вернуть Элемент А массива плюс __Логика суммы элементов полученного массива__ без Элемента А.

Если бы мы захотели создать _рекурсивную_ функцию __sum__ на основе этой логики, и проследили, что происходит со стеком вызовов, то увидели бы, что:
1. Вызывается функция sum( [2, 4, 6] ). В стеке вызово создается ее контекст выполнения и помещается на верх. Так как переданный массив __не пуст__ - функция должна вернуть 6 + sum( [2, 4] ). Так как у нас вызов функции из тела функции, то процесс выполнения текущей функции приостанавливается и ...
2. Вызывается функция sum( [2, 4] ). В стеке вызово создается ее контекст выполнения и помещается на верх. Так как переданный массив __не пуст__ - функция должна вернуть 4 + sum( [2] ). Так как у нас вызов функции из тела функции, то процесс выполнения текущей функции приостанавливается и ...
3. Вызывается функция sum( [2] ). В стеке вызово создается ее контекст выполнения и помещается на верх. Так как переданный массив __не пуст__ - функция должна вернуть 2 + sum( [] ). Так как у нас вызов функции из тела функции, то процесс выполнения текущей функции приостанавливается и ...
4. Вызывается функция sum( [] ). В стеке вызово создается ее контекст выполнения и помещается на верх. Так как переданный массив __пуст__ - функция должна вернуть 0. Мы достигли __базы рекурсии__. Функция возвращает 0 и контекст ее выполнения удаляется из стека вызовов. На вершине стека оказывается контекст выполнения предыдущей функции ...
5. sum( [2] ). Она возвращает 2 + 0 = 2. Контекст ее выполнения удаляется с вершины стека вызовов, на вершине оказывается контекст выполнения предыдущей функции ...
6. sum( [2, 4] ) 
... и так далее. Функции возвращают результаты суммы, завершаются, их контексты выполнения удаляются из стека вызовов, пока в итоге мы не доходим до материнской функции, запустившей процесс: sum( [2, 4, 6] ), которая возвращает 6 + 6 = 12. Все контексы выполнения удалены из стека вызовов, работа функций завершена, результат получен. 

__СОВЕТ__
Когда мы пишем рекурсивную функцию, в которой задействован массив, базовым случаем часто оказывается пустой массив или массив из одного элемента. Если неизвестно, с чего начать - всегда можно попробовать этот вариант. 

Попробуем реализовать описанную рекурсивную функцию на JS

```js
function sum(arr) {
  // базовый случай - пустой массив
  if (arr.length === 0) {
    return 0
  }
  // шаг рекурсии
  return arr.pop() + sum(arr)
}
```
Функция работает с концом массива, так как это более экономичный подход с точки зрения ресурсов компьютера

Интересная задача ставится автором книги:
Нас просят написать рекурсивную функцию, которая будет искать наибольший элемент из переданного списка. 

Чтобы найти логику решения этой задачи, на необходимо воспользоваться принципом __"Разделяй и властвуй"__.
1. Надо найти _Базовый случай_ - _базу рекурсии_
2. Надо определиться с рекурсивным случаем - логикой, которая будет видоизменять переданные исходные данные, пошагово приближая нас к _Базовому случаю_.

```js
function findMax(arr) {
  // базовый случай
  if (arr.length === 1) {
    return arr[0]
  }
  let last = arr.pop()
  let subMax = findMax(arr)
  return last > subMax ? last : subMax
}
```
На каждой итерации переменная last сохраняет в себе последний элемент и помогает сократить список на один элемент с конца. Что приближает нас к базовому случаю - когда в списке останется только один элемент. 

Но для сравнения нам нужно 2 элемента. Поэтому введем вторую переменную subMax и будем ожидать, что в нее будет записан результат рекурсивного вызова нашей функции. Пока в списке остается больше одного элемента, переменная subMax будет ожидать результата рекурсивного вызова. Когда в списке останется один элемент, функция вернет его - так как сработает условие:

```js
if (arr.length === 1) {
    return arr[0]
  }
```

Вернется самый первый элемент списка. Этот элемент будет записан в контексте вызова предыдущей функции в переменную subMax, и код тела станет выполняться дальше, а там нас ждем директива return, которая должна произвести сравнение элемента из переменной last и того элемента, что вернулся из предыдущей функции. Большее значение вернется в предыдущий рекурсивный вызов и опять попадет в сравнение, из которого наверх попадет большее, и так далее...
... Пока самая первая функция не проведет сравнение первого элемента с самым большим элементом из предыдущих элементов списка. И не вернет большее значение всего списка. 

В последней задаче автор интересуется у нас, каков будет базовый случай для бинарного поиска, доведись нам реализовать его с помощью рекурсии. 

#### Быстрая сортировка

Быстрая сортировка - это алгоритм сортировки. Она работает быстрее сортировки выбором и часто применяется в реальных проектах. 
Она основана на стратегии _Разделяй и Властвуй_

Итак, попробуем воспользоваться быстрой сортировкой для упорядочивания массива. 

__Базовый случай__ - представим себе такой простейший массив, в котором сортировать элементы вообще не нужно. Очевидно, что это либо пустой массив, либо массив из 1 элемента. 
Такие массивы можно просто возвращать в исходном виде - это и будет наш _базовый случай_

```js
function quicksort(arr) {
  if (arr.length < 2) {
    return arr
  }
}
```

__Рекурсивный случай__ - теперь пора поговорить о массивах подлиннее. Массив из 2 элементов сортируется без особых проблем: сравниваем 2 элемента. Если первый _больше_ второго, то просто меняем их местами. 
Но такая логика в отншении массива из 3 элементов работает уже не так хорошо. 
Алгоритм __Быстрой сортировки__ работает так: сначала из всего массива выбираем один элемент. Он называется __опорный элемент__. 
При выборе __опорного элемента__ стоит придерживаться _особой_ логики, чтобы выбрать _хороший опорный элемент_, но пока просто выберем первый. 
Теперь наша задача найти элементы, которые _меньше_ опорного и те, которые _больше_ опорного. Этот процесс называется __Разделением__
В итоге мы должны получить: 
* массив элементов, которые меншьше опорного
* сам опорный элемент
* массив элементов, которые больше опорного
Заметим, что получившиеся 2 подмассива _не отсортированы_. Они просто выделены из исходного массива. 

Но вот если бы они были отсортированы, то тогда нам бы только оставалось объединить их в порядке: левый подмассив, опорный элемент, правый подмассив. И мы бы получили полностью отсортированный массив. 
Но как этого добиться? Как сделать неотсортированные подмассивы отстртированными? 
На самом деле можно применить к неотсортированным массивам рекурсивный вызов быстрой сортировки. И всякий раз, когда подмассив получается достаточно большим, рекурсивно вызывать быструю сортировку для такого подмассива, пока функция быстрой сортировки в каждом отдельном случае не натолкнется на базовый случай, с которым она знает как работать. Тогда стек вызовов функций начнет рекурсивно схлопываться, функции будут возвращать базовые случаи, которые будут расставляться в правильном порядке, чтобы в конце получить полностью отсортированный массив. 

Для примера возьмем массив [33, 15, 10]

В качестве опорного элемента возьмем первый: 33. 
Теперь функции быстрой сортировки надо распределить оставшиеся элементы в 2 подмассива: меньше 33 и больше 33. В левый массив(который меньше 33) попадут [15, 10]. В правый массив ничего не попадет, так как у нас нет чисел больше 33, поэтому он останется пустым. 
Получаем: 
[15, 10] 33 []

Так как у нас есть _неотсортированный_ подмассив из 2 элементов, мы просто рекурсивно вызовем для него нашу функцию сортировки. Она проделает все то же самое для этого массива, тоесть вычленит из него _опорный_ элемент и относительно него расположит второй элемент. А значит придет к базовому случаю. 
Затем рекурсивные вызовы __схлопнутся__, выбрасывая элементы в отсортированном виде.
В конечном итоге мы получим отсортированный массив: 
[10, 15, 33]

Здесь автор подводит нас к интересной мысли. Исходя из примеров выше мы можем утверждать, что наша функция __быстрой сортировки__ гарантированно справляется с массивами из 0, 1, (это вообще базовые случаи), 2 и 3 элементов. Но справится ли она с массивом из 4 элементов? Если мы передадим нашей функции такой массив, то, после того, как она возьмент _опорный элемент_, в каждом из подмассивов окажется от 0 до 3 элементов. А с таким размером массива наша функция точно справляется, просто надо рекурсивно вызвать ее для этого подмассива. А значит функция работает с массивом из 4 элементов. По той же логике теперь мы можем доказать, что функция справится с массивом из 5 элементов. И так далее. 

__ДОКАЗАТЕЛЬСТВО ПО ИНДУКЦИИ__
Мы познакомились с __доказательством по индукции__. Это один из способов доказать, что алгоритм работает. Каждое индуктивное доказательство состоит из __базы__ и __индуктивного перехода__. Допустим надо доказать, что возможно подняться по лестнице. Если удалось описать набор дейтсвий, которые гарантированно позволят подняться с первой ступеньки на вторую, то можно утверждать, что у нас есть способ на каждом этапе подняться на еще одну ступеньку. Со ступеньки 2 на ступеньку 3. Вне зависимости от того, на какой ступеньке мы стоим. Базовый случай - переход от ступеньки 1 на ступеньку 2. 
Аналогично, мы можем говорить об алгоритме быстрой сортировки. Работоспособность алгоритма для базового случая - работа с массивами длинной 0 и 1 элемент была продемонстрирована. В __индуктивном переходе__ мы доказывали, что если алгоритм работает для массива из 1 элемента, то он сработает для массива из 2 элементов. Мы __перешли__ от базового случая к более комплексному. Так же нам удалось доказать, что для массива из 3 элементов наш алгоритм будет работать именно потому, что он работает для массива из 2. Это важная особенность: мы доказали, что сама природа нашего алгоритма сведет рекурсивное решение к случаям, одним из которых может стать подмассив из 2 элементов - а мы __уже доказали__, что наш алгоритм справляется с таким случаем, а значит в доказательстве работоспособности для массива из 3 элементов можно сослаться на доказательство для 2 элементов, которое в свою очередь ссылается на доказательство работоспособности для базовых случаев. 
И когда перед нами станет задача доказать работоспособность алгоритма для массива из 4 элементов, мы будем ссылаться в доказательстве на работоспособность алгоритма для 3 элементов. 
А смекалка позволит нам сделать предсказание, что чтобы доказать работоспособность алгоритма для массива из 100 элементов нам не нужно идти в своем доказательстве последовательно от базового случая до 99.

Осталось только реализовать нашу логику в виде простейшего кода. 

Мы говорили о базовом случае
```js 
function quickSort(arr) {
  if (arr.length < 2) {
    return arr
  }
}
```
Он возвращает исходный массив, если в нем от 0 или 1 элемент. 

Теперь реализуем оставшуюся логику.
Нам необходимо выбрать _опорный_ элемент. Отсортировать остальные элементы массива относительно опорного элемента. Вернуть массив, в котором элементы отсортированы относительно опорного элемента. 

```js
// выделяем ОПОРНЫЙ ЭЛЕМЕНТ
// пусть это будет первый элемент массива
let pivot = arr[0]
```

Теперь пришла пора сортировать остальные элементы массива в подмассивы больше\меньше _опорного_ элемента. 

Для этого нам нужно сравнить каждый элемент с _опорным_: 
elem > pivot или elem < pivot. 
В сортировке нам поможет метод массивов .filter(func)
На основе переданной ему функции сортировки он выберет только подходящие элементы из массива. И очень удобно, что метод возвращает массив.
Но помним: так как первый элемент мы взяли в качестве _опорного_, то производить фильтацию надо по всем элементам кроме первого. А значит воспользуемся методом .slice()

```js
// получим массив элементов, которые МЕНЬШЕ опорного
let less = arr.slice(1).filter(i => i < pivot);
// получим массив элементов, которые БОЛЬШЕ опорного 
let greater = arr.slice(1).filter(i => i > pivot);
```

А в конце передадим подмассивы less и greater нашей функции быстрой сортировки, чтобы она разобралась с правильным порядком их элементов. 
И вернем результат, обязательно в правильном порядке: меньшие элементы, опорный элемент, большие элементы.
Так как наша функция возвращает массив, но вызывается рекурсивно, позаботимся о том, чтобы на выходе получить не вложенные массивы, а один массив из отсортированных элементов. Для этого воспользуемся оператором ... который раскороет на каждом шаге результат рекурсивног подвызова.

```js
return [...quickSort(less), pivot, ...quickSort(greater)];
```
В итоге получаем:
```js
function quickSort(arr) {
  if (arr.length < 2) {
    return arr
  }
  // выделяем ОПОРНЫЙ ЭЛЕМЕНТ
  let pivot = arr[0];
  // получим массив элементов, которые МЕНЬШЕ опорного
  let less = arr.slice(1).filter(i => i < pivot);
  // получим массив элементов, которые БОЛЬШЕ опорного 
  let greater = arr.slice(1).filter(i => i > pivot);

  return [...quickSort(less), pivot, ...quickSort(greater)];
}
```

##### Снова об "О - большом"

Алгоритм __быстрой сортировки__ уникален тем, что его скорость зависит от выбора _опорного_ элемента. 

Но прежде, чем разъяснить истинность и нюансы этого утверждения нам стоит вновь обратиться к "О-большому" для некоторых алгоритмов

- $O(\log n)$ - или _Логарифмическое время_ - Бинраный поиск
- $O(n)$ - или _Линейное время_ - Простой поиск
- $O(n \times \log n)$ - эффективные алгоритмы сортировки, например - _Сортировка слиянием_
- $O(n^2)$ - медленные алгоритмы сортировки - _Сортировка выбором_
- $O(n!)$ - очень медленные алгоритмы - Задача о коммивояжере

Возьмем к примеру скорость работы алгорима _Сортировка выбором_: $O(n^2)$. - Это когда нам надо пройтись по массиву число раз, равное количеству элементов в самом массиве. Это довольно медленный алгоритм. 

А вот алгоритм Сортировка слиянием работает со скоростью $O(n \times \log n)$. Гораздо быстрее!

С _Быстрой сортировкой_ все обстоит сложнее. В __худшем__ случае она работает за время $O(n^2)$ - ничем не лучше _Сортировки выбором_. 
Но это худший случай. А в среднем быстрая сортировка выполняется за время $O(n \times \log n)$.

Исходя из представленной информации напрашиваются 2 вопроса:
* что значит __лучший__ случай и __худший__ случай?
* если _Быстрая сортировка_ показывает время $O(n \times \log n)$ только в каком-то __лучшем__ случае, а _Сортировка слиянием_ __гарантированно__ работает с таким временем, не лучше ли _всегда_ использовать _Сортировку слиянием_?

###### Сортировка слиянием и Быстрая сортировка

Представим себе функцию, которая получает список и последовательно выводит в консоль каждый элемент этого списка

```js
function showItems(arr) {
  for (let item of arr) {
    console.log(item);
  }
}
```
Так как такая функция перебирает весь список длинною n, то она выполняется за время $O(n)$.
Предположим, что мы изменим функцию так, чтобы она делала секундную паузу перед каждым выводом элемента. 
И если нам нужно будет решить, какую функцию использовать для быстрого вывода в консоль группы элементов, логично будет не модифицировать функцию добавлением в нее секундной задержки.

Но обратим внимание, что даже с учетом секундной задержки время выполнения нашей функции оценивается как $O(n)$, хотя очевидно, что она выполняется дольше. 
Однако более корректно было бы учесть секундную задержку при учете времени выполнения. Чтобы отразть в "О-большом" ту реальную разницу между функцией и ее модифицированным вариантом:

$$O(c \times n)$$
Где c - это наш коэфициент секундной задержки. Он называется _константой_.


Так, если мы предположим, что для вывода одного элемента в консоль компьютеру потербуется 10мс (это условная величина которая не отражает реальной скорости работы компьютера), а для вывода с задержкой 1с, то у нас появляются 2 константы:
* $c_1 = 0.01$ секунды - для аппаратной задержки в 10мс
* $c_2 = 1$ секунда - для пользовательской задержки в 1с

__Обычно константа игнорируется__

Если два алгоритма имеют разное "О-большое", то считается, что константа не имеет значения. 
Чтобы продемонстрировать это на примере, возьмем 2 алгоритма: _Простой поиск_ и _Бинарный поиск_.
И для _Бинарного поиска_ добавим пользовательскую константу $c_2$ в целую секунду: $O(c_1 \times n) = O(10ms \times n)$. А для _Простого поиска_ возьмем нашу наименьшую константу $c_1$: $O(c_2 \times \log n) = O(1s \times \log n)$.

На первый взгляд _Простой поиск_ приобрел некоторую заманчивость в плане времени выполнения благодаря нашей наименьшей константе. 

Теперь предположим, что поиск ведется по списку из 4 000 000 000 элементов (4 миллиарда).

Получаем следующие значения:
* Для _Простого поиска_: $10мс \times$ 4 миллиарда = 463 дня
* Для _Бинарного поиска_: $1с \times \log(4 000 000 000) = 1с \times 32$ = 32 секунды

Как видим, бинарный поиск работает намного быстрее, не смотря на константы, как и предсказывало "О-большое"

Однако, в некоторых случаях, константа __может иметь значение__.
Примеры подобного рода - _Быстрая сортировка_ и _Сортировка слиянием_.

Обе сортировки характеризуются временем выполнения $O(n \times \log n)$.
Но у _Быстрой сортировки_ __константа__ меньше. _Быстрая сортировка_ работает __быстрее__. 

А на практике _Быстрая сортировка_ работает быстрее, потому что __средний__ случай встречается намного чаще __худшего__. 

Как выглядит __средний__ случай и чем он отличается от __худшего__?

###### Средний и худший случай

Быстродействие _Быстрой сортировки_ напрямую зависит от выбранного _опорного_ элемента. 
Предположим, что _опорным_ всегда выбирается первый элемент, а на сортировку приходит уже отсортированный массив. Быстрая сортировка не проверяет, отсортирован входной массив или нет и пытается его сортировать. 

В данном случае мы столкнемся с тем, что на каждом шаге рекурсии в одном подмассиве у нас окажется весь переданный массив за исключением _опорного_ элемента. 

[1,2,3,4,5,6,7,8]

[] 1 [2,3,4,5,6,7,8]

[] 2 [3,4,5,6,7,8]

[] 3 [4,5,6,7,8]

[] 4 [5,6,7,8]

[] 5 [6,7,8]

[] 6 [7,8]

[] 7 [8]

Размер стека вызовов в данном случае составит 8

Но предположим, что в качестве _опорного_ мы выбираем элемент из __середины__. Тогда:

[1,2,3,4,5,6,7,8]

[1,2,3] 4 [5,6,7,8]

[1] 2 [3] ::: [5] 6 [7,8]

 [] 7 [8]

Стек данного рекурсивного вызова очевидно короче, его высота составляет 4.

Массив всякий раз делится надвое, поэтому количество рекурсивных вызовов, равное количеству элементов, излишне. 

В первом случае __ВЫСОТА СТЕКА ВЫЗОВОВ__ может быть описана как $O(n)$ - это худший вариант развития событий, _худший_ сценарий, по сути повторяющий собой решение _последовательным перебором_. А во втором случае __ВЫСОТА СТЕКА ВЫЗОВОВ__ может быть описана как $O(\log n)$ - это лучший вариант развития событий, _лучший_ сценарий.

Тут необходимо сделать отступление:
Если мы посчитаем вручную, то увидим, что во втором случае нам пришлось сделать 5 вызовов всего. При этом левая ветка от вершины к остнованию 3 вызова, правая ветка от вершины к основанию 4 вызова. Но первые 2 шага на схеме для обоих веток будут общими, поэтому фактически после 2 шагов будет выполнен 1 шаг в левой ветке и 2 шага в правой ветке:
$$
2 + 1 + 2 = 5
$$

Тут есть принципиальный момент. Да, сумма вызовов по всем веткам не равна сумме вызовов в самой длинной ветке. 

Однако обратим внимание вот на что:

При линейном переборе массива у нас одна длинная цепочка действий. Каждый шаг проводит работу с подмножеством, практически идентичным подмножеству предыдущего шага. Суммарное время $n + (n-1) + (n-2) + ... + 1 = \frac{n(n-1)}{2} = O(n^2)$ - это как раз ситуация нашего __худшего__ случая, когда 8 элементов массива дали линейную цепочку стека вызовов длинною 8 вызовов. Каждый из этих вызовов __полностью__ просматривает весь переданный ему массив.

Разделяй и властвуй дает нам сбалансированное разбитие. 
* На верхнем уровне дерева стека рекурсивных вызовов мы работаем с $n$ элементов, разделяя их на части. 
* На следующем уровне у нас 2 подзадачи размером $\frac{n}{2}$ и каждая обрабатывает свои $\frac{n}{2}$ элементов --> но если мы сложим все эти обработки то получим те же самые $n$ элементов: $\frac{1}{2} n + \frac{1}{2} n = O(n)$
* На следующем уровне 4 подзадачи, каждая размером $\frac{1}{4} n$, общее время обработки всех 4 задач составит $4 \times \frac{1}{4} n = O(n)$
* И так до тех пор, пока размер подзадачи не достигнет уровня базы рекурсии.

Получается, что если мы сложим не все ветки разом, а будем складывать только количество элементов, обрабатываемых на каждом __уровне__ дерева стека рекурсивных вызовов, то на каждом уровне мы как-бы тоже просматриваем весь массив $n$. 

На каждом уровне суммарная работа $O(n)$. 

Но число уровней теперь не $n$, а $\log n$, что дает $O(n\times \log n)$ !!!

_Вот почему мы в праве говорить, что глубина стека рекурсивных вызовов, или размер дерева стека рекурсивных вызовов, определяется __самой длинной веткой__, а не суммой веток._

Сумма веток превратит нашу разветвленную сруктуру в линейную, но для такой структуры количество выполняемых операций будет неоднородным! НЕ равным $O(n)$, а значит подсчитьать О-большое будет не в пример сложнее.

__Ключевая идея:__
* _Для каждой рекурсии -- работа линейна по размеру массива_
* _Для всей рекурсии -- мы суммируем такие линейности для разных размеров массива_

Таким образом, суммируя все вышесказанное:
__Худший случай__

Высота стека вызовов составит $O(n)$, алгоритму каждый раз придется работать с $O(n)$ элементами переданного массива, а значит общее время рабты в худшем случае составит 

$$
O(n)\times O(n) = O(n^2)
$$

__Лучший случай__

Высота стека вызовов составит $O(\log n)$. Да, алгоритму все так же придется работать с $O(n)$ элементами переданного массива, но в итоге мы получим более заманчивую формулу времени работы:

$$
O(n) \times O(\log n) = O(n \times \log n)
$$

А сюрприз в том, что лучший случай зачастую является средним. Если мы всегда будем выбирать в качестве опорного случайный элемент массива, то в подавляющем большинстве случаев время работы алгоритма составит $O(n \times \log n)$. Исключение - если все элементы массива одинаковы время рабты алгоритма будет как у худшего сценария, если мы не введем дополнительную логику. 

Итак, алгоритм _Быстрой сортировки_ -- один из самых __быстрых__ среди всех существующих алгоритмов сортировки. И заодно является хорошим примером стратегии __разделяй и властвуй__. 

Стратегия __разделяй и властвуй__ и __рекурсия__ это понятия, которые необходимо разделять. 

__Рекурсия__

Сама по себе рекурсия не гарантирует никакого ускорения. Мы можем решить задачу о суммировании элементов массива через _рекурсию_, а можем с помощью простого цикла, и рекурсивное решение не будет самым быстрым! Но это будет классическое решение с помощью рекурсии. Рекурсия допускает, что время ее работы будет $O(n)$, это вполне нормально для рекурсии. 

Рекурсия может быть выбрана как синтаксически более понятный для чтения и написания способ решения задачи по сравнению с циклом - и в этом будет ее преимущества, а не в скорости. 

Преимущество рекурсии - понятность кода при работе со вложенными структурами или задачами, которые естественно определяются через самих себя. 


__Разделяй и властвуй__ 

Это про скорость. Когда нам не подходит линейный перебор каждого элемента массива, потому что это слишком __долго__. Когда мы хотим ускориться. Эта стратегия позволяет разбить одну задачу как-бы на несколько (например две) __ветвящихся__ подзадачи. Не последовательный рекурсивный подвызов функции для __каждого__ следующего элемента, а 2 __ветвящиеся__ задачи, которые тем не менее никто не запрещает решать рекурсивно. Но! За счет разветвления этих задач мы и получаем ситуацию, когда высота дерева стека рекурсивных вызовов разительно отличается от таковой высоты при последовательном вызове функций для каждого элемента обрабатываемого списка. 

Именно тут отражен момент, когда мы смогли говорить о том, что для быстрого поиска есть __хороший__ и __плохой__ сценарий. 

В __плохом__ сценарии нам никак не удавалось __разветвить__ задачу, потому что всегда получался пустой массив и массив из всех остальных элементов, что практически сводило всю нашу стратегию к итеративному подходу (наподобие того, что мы использовали при подсчете всех элементов массива рекурсией): сколько элементов - такова и высота стека вызовов. Вот почему мы и оценивали ее как $O(n)$

В хорошем же сценарии, когда мы выбирали удачный опорный элемент, мы наконец смогли добиться __разветвленности__ процессов: два подмассива, две __независимые__ подзадачи. И именно за счет разветвленности мы смогли сократить высоту дерева стека вызовов на величину, которую уже оценили как $O(\log n)$. 

Это была история про ускорение, которого мы смогли добиться за счет сокращения высоты дерева стека рекурсивных вызовов.


### Хеш - таблицы

Допустим, мы продавец в магазине. Каждый раз, когда клиент покупает товар, мы должны узнать его цену. У нас для этого есть специальная книга. Если записи в книге не упорядочены, то теоретически, чтобы найти цену нужного товара, нам нужно просмотреть все записи в книге. И такая задача сравнима с _простым поиском_, а значит займет $O(n)$ времени. 

Если же записи упорядочены, то задача сведется к _бинарному поиску_, а значит поиск товара займет $O(\log n)$.

Но даже при таких раскладах, поиск займет время, зависящее от размеров нашей гипотетической книги. Клиетны могут начать нервничать.

Неплохо было бы иметь помощника, который бы помнил все цены на товары наизусть. Тогда он сразу бы подсказывал нам цену на товар. 

Такой помощник сообщает время сразу, _вне зависимости от размеров книги_, а значит это будет еще быстрее, чем использовать бинарный поиск.

Мы хорошо знакомы с 2 типами данных: __списки__ и __массивы__. 
Допустим, мы выберем массив для хранения данных о наших товарах. Каждый элемент массива должен содержать название товара и его цену. Допустим, мы отсортируем массив по __названиям__ товаров. Тогда мы сможем провести по такому массиву _бинарный поиск_. Но если мы хотим, чтобы поиск занимал время, не зависящее от размера данных, тоеть если мы стремимся к $O(1)$, то нам пригодятся __хеш - функции__. 

#### Хеш - функции

Хеш - функция представляет собой функцию, которая принимает строку и возвращает число. 

Говорят, что _хеш - функции отображают строки на числа_. 

Хеш - функция должна соответствовать некоторым требованиям:
* Она должна быть последовательной. Получая строку "Апельсин" и преобразуя ее в число 4 мы должны быть уверены, что в следующий раз, когда передадим этой функции строку "Апельсин" то снова получим на выходе число 4. 
* Разным словам должны соответствовать разные числа

Итак, хеш - функция преобразует строки в числа. Это поможет нам с задачей хранения данных в массиве. 
Как мы помним, у массивов произвольный доступ к элементам. Это значит, что в не зависимости от длинны массива мы можем получить любой его элемент по индексу. 

Передав хеш - функции название товара, вроде "Апельсин", мы можем получить число, обозначающее товар. Пусть 3. Теперь берем наш массив и в позицию с индексом 3 записываем цену апельсина. 

Помните, чем мы были ограничены раньше? В каждом элементе нам приходилось хранить и название товара, и его цену. А потом упорядочивать все элементы массива по названиям, чтобы получить возможность проводить бинарный поиск. 
Теперь мы лишились этого ограничения. Хеш-функция преобразует название (строку) в число (индекс), а храним мы только цену. И получаем возможность мгновенного доступа к элементу. 

Хеш-функция неизменно связывает название с одним индексом. В первый раз, когда мы передаем ей название товара, она возвращает число, которое мы будем использовать в качестве индекса в массиве. В последующие разы, когда мы передаем хеш-функции то же самое название, она будет возвращать нам индекс, по которому в массиве хранится цена товара. 

Хеш-функция связывает разные строки с разными индексами. Таким образом, каждое оригинальное название товара получает оригинальный индекс. 

Хеш-функция знает размеры массива и возвращает только действительные индексы. Таким образом, если длинна массива 5, хеш-функция не вернет 100, потому что это значение не является действительным индексом в массиве. 

Когда мы свяжем воедино _хеш-функцию_ и _массив_, мы получим структуру данных, называемую __хеш-таблицей__.

Массивы и списки напрямую отображаются на адреса памяти, но хеш-таблицы устроены хитрее. Они определяют место хранения элементов при помощи хеш-функций. 

Они также известны под другими названиями: "Ассоциативные массивы", "Словари", "Отображения", "Хеш-карты" или просто хеши. 

Хеш-таблицы исключительно быстро работают, и все благодаря тому что в основе их работы лежит скорость получения данных из массива. 

Важно оговориться, что мы обсуждаем __идеальную__ хеш - функцию. Она вносит _каждый_ новый элемент в _отдельную_, _собственную_ ячейку. На практике __идеальных__ функций не существует. Часто выходить так, что для нескольких __разных__ строк логика хеш - функции выдает __одинаковые__ числовые результаты, что приводит к тому, что на __одну__ ячейку массива претендуют несколько __разных__ элементов. Это вопрос __коллизий__, а такое _взаимно-однозначное_ связывание называется _инъективной функцией_. Красивый термин, подойдет чтобы флексить им перед пацанами за гаражами.

Самостоятельная реализация _хеш - таблиц_ задача довольно редкая, по той причине что практически каждый язык программирования предоставляет их готовую реализацию "_из коробки_". 

#### Использование хеш-таблиц для поиска

Представим телефонную книгу в телефоне. Имена людей в ней связаны с их номерами телефонов. Такая книга должна поддерживать следующие функции:
* Добавление имени человека и номера, связанного с этим именем
* Получение номера телефона, связанного с введенным именем

Эта задача идеальна для хеш-таблиц. Они отлично работают, когда мы хотим:
* Создать связь, __отображающую__ один объект на другой. 
* Найти значение в списке.

(Тут автор прибменил терминологию, скорее характерную для математики. Поясним. Если мы возьмем абстрактнуб функцию $f(x)=y$, то тем самым мы как бы скажем: _множество значений $x$ __отображается__ на множество значений $y$ согласно некому правилу_, которое и описывает функция. Так, $f(x) = 2x$ говорит о том, что _любому значению из множества $x$ соответствует такое значение из множества $y$, которе больше $x$ в 2 раза_.

Применительно к словам автора мы можем сказать: В нашем примере любому добавленному в телефонную книгу имени соответствует лишь один номер телефона, а правило, по которому конкретное имя связано с конкретным номером описывается логикой, заложенной в хеш-функцию. Тоесть множество имен телефонной книги __отображается__ на множество номеров телефонной книги согласно правилу, которое связывает __конкретное имя__ с __конкретным номером__.)

Преимущество хеш-таблиц для задач подобного рода становится очевидным, если мы попытаемся решить ту же задачу с использованием массивов. Ведь хеш-таблицы упрощают моделирование __отношений между объектами__. 

Хеш-таблицы используются для поиска соответствий в гораздо большем масштабе. 

####  Хеш DNS

Так, для любого посещаемого веб-сайта его имя преобразуется в IP - адрес. 
Связать символьное имя с IP - адресом это задачка для хеш-таблиц. Этот процесс называется __преобразованием DNS__. 
Хеш - таблицы это лишь один из способов реализации данной функциональности. 

На компьютерах существует хеш DNS, который хранит подобные сопоставления для недавно посещенных сайтов и который удобно реализовывать с помощью хеш - таблиц. 

#### Исключение дубликатов

Допустим, мы руководим избирательным участком. Естественно, каждый избератель может проголосовать всего 1 раз.

Как узнать, что он не голосовал ранее? Когда человек приходит на участок, мы спрашиваем его __полное имя__ (наша строка) а затем проверяем в списке имен, что это имя ранее не было записано. 

Если имя входит в список - значит человек ранее уже голосовал - мы не можем допустить его к голосованию повторно. 

Если имени в списке нет - мы добавляем его в список и пропускаем человека для голосования.

А теперь представим, что ситуация приближена к реальной - это значит, что список проголосовавших к середине дня уже огромен, а значит проверка каждого нового человека - задача, требующая огромного времени, если мы решаем ее последовательным перебором. Однака ничто не мешает нам воспользоваться хеш-таблицами!

Таким образом нам потребуется функция, которая на входе принимает имя голосующего а затем проверяет, нет ли этого имени в списке проголосовавших. 

```js
// создадим пустой список
const voters = {};

function checkVoter(name) {
  if (voters[name]) {
    console.log(`
      ${name} уже проголосовал.
      Он не может быть допущен 
      к голосованию повторно!
      `)
      return;
  } else {
    // занесем ранее не голосовавшего
    // участника в наш список
    voters[name] = true;
    console.log(`
      Участник ${name} может 
      быть допущен к голосованию
      `)
  }
};
```
Для создания функции проверки голосовавших на основе логики хеш - таблиц мы воспользовались пустым объектом как основой для нашего списка. 
Ввиду того, что свойства объекта - это строки, а доступ к свойствам объекта в JS осуществляется на основе хеш - функции, реализованной на уровне языка, то пустой объект подойдет для поставленной задачи. 

Если бы мы хранили имена проголосовавших в списке или массиве, то со временем проверка каждого нового значения отнимала бы все больше времени, так как каждая проверка __последовательно__ сравнивала бы предоставленное значение со всеми, уже __имеющимися__ в списке. 

Хеш - таблица позволяет провести __проверку для исключения дубликата__ со скоростью, __не зависящей__ от текущего _размера_ списка. 

#### Использование хеш-таблицы как кэша

Наш последний пример - кэширование.

Общая идея кэширования такова: 
* Мы обращаемся с запросом к серверу сайта. 
* Сервер задумывается, генерирует веб-страницу и отправляет ее пользователю.
* Мы получаем веб-страницу.

Например, сервер хочет показать нам какие-то динамические данные. Например, список заявок в друзья в случае социальной сети. На сбор этой информации у сервера уйдет какое-то время.
На сбор и обработку такого рода информации может уйти, например, пара секунд. Это очень долго, пользователь получит __негативный__ опыт от использования нашего сервера. 

Кроме того, серверу социальной сети приходится обслуживать миллионы пользователей, и эти пары секунд для них суммируются. 

Тут нам потребуется другой пример. Представим, что у нас есть племянница, которая постоянно задает нам вопросы о планетах Солнечной системы. Ее интересует расстояние в километрах от Земли до других объектов: _"Сколько от Земли до Марса?"_, _"Сколько от Земли до Луны?"_, _"Сколько от Земли до Юпитера?"_ и так далее. Каждый раз мы вводим запрос в Google и сообщаем ответ. На это уходит около минуты. Но представим, что каждый раз племянница задает только один вопрос: _"Сколько километров от Земли до Луны?"_. Довольно скоро мы запомним, что Луна находится на расстоянии  384 400 километров от Земли. Искать информацию в Google теперь не нужно, мы сразу сообщаем племяннице запомненную нами цифру. 

Возвращаемся к примеру с соцсетью. 
Если мы авторизовались и вошли на свою страницу, то серверу необходимо подготовить для нас персонифицированные динамические данные, наподобие заявок в друзья, которые поступили за время нашего отсутствия в соцсети. 

Но если мы зашли на главную страницу сервиса без авторизации, то увидим страницу входа. Все пользователи, кто не прошел регистрацию или авторизацию видят одну и ту же страницу. 

Сервер перестает выполнять __ненужную__ работу и генерировать домашнюю страницу снова и снова. Вместо этого он __запоминает__, как выглядит домашняя страница и отправляет ее всем неавторизованным пользователям.

Такой механизм хранения называтеся __Кэшированием__. Он обладает двумя преимуществами:

1. Пользователь получает закешированную веб-страницу намного быстрее, как и в случае, когда мы запомнили расстояние от Земли до Луны. 
2. Серверам соцсети приходится выполнять меньше работы.

Кэширирование - стандартный способ ускорения работы. Его используют все крупные веб-сайты. 
А кэшированные данные храняться в хеше!!

Кэшируюется не только страница входа, но и страницы типа _О нас_, _Контакты_ и так далее. А связь между кэшированной страницей и ее веб-адресом устанавливается с помощью хеша. 

Когда мы посещаем какую-либо страницу, сервер сайта сначала проверяет, не хранится ли она в кэше. Если да - данные приходят из кэша. Если нет - сайт генерирует страницу персонально для пользователя. 

#### Коллизии

В большинстве языков программирования существует собственная реализация хеш-таблиц. Нам врядли придется писать собственную реализацию, от чего нет особой нужды досконально разбираться в нюансах создания хеш-таблиц. 

Нам необходимо быстродействие. А чтобы воспользоваться всеми преимуществами предоставляемых хеш-таблиц осознанно, нужно понимать, что такое __коллизии__.

Прежде всего разберемся с утверждением, что хеш-функция предоставляет __разные ключи__ для __разных значений__ (строк).

На самом деле реализовать такую хеш-функцию почти невозможно.

Рассмотрим пример: Пусть доступный нам массив состоит из 33 ячеек. 

И хеш-функция очень простая: ячейки распределяются в алфавитном порядке. Строка на А получит нулевую ячейку, строка на Я получит последннюю ячейку.

Сначала мы хотим сохранить цену на апельсины. Апельсины начинаются на А, поэтому для их цены будет выделена первая ячейка. Потом мы захотим записать цену бананов - для этого будет выделена вторая ячейка. Пока все прекрасно!

Но вот нам нужно внести цену Авокадо. Авокадо тоже на А, а значит наша хеш-функция выделит первую ячейку. Но ячейка уже занята ценой на Апельсины!

Такая ситуация называется __коллизией__: _двум ключам назначен один элемент массива_. 

Чтобы не потерять данные из ячейки, существует ряд стратегий разрешения коллизий. Самый простой выглядит так: _При возникновении __коллизии__ (когда __несколько__ ключей отображаются на __один__ элемент) внутри этого элемента создается связанный список_.

В нашем примере и Апельсины, и Авокадо отображаются на один элемент _(нулевой элемент массива)_, поэтому внутри этого элемента создается связанный список.

Теперь, если нам необходимо узнать цену бананов, работа выполниться привычно быстро. Но если необходимо узнать цену апельсинов - будет некоторая задержка, так как нам необходимо провести поиск по связанному списку, чтобы найти интересующий элемент. Если список мал, например ограничен тремя-четырьмя элементами - это не страшно, задержка будет минимальной. Но если у нас магазин товаров на А, то все они окажутся в нулевом элементе массива, а значит все попадут в связанный список. А значит мы потеряем преимущество хеш-таблицы с ее номинальной скоростью доступа в $O(1)$ и получим последовательный доступ с $O(n)$. 

Из этого примера следуют два урока:
* _Выбор хеш-функции действительно важен_. Хеш-функция, отображающая все ключи на один элемент никуда не годится. В идеале хеш-функция должна распределять ключи равномерно по всему хешу.
* Если связанные списки становятся слишком длинными, работа с хеш-таблицей сильно замедляется. Но они не станут слишком длинными при использовании хорошей хеш-функции. 

Хеш-функции играют важную роль. Хорошая хеш-функция минимизирует возникновение коллизий. 

#### Быстродействие

В среднем хеш-таблицы выполняют любые операции за время $O(1)$. Такое время называется __постоянным__. Это не значит, что операции выполняются __мгновенно__, просто время не меняется в зависимости от __размера хеша__. 

Итак
* В __среднем случае__ операции с хеш-таблицами выполняются за __постоянное__ время $O(1)$
* В __худшем случае__ операции с хеш-таблицами выполняются за __линейное__ время $O(n)$

При поиске элемента хеш-таблицы не уступают в скорости массивам. А при вставке или удалении сопоставимы со связанными списками. Но в худшем случае хеш-таблицы очень медленно выполняют все эти операции, поэтому так важно избегать коллизий, когда мы используем хеш-таблицы. 

Для предотвращения коллизий необходимы:
* Низкий коэффициент заполнения 
* хорошая хеш-функция

##### Коэффициент заполнения

Коэффициент заполнени хеш-таблицы вычисляется по формуле:

$$
\frac{\text{количество элементов в хеш-таблице}}{\text{общее количество элементов}}
$$

Хеш-таблицы используют массив для хранения данных, поэтому для вычисления коэффициента можно подсчитать количество заполненных элементов в массиве.

Например, у нас массив из 5 элементов. Хеш-функция заполнила 2 элемента. Чтобы подсчитать коэффициент нам необходимо _количество занятых данными элеметов_ разделить на _общее количество элементов_, а значит получаем:

$$
\text{коэффициент заполнения} = \dfrac{2}{5} = 0,4 = 40\%
$$

Допустим, у нас есть 100 элементов и хеш-таблица размером 100 позиций. В идеале, если мы сохраним отдельный элемент в отдельной ячейке, то получим __коэффициент заполнения__ равный 1.

А если у нас 200 элементов? тогда коэффициент заполнения будет равен 2. 

Коэффициент заполнения больше 1 означает, что количество элементов для заполнения хеш-таблицы превышает размерность массива.

С ростом значения коэффициента заполнения хеш-таблицы используемый ею массив необходимо _расширить_. Представим, что коэффициент заполнения приближается к 1. Расширение будет заключаться в создании нового массива, который, зачастую, в 2 раза больше предыдущего.

Перенесем старые элементы в новый массив и получим более низкий коэффициент заполнения. 

Обычно, правило гласит: _Создавать новый увеличенный массив следует когда коэффициент заполнения приближается к 0,7_.

Но ведь изменение размеров требует времени! Да, это так, поэтому оно не должно происходить слишком часто. Но даже с учетом периодически происходящих изменений размера исходного массива время работы хеш-таблицы все равно составляет $O(1)$.

##### Хорошая хеш-функция

Хорошая хеш-функция должна обеспечивать равномерное распределение элементов в массиве.

Плохая хеш-функция создает скопления и порождаем множественные коллизии.

Как пример хорошей хеш-функции автор предлагает рассмотреть функцию CityHash, которая используется в том числе и в Google.  

Немножко поговорим про нее.
CityHash - это крепкая, "боевая", промышленная разработка. Это семейство очень быстрых хеш-функций, созданных в Google около 2011 года. Она предназначена для __строк__ и __бинарных данных__, чтобы быстро получать хеш фиксированной длинны (например, 64 бит). 

Google работает с огромным объемом текстовой информации: поисковый индекс, веб-страницы, документы. 
Для таких данных нужно очень быстро считать хеш строки (так как строк - миллиарды). Да еще и хеш должен быть очень качественным, тоесть: равномерно распределять строки по числовому диапазону, минимизировать коллизии, хорошо работать на строках разной длинны.

Общий принцип работы CityHash заключается в том, что функция берет строку, разбивает ее на блоки (обычно по 16 байт). Каждый блок "смешивается" с помощью арифметики (сложения, побитовые сдвиги, умножения на специальные константы). В конце все результаты схлопываются в единое число фиксированной длинны (16, 32, 128 бит).

__Главная идея__ всего этого процесса в том, чтобы обеспечить максимальную __чувствительность__ исходных данных, когда даже перемена одного символа в исходной информации приведет к сильному изменению итогового результата (_так называемое __свойство лавины___)

Чем хорош CityHash? Он очень быстро работает, так как заточен под современные процессоры. Имеет высокое качество распределения, что обеспечивает малый процент коллизий. 


###### ИТОГИ:

Хеш - функция работает с массивам. Она знает его размер. Получая строки, она преобразует их в индексы для этого массива, записывает значения в массив по этим индексам. 

Похожим образом в JS реализованы Объекты. Когда мы передаем в них новое свойство в формате __ключ - значение__, запускается хеш функция.  Она берет строковые ключи и преобразует их в индексы массива. По этим индексам в массив записываются __значения__. Это позволяет обращаться к свойствам объектов со скоростью $O(1)$, что сопоставимо со скоростью доступа к элементам массива. Произвольный доступ во всей красе. 

Но мы знаем, что у нас всегда есть возможность получить все ключи свойств объекта. Что же получается, хеш - функция берет индексы и преобразует их обратно в строки? Вовсе нет, хеш - функция однонаправлена, она так не умеет. Но решение простое: каждый элемент массива хранит не только __значение__ свойства, но и его __ключ__, в строковом формате. Это позволяет при необходимости пройтись по всем подряд свойствам объекта, собрать из них названия ключей и вывесть их. Да, так как это итеративный подход то скорость такой операции скорее сторит оценивать как $O(n)$, но операция не частая и это приемлемо. 


### Поиск в ширину

Эта глава посвящена __графам__.

__Поиск в ширину__ - это алгоритм, работающий с графами.

Поиск в ширину позволяет найти _кратчайшее расстояние_ между двумя объектами. Однако сам термин _кратчайшее расстояние_ может иметь несколько разных значений. 

С помощью поиска в ширину можно:

* Реализовать проверку правописания (минимальное количество изменений, преобразующих ошибочное написание слова в правильное). 
* Найти ближайшего врача
* Создать поискового робота

#### Знакомство с графами

Допустим, мы находимся в городе А и хотим добраться в город Н. Прямого маршрута между городами нет, поэтому нам придется совершать пересадки в других городах. Наша задача - минимизировать количество пересадок, чтобы наш маршрут был более комфортным.

Простейший вопрос, которым мы можем задаться в данном случае: можно ли добраться до город Н за 1 шаг? Очевидный ответ нет, потому что мы знаем, что прямого маршрута между городами нет.

_Но мы можем обозначить ближайшие точки пересадок, до которых можно добраться за 1 шаг, наметив таким образом основные направления, по которым может быть построен оптимальный маршрут._

Следующий вопрос: можно ли добраться до города Н за 2 шага? Основные линии нами уже намечены, попробуем пройти по каждой из них на 2 шага с целью узнать, не приведет ли один из путей в пункт назначения.

_И в этот раз, допустим, неудача. Ни один из марщрутов, подразаумувающийх пересадку (тоесть состоящий из двух шагов) не привел нас к цели. _

Следующий вопрос (как мы уже догадались): нельзя ли добраться за 3 шага?

_Наши действия просты: берем все имеющиеся сформированные маршруты и к каждому добавляем еще одну пересадку. Ура! один из маршрутов теперь ведет прямо в город Н. Это и будет наш приоритетный маршрут. _

Для нахождения ответа мы __смоделировали задачу в виде графа__ и воспользовались __поиском в ширину__. 

#### Что такое граф?

$$
\text{Граф моделирует набор связей}
$$

Допустим, мы играем с друзьями и хотим смоделировать, кто кому сейчас должен.

Например, Роман должен Петру

$$\text{Роман}\to\text{Петр}$$

Можно создавать и более сложные связи, где некоторые участники условно должны нескольким игрокам а значит от них идет нексолько стрелок к разным участникам. 

Каждый граф состоит из __узлов__ и __ребер__

Точка, от которой или к которой идут стрелки - это __узел__.
Сама стрелка - это __ребро__.

Узел может быть напрямую соединен с несколькими другими узлами.

Эти узлы называются __внутренними__ или __внешними__ соседями.

Что значат термини __внутренний сосед__ и __внешний сосед__?

Если связь (ребро) идет в направлении __от__ Романа __к__ Петру, то Роман - __внутренний__ сосед Петра. А Петр - __внешний__ сосед Романа. 

Не забываем, что наши ребра имеют направление, они являются стрелками. Если представить, что стрелка всегда указывает __во внешнюю сторону__, то логика становится понятна: стрелка условно, в каждом отдельном случае, когда мы говорим о каких-то двух конкретных соединенных ребром узлах, идет __от__ одного __к__ другому. От __внутреннего__ соседа $\to$ __ко__ внешнему. 

Но если два узла не связаны непосредственно, с помощью _одного_ ребра (стрелки), то гороворить об их соседстве не приходится. 

Вот так графы используются для моделирования связей между разными объектами - с помощью стрелок между ними.

#### Поиск в ширину

Мы уже рассматривали один вид поиска - _Бинарный поиск_.

_Поиск в ширину_ также относится к категории алгоритмов поиска, но работает с графами.

Он помогает ответить на вопросы 2 типов: 
* Существует ли __путь__ от узла А к узлу Б?
* Как выглядит __кратчайший__ путь от узла А к узлу Б?

Наша задача про города А и Н ставила вопрос второго типа: каков кратчайший путь. 

Разберемся, как алгоритм отвечает на вопрос первого типа, существует ли путь вообще.

Представим, что мы выращиваем огурцы. Мы ищем продавца, который будет продавать наши замечательные огруцы. 

Может быть, продавец найдется среди наших контактов в соцсети?

Для начала поищем среди друзей.

Составим список друзей, чтобы понимать, к кому будем обращаться. Далее зададим вопрос каждому человеку в списке: Ты тогруешь огурцами? Если __ДА__ - завершаем поиск, мы нашли продавца, причем первого, кто ответил утвердительно. Если первый ответил __НЕТ__ - спрашиваем у второго, третьего и так далее. Если последний друг из нашего списка ответил __НЕТ__ - значит никто из нашего ближнего круга не подошел. 

Теперь будем проводить поиск среди друзей наших друзей.

Логика такая: если первый друг ответил нет, то прежде, чем перейти ко второму другу мы в конец списка добавим _друзей первого друга_. Таким образом, если среди _наших_ друзей продавца не нашлось, то после опроса последнего _нашего_ друга из списка мы перейдем к опросу друзей _первого друга_, затем _второго друга_ и так далее. 

Теперь ответ __НЕТ__ приводит не просто к переходу к следующему члену списка, а вначале добавляет его друзей в конец нашего списка. 

Таким образом, если нам не удается быстро найти продавца, со временем мы проверим друзей наших друзей, а потом их друзей и так далее.

С этим алгоритмом рано или поздно мы пройдем по всей сети, пока наконец не наткнемся на продавца огурцов.

Такой алгоритм и называется _Поиском в ширину_.

Итак, мы нашли продавца для наших огурцов. Это был вопрос первого типа. Теперь ответим на вопрос второго типа: каков наикратчайший путь до этого продавца. 

Будем считать, что наши друзья - это __связи первого уровня__. Мы можем провести стрелочку, означающую дружеские отношения, от себя до каждого такого человека. Друзья наших друзей - это __связи второго уровня__ - не лично знакомые нам люди, но те, связаться с кем мы можем через одного посредника (в лице нашего друга).

Исходя из этого, можем выстроить нехитрую логику: связи первого уровня __предпочтительнее__ связей второго уровня. Связи второго уровня __предпочтительнее__ связей третьего уровня и т.д. - чем меньше посредников - тем лучше.

Отсюда следует, что поиск по контактам __второго__ уровня не должен производиться, пока мы не опросим все контакты __первого__ уровня - наших непосредственных друзей. 

Да, если мы берем аналогию со списком - на первых порах преимущества _Поиска в ширину_ могут быть не так очевидны. Ведь список - это линия имен сверху вниз. И не совсем ясна принципиальная разница между последним другом и первым другом первого друга, ведь они идут в списке один за другим. 

Но представим, что мы расположили друзей по кругу, вокруг себя. И проверка - это словно движение стрелки по циферблату - стрелка движется по малому кругу, по связям __первого уровня__. А потом ей надо пройти по воторому кругу - по связям __второго уровня__. Этот круг явно шире, в нем больше элементов, а так как мы задаем __каждому__ элементу один и тот же вопрос, то стрелка по любому _внешнему_ кругу будет проходить дольше, чем по предыдущему _внутреннему_.

Но говоря о компьютерах, конечно наиболее приближенной к реальной будет аналогия со списком. Поэтому и существует четкое правило: Друзья проверяемого объекта всегда добавляются в __конец__ списка, что гарантирует, что поиск не перейдет на объекты _нового_ уровня пока не будут проверены все объекты _текущего_, ведь мы проверяем сверху вниз по списку.

Поэтому _Поиск в ширину_ находит не только сам факт наличия продавца огруцов, но еще и всегда _ближайшего_ к нам продавца. 

Для описанных нами операций существует специальная структура данных, которая называется __очередью__.

#### Очереди

Компьютерные очерди работают очень похоже на то, что мы видим в реальной жизни. 

Допустим, мы с другом стоим на автобусной остановке в очереди. Если мы стоим ближе к началу, а друг за нами, это значит, что в автобус первыми сядем мы.

Структура данных очереди работает аналогично. 

Очереди чем-то похожи на _стеки_ - мы не можем обращаться к произвольным элементам очереди. Вместо этого поддерживаются 2 операции: __постановка в очередь__ и __извлечение из очереди__. 

Если мы поставили в очередь 2 элемента, то элемент, поставленный _первым_ будет извлечен из очереди _раньше_ второго. И это свойство можно использовать для реализации __списка поиска__. 

Наши "друзья", добавленные в список очереди __первыми__ будут извлечены из него и проверены (на предмет торговли огурцами) __первыми__. 

Очередь относится к категории структур данных __FIFO__: _First In First Out_ (Первым пришел, первым ушел).

А стек принадлежит к числу структур данных __LIFO__: _Last In First Out_ (Последним пришел - первым ушел).

#### Реализация графа

Для начала необходимо реализовать граф на программном уровне.

Граф состоит из нескольких _узлов_, и каждый узел соединяется с _соседними_ узлами. 

Как выразить отношение $\text{Я}\to\text{Яков}$ ?

Для этого понадобится структура данных, которая выражает отношения между элементами: __хеш-таблица__.

Хеш-таблица связывает ключ со значением. В данном случае узел должен быть связан со всеми его внешними соседями.

```js
// объект как отличная встроенная
// реализаця хеш-таблиц
const graph = {};

// свойству, выражающему нас
// присвоен массив наших друзей
graph["вы"] = ["Алиса", "Боб", "Клэр"];
```
Элемент "вы" __отображается__ на массив наших друзей.

Наши друзья теперь - это наши __внешние соседи__. 

Тут стоит немного отвлечься и пояснить приведенный выше код. 

Все время, что мы говорили о графах, у нас был "Слон в комнате": мы говорили о структуре, очень легко представимой графически. Рисуем кружок в центре листа, подписываем его "вы", от него как лучи солнца или спицы колеса, во все стороны рисуем линии. На противоположном конце каждой линии рисуем кружок и пишем в кружках: "Алиса", "Боб", "Клэр". Вот мы изобразили связи __первого уровня__, __соседей__, получился полноценный граф. Далее мы с легкостью можем от каждого нового куржка проводить линии, чтобы окончить их другими кружками, где укажем друзей для "Алисы", "Боба", "Клэр". 

Но дело в том, что наша программа не поймет графическое изображение, нарисованную схему. Нам нужно найти такой способ отображения данных, который будет понятен компьютеру. Мы используем граф для передачи данных о структуре связей в системе друзей и их друзей. А значит нам нужен способ __представления графа__ для компьютера. Тоесть нам нужна структура данных, которая поможет компьютеру оперировать графом так же непринужденно, как и нам, пользующимся листком с рисунком.

Есть несколько проверенных способов __представления графа__. Его можно передать в виде __матрицы смежности__, где 1 - факт наличия связи, 0 - факт отсутствия связи между элементами

```
   A B C
A [0 1 1]
B [1 0 0]
C [1 0 0]
```
Можно представить в виде __списка ребер__, где мы просто составляем список всех ребер в графе, а ребро - это два узла, между которыми оно проходит:

```
[
  ["A", "B"],
  ["A", "C"],
  ["B", "D"]
]
```
_Это очень простая структура, удобно хранить граф как сырые данные, но неудобно искать соседей - приходится проходиться по всему списку_

Третий способ это __список смежности__: 
* Каждой вершине соответсвует список ее соседей
* Реализуется через объект (хеш-таблицу) или массив списков. 

Плюсы: экономит память, легко итерироваться по соседям. 
Минусы: не так удобно быстро проверить, есть ли связь между двумя вершинами - нужно проходиться по списку соседей. 

Так какое же представление графа предлагает нам автор в этой теме?

```js
graph["вы"] = ["Алиса", "Боб", "Клэр"];
```

Вершина и список ее соседей, это __список смежности__. 

Почему его? Скорее всего из-за специфики _Поиска в ширину_. Нам важно быстро обращаться к узлу и легко получать полный список его соседей. Для списка смежности это занимает $O(1)$ времени вне зависимости от количества объектов. И плюс нам легко строить побход по _уровням связи_. Выбрав ключевой объект сразу получаем список его _соседей_, а пока обходим их добавляем соседей соседей в конец списка проверки, формируя основу для проверки _связей второго уровня_, если она понадобится. Так мы "идем концентрически", как-бы кругами от исходной точки.

Возвращаемся к книге.
Результатом кода 

```js
const graph = {};
graph["вы"] = ["Алиса", "Боб", "Клэр"];
```

является то, что теперь, стоит нам вызвать 

```js
graph["вы"];
```

мы сразу же получим массив всех наших __внешних соседей__ _(тоесть узлов, к которым обращается ( $\to$ ) узел "вы")_.

Это довольно простая схема, и выражена она довольно простым кодом.

Но что, если мы имеем дело со схемой посложнее: где есть уже _связи второго уровня_ и один и тот же элемент может иметь иметь несколько __внутренних соседей__? (Имеем в виду, что у __наших__ друзей Боба и Алисы есть __общая__ подруга Пэгги, тоесть: $\text{вы}\to\text{Боб}\to\text{Пэгги}$ и в то же время $\text{вы}\to\text{Алиса}\to\text{Пэгги}$).

Приведем пример __списка смежности__, который моделирует эту более сложную структуру. (А мы в свою очередь можем попробовать зарисовать ее на бумаге и убедиться, что список смежност довольно точно передает сущность графа):

Важное замечание! При составлении списка смежности, который отражает связи для всех элементов графа, мы должны для __каждого__ элемента (каждого __узла__) создать __отдельное__, персональное свойство в объекте $\text{graph}$, даже если у этого узла нет внешних соседей. Тогда этому свойству-узлу в качестве значения будет передан пустой массив.

```js
// Список смежность для графа
// более сложной структуры
graph = {};
graph["вы"] = ["Алиса", "Боб", "Клэр"];
graph["Боб"] = ["Анудж", "Пегги"];
graph["Алиса"] = ["Пегги"];
graph["Клэр"] = ["Том", "Джонни"];
graph["Анудж"] = [];
graph["Пегги"] = [];
graph["Том"] = [];
graph["Джонни"] = [];
```

Мы можем обратить внимание на то, что друзья для узла "вы" перечислены в порядке "Алиса", "Боб", "Клэр". А вот в список смежности они в качестве свойств-узлов попадают в порядке "Боб", "Алиса", "Клэр". Это критично?

Чтобы ответить на этот вопрос, нужно вспомнить, почему мы вообще используем объект как основу для нашего графа. А все потому, что объект - это готовая, предоставляемая языком реализация хеш-таблицы. Значит вопрос можно переформулировать так: для __хеш-таблицы__ приципиально, в каком __порядке__ в нее добавляются элемены? А для этого надо вспомнить, что хеш-таблица для хранения данных использует массив. И то, как в массиве расположатся элементы зависит не от нас, а от реализации хеш-функции, которая управляет этим процессом, элементы в хеш-таблице __не упорядоченны__. Иначе говоря, если мы не имеем контроля над тем, как заполняется хеш-таблица, стоит ли нам заботиться о порядке, в котором мы передаем элементы для ее заполнения? С учетом того, что доступ к любому добавленному элементу осуществляется за $O(1)$ вне зависимость порядка, в котором он был добавлен, запись

```js
graph["вы"] = ["Алиса", "Боб", "Клэр"];
graph["Боб"] = ["Анудж", "Пегги"];
graph["Алиса"] = ["Пегги"];
graph["Клэр"] = ["Том", "Джонни"];
```
и запись

```js
graph["вы"] = ["Алиса", "Боб", "Клэр"];
graph["Алиса"] = ["Пегги"];
graph["Боб"] = ["Анудж", "Пегги"];
graph["Клэр"] = ["Том", "Джонни"];
```
эквивалентны в вопросе эффективности работы итогового __списка смежности__ (хеш-таблицы).

Еще одно особенностью нашего графа является наличие элементов вида

```js
graph["Анудж"] = [];
graph["Пегги"] = [];
graph["Том"] = [];
graph["Джонни"] = [];
```
У них есть внутренние соседи (те, что направляют стрелки от себя к этим элементам), но нет внешних соседей (от перечисленных элементов не отходят стрелки). 

Следовательно, мы имеем дело с __направленным__ графом: отношение действует в __одну__ сторону (от чего-то к чемуто). 

В __ненаправленном__ графе стрелок нет, есть просто ребро, соединяющее 2 узла. Такое ребро можно рассматривать как стрелку, направленную в обоих направлениях

$$
\text{Росс} \longleftrightarrow \text{Рейчел}
$$

В __ненаправленных__ графах не существует деления соседей на _внутренних_ и _внешних_: два соединенных ребром узла просто _соседи_.

#### Реализация алгоритма

Этапы нашего алгоритма:
1. Создать _очередь_ с именами проверяемых людей
$$\text{НАЧАЛО ЦИКЛА}$$
2. Если очередь не пуста: Извлечь из очереди очередного человека
3. Проверить, является ли этот человек продавцом огурцов
    - 3а. Если ДА: Вернуть имя этого человека, завершить выполнение кода
    - 3b. Елси НЕТ: Добавить всех соседей этого человека в очередь
4. Перейти к шагу 2.
$$\text{КОНЕЦ ЦИКЛА}$$
5. Если очередь пуста, в нашем графе нет торговца огруцами

Итак. Автор приступает к реализации плана. Создавая _очередь_, он обращается ко встроенной в python реализации очередей. JS не может похвастаться наличием встроенных очередей. 
Поэтому в данном случае нам придется использовать обычный _массив_, и обратиться к его методам, имитирующим поведение FIFO. А именно $.shift()$, чтобы извлекать элементы из начала массива, и $.push()$ - чтобы добавлять элементы в конец массива. 

Так же заметим, что автор использует двустороннюю очередь, но
* Для задач _Поиска в ширину_ нам хватит и имитации обычной очереди
* Ничто не мешает нам пользоваться набором методов push, pop, shift, unshift, если мы захотим полностью имитировать логику работы двусторонней очереди (но, к сожалению, не ее скорость работы).

Да, массив - это не идеальная структура данных для имитации _очереди_ из-за того, что операция удаления элемента из начала $.shift()$ приводит к последующей переиндексации каждого элемента массива, а значит время ее выполнения $O(n)$. 

Можно постараться и написать реализацию своей структуры данных на основе связанного списка, либо воспользоваться готовой библиотекой, но пока нам это не нужно. 

Вернемся к реализации алгоритма _Поиска в ширину_

```js
// Создадим массив
// в качестве имитации очереди
const searchQueue = [];

// Заполним массив именами
// первого уровня связи с "вы"
searchQueue.push(...graph["вы"]);
```

Теперь у нас есть список связей первого уровня, среди элементов которого нам предстоит вести поиск продавца.

```js
// Создадим функцию поиска продавца
function findSeller(queue) {

  // Пока список проверяемых людей не пуст
  while (queue.length > 0) {
    // Извлечем первого человека из списка
    let person = queue.shift();

    // передадим его на проверку в функцию
    // которая определяет продавца по имени
    if (checkIsSeller(person)) {
      console.log(`${person} торгует огурцами!`);
      return;
    } else {
      // если не продавец 
      // добавим его друзей (внешних соседей)
      // в конец списка проверяемых
      queue.push(...graph[person]);
    }
  }

  // если выполнение дошло сюда 
  // значит в графе нет торговца
  console.log("Торговец не найден");
  return;
};
```

Теперь набросаем функцию, которая будет проверять, является ли человек продовцом, исходя из последней буквы его имени. Если она "м" - значит он продавец и функция вернет $true$. Просто и без излишеств. 

```js
// функция определения торговца по имени
function checkIsSeller(name) {
  return name.endsWith("м");
}
```

Теперь посмотрим, как работает функция.

Мы создали массив, нашу условную очередь, и заполнили ее первым списком имен - тем списком, который вернул нам наш граф, когда мы попросили его показать все связи узла "вы". Тоесть нам вернулся массив всех соседей, всех связей первого уровня элемента "вы". 

То что надо для поиска в ширину! Сначала ведем поиск среди элементов первого уровня, внешних соседей начального элемента. А __список смежности__ как раз хранит и предоставляет такой список для каждого узла графа! Идеально.

Передаем наш список в функцию поиска продавца в графе.

Так как преданный нами список не пуст (очередь не пуста), то выполняется условие

```js
 while (queue.length > 0)
```
и начинается ЦИКЛ, который мы отмечали на нашей схеме.

__Первое__ имя нашего списка _извлекается_ из массива (очереди, мы тут FIFO имитируем) и записывается в переменную $person$. Теперь наш исходный список __меньше__ на 1 элемент, обработка элементов _связи первого уровня_ началась. 

```js
 let person = queue.shift();
```

Первым узлом для проверки у нас будет Алиса, так как

```js
graph["вы"] = ["Алиса", ... 
```

Далее мы создаем условную логику, в которой, если нам попался продавец - цель достигнута, сообщим об этом (пункт схемы 4a).
Если человек не прошел проверку на продавца - обратимся к списку __его__ связей первого уровня, его внешних соседей $graph(person)$. Эти имена понадобятся нам - они начнут формировать часть списка проверки, покрывающую связи второго уровня __относительно "мы"__. (связи первого уровня нашего друга для нас будут связями второго уровня)

```js
if (checkIsSeller(person)) {
      console.log(`${person} торгует огурцами!`);
      return;
    } else {
      // если не продавец 
      // добавим его друзей (внешних соседей)
      // в конец списка проверяемых
      queue.push(...graph[person]);
    }
```
Алиса не проходит проверку на продавца, ее друзья отправляются в конец списка проверяемых. 

Код в теле нашего цикла подошел к концу, а значит пора циклу проверить свое условие. Список проверяемых не пуст. Извлекаем следующий первый элемент нашего списка, и им будет Боб. 
Для Боба все повторяется по аналогии с Алисой: Его имя удаляется из начала списка, он тоже не проходит проверку, все его соседи-друзья отправляются в список для проверки, прямо за друзьями Алисы. Для Клэр все происходит так же. 

Все, наши непосредственные друзья-соседи проверены, среди связей первого уровня нет торговца. 

Но список не пуст - из него пропали наши друзья, но теперь он заполнен всеми связями второго уровня. 

А значит цикл продолжит проверку по связям второго уровня. 

И поиск будет идти, пока не доберется до друга нашей подруги Клэр, Тома. Имя Тома пройдет проверку на продавца, потому что оно заканчивается на "м", а значит торговец найден. 

У Алисы и Боба есть один общий друг - Пегги. 

Следовательно, Пегги будет добавлена в список дважды: при добавлении друзей Алисы и при добавлении друзей Боба. 

В результате Пегги появится в очереди поиска в двух экземплярах. Но проверить, является ли Пегги продавцом, достаточно всего _один раз_. Проверяя ее дважды мы выполняем ненужную, лишнюю работу. Следовательно, после проверки человека нужно пометить как _уже проверенного_. 

Если этого не делать, может возникнуть бесконечный цикл. 

Предположим, что у нас есть граф, который выглядит так

$$
\text{вы} \longleftrightarrow \text{Пегги}
$$

_Да, это тот самый __ненаправленный__ граф, где нет внешних\внутренних соседей и два соединенных ребром узла являются просто соседями_.

В начале работы с этим графом очередь поиска содержит всех нашиших соседей

Очередь поиска: ["Пегги"];

Теперь мы проверяем Пегги. Она удаляется из очереди поиска, очередь пока пуста. Она не является продавцом, а значит в конец очереди поиска добавляются ее соседи, а это "вы".

Очередь поиска: ["вы"];

Теперь мы проверяем себя. "вы" удаляется из очереди поиска, очередь пока пуста. Мы не являемся продавцом, а значит в конец очереди поиска добавляются наши соседи, а это Пегги. 

Очередь поиска: ["Пегги"];

Так. Где-то мы уже видели такую очередь поиска. 

Возникает __бесконечный цикл__, потому что очередь поиска будет бесконечно переходить от "вы" к "Пегги". 

А значит, прежде, чем проверять человека, следует убедиться в том, что ранее он не был проверен. Для этого мы будем вести _список уже проверенных_ людей. 

Наш код не содержит такой модификации, но при этом он не приводит к появлению бесконечных циклов, потому что: у нас __направленный__ граф, и соединенные ребром узлы не появляются в списке соседей друг у друга; у Пегги в нашем графе есть 2 внутренних соседа, но нет ситуации, которая приводила бы к возникновению цикла (например: $\text{"вы"} \longrightarrow \text{"Алиса"} \longrightarrow \text{"Пегги"} \longrightarrow \text{"вы"}$ ).

И все же хорошим тоном было бы добавить в наш код такую проверку. Для этого создадим отдельный __список__, который будет хранить имена проверенных людей, и перед тем, как отправлять имя на проверку, будем уточнять, не встречается ли оно в этом __списке__. 

```js
function findSeller(queue) {
  while (queue.length > 0) {
    let person = queue.shift();

    // заведем список уже проверенных
    const searched = new Set();

    // сначала проконтролируем, не проверяли ли мы
    // уже этого человека. 
    if (!searched.has(person)) {

      if (checkIsSeller(person)) {
        console.log(`${person} торгует огурцами!`);
        return;
      } else {
        queue.push(...graph[person]);
      }
    }
  }
  console.log("Торговец не найден");
  return;
};
```

Да, эта проверка не избавляет нас от того, что один и тот же человек окажется в списке проверяемых несколько раз, но мы хотя бы не будем проверять его все эти разы. 

#### Время выполнения

Если поиск продавца выполнен по всей сети, значит мы прошли __по каждому ребру__. Таким образом, время выполнения составляет $O(\text{количество ребер})$. 

Также в программе должна храниться очередь поиска. Добавление одного человека в очередь выполняется за постоянное время $O(1)$. Выполнение операции для каждого человека потребует суммарного времени $O(\text{количество людей})$. 

Таким образом, поиск в ширину выполняется за время 
$$O(\text{количество людей} + \text{количество ребер})$$

Что обычно записывается в форме:

$$
O(V+E)
$$
Где $V$ - количество вершин, $E$ - количество ребер. 

Рассмотрим этот вопрос немного подробнее. 
Итак, мы берем граф и запускаем для него _Поиск в ширину_

Для начала мы берем стартовую вершину, стартовый узел, и кладем в очередь проверки все вершины-соседи (если граф направленный, как в рассмотренном нами случае, то всех внешних соседей стартового узла).

Пока очередь не пуста, мы извлекаем по одному узлу из очереди и добавляем в конец очереди всех соседей этого узла (если он не прошел проверку). 

Да, возможна ситуация, когда у одного узла есть несколько внешних соседей (опять же, мы говорим про направленный гарф). А значит такой узел может попасть в очередь несколько раз. Именно на этот случай мы реализовали список уже проверенных узлов - он помогает нам __не проверять__ один и тот же узел несколько раз, даже если он неоднократно дублирован в очереди проверки. 

Таким образом, если мы зададим вопрос так: сколько раз __каждый__ узел графа будет __проверен__ мы можем с уверенностью сказать: Не более одного раза. А значит время, затраченное на проверку узлов графа при _Поиске в ширину_ составит $O(V)$, где $V$ - количество вершин. 

Следующий вопрос: сколько раз мы обработаем ребра графа? Уточним, что значит обработать ребро графа в контексте нашего алгоритма _Поиска в ширину_: это значит обратиться к свойству-узлу внутри объекта и внести в очередь проверки всех указанных для этого узла в массиве соседей. Потому что то, что графически ребра, стрелки - у нас представлено в виде массива связанных с узлом соседей. 

Именно поэтому, когда узел имеет нескольких внутренних соседей, мы говорим: этот узел встречается в массиве, перечисляющем внешних соседей, у __нескольких__ узлов. Это значит, что на этом узле сходятся несколько ребер __от__ его внутренних соседей. Обработать ребро - значит внести узел из массива в _очередь_ проверки. И каждое такое ребро __будет обработано__, в результате чего узел окажется дублирован в очереди проверки (но саму проверку проходить не будет, от этого мы защитились). 

Следовательно, говоря о том, __сколько времени займет обработка ребер графа__ мы можем уверенно заявить: каждое ребро будет гарантированно обработано один раз, значит время обработки ребер графа составит $O(\text{количество ребер графа})$, что равно $O(E)$.

Ну а суммировав __обработку ребер__ и __проверку вершин__ мы и получим $O(V+E)$

Вопрос на звездочку: а в __ненаправленном графе__ какое время выполнения алгоритма?

Узлов в очередь попадер очевидно больше, так как каждый узел получает в массив __всех__ своих соседей, а значит дублирование тут - систематическая практрика. Но список провренных узлов все так же обеспечивает нам тот факт, что каждый узел будет проверен только один раз. Время так же $O(V)$.

А ребер у нас стало в 2 раза больше, потому что одно ребро в контексте нашей реализации графа в виде списка смежности можно рассматривать как 2 ребра: в одну и в противоположную сторону. Таким образом, время обработки ребер стало $O(2E)$.

Общее время стало $O(V) + O(2E) = O(V+2E) = O(V + E)$

Почему? Потому что коэфициенты мы отбрасываем. 

Почему? Потому что нам важна __форма графика__, описывающего динамику изменения времени выполнения от объема входных данных. А коэфициент может растягивать или сжимать график, но не изменять принципиально его форму. Но это в теории. На практике мы учитываем все факторы, которые имеют важный вес. Если коэфициент значительно изменит картину - мы будем его учитывать. 

В завершение темы автор приводит пример генеалогического древа: на вершине мы, под нами родители, под каждым родителем их родители и так далее. 

Генеалогическое древо - это тоже граф. В нем есть узлы и ребра. 
Ребра указывают на родителей человека. Естественно, все ребра направлены вниз, так как направленное вверх ребро не имеет смысла: дочь не может быть матерью своей матери. 

Такая особая разновидность графа, в котором нет ребер, указыающих в обратном направлении, называется __деревом__. 

### Деревья

Что общего у алгоритмов сжатия и алгоритмов хранения информации в базе данных? В их основе лежат деревья, выполняющие всю "грязную работу".

Деревья - подмножество Графов.

Видов деревьев довольно много. 

#### Первое дерево

Дерево - разновидность графа, а значит оно тоже состоит из узлов и ребер.

Автор предупреждает, что в данной книге будет работать с корневыми деревьями. 

У __корневого дерева__ имеется один узел, от которого можно перейти к любому другому узлу. Здесь и далее, говоря __дерево__ будем иметь в виду __корневое дерево__.

У узлов могут быть __дочерние__ узлы, а у дочерних узлов может быть __родительский__ узел. В общем в конструкции

$$
\text{Родительский узел} \to \text{Дочерний узел}
$$

тот узел, от которого идет стрелка - родительский. Узел, к которому идет стрелка - дочерний. 

Не путать с приведенным ранее примером с генеалогическим древом. Там на вершине был узел, обозначающий нас, но так как стрелки шли от него вниз то мы были родительским узлом по отношению к нашим родителям, которые были для нас дочерними узлами. 

В дереве узлы имеют по крайней мере одного родителя (зачастую каждый узел и будет иметь одного родителя. А вот детей у каждого узла будет обычно два, но может быть и один). Существует только один узел без родителя - это __корневой узел__. Тот, что на вершине. Тот, от которого пошло "расти" дерево. 

Узлы, которые не имеют дочерних узлов, называются __листовыми узлами__ (_листьями_).

```
корневой узел                  ← корневой узел
├── родительский узел A        ← родительский узел
│   ├── дочерний узел A1       ← дочерний узел
│   │   ├── лист A1a           ← лист
│   │   └── лист A1b           ← лист
│   └── дочерний узел A2       ← дочерний узел
│       └── лист A2a           ← лист
└── родительский узел B        ← родительский узел
    ├── дочерний узел B1       ← дочерний узел
    │   └── лист B1a           ← лист
    └── дочерний узел B2       ← дочерний узел
        ├── лист B2a           ← лист
        └── лист B2b           ← лист

```

#### Каталоги файлов

Так как дерево - разновидность графа, к нему можно применить алгоритмы, работающие с графами.

Мы уже знаем _поиск в ширину_ - алгоритм для нахождения кратчайшего пути в графе. _Поиск в ширину_ применим и для деревьев. 

Каталог файлов на компьютере представляет собой дерево. Представим, что у нас есть такой каталог

```
pics
├── 2001
│   ├── a.png
│   └── space.png
└── odyssey.png
```

Требуется вывести имена всех файлов каталога pics, включая все его подкаталоги. 

Однако, в данном случае, существует только один подкаталог: 2001

Эту задачу можно решить _Поиском в ширину_

Ранее мы использовали алгоритм _Поиска в ширину_ как инструмент для поиска. Однако этим его возможности не ограничиваются. Поиск в ширину - это __алгоритм обхода__. Это значит, что он посещает _каждый_ узел дерева ("обходит" его).

А это то, что нам нужно. Ведь нам нужен алгоритм, который посетит каждый узел в дереве и выведет его имя. Для перебора файлов в каталоге можно воспользоваться _Поиском в ширину_. Алгоритм также заходит в подкаталоги, ищет в них файлы и выводит имена обнаруженных файлов.

Логика будет выглядеть так:
1. Посетить каждый узел в дереве
2. Если узел является файлом - вывести его имя
3. Если узел является папкой - добавить его в очередь папок, чтобы найти находящиеся в нем файлы

Получаем примерно такой код

```js
// Подключаем модуль fs для работы с файловой системой
const fs = require("fs");
const path = require("path");

// Функция обхода папки и вывода файлов
function printNames(startDir) {
  // Очередь для поиска в ширину
  let searchQueue = [startDir];

  // Пока очередь не пуста ...
  while (searchQueue.length > 0) {
    // Берём первый элемент из очереди
    let dir = searchQueue.shift();

    // Получаем массив файлов и папок в директории
    let files = fs.readdirSync(dir).sort();

    for (let file of files) {

      // Соединяем путь до файла и имя папки
      let fullPath = path.join(dir, file);

      // Если это файл — печатаем его имя
      if (fs.statSync(fullPath).isFile()) {
        console.log(file);
      } else {
        // Если папка — добавляем в очередь
        searchQueue.push(fullPath);
      }
    }
  }
}

// Запуск
printNames("pics");
```

Здесь используется очередь, как в примере с продавцом. В очереди хранится информация о том, в каких еще папках нужно провести поиск файлов.

И если в том примере мы останавливались сразу же после нахождения продавца, то теперь мы не остановимся, пока не проверим все узлы нашего дерева. 

Впрочем, в данном примере есть одно важное отличие от предыдущего кода. А именно: мы не ведем отдельный список уже проверенных узлов. Почему? В деревьях не могут появиться циклы, так как у каждого узла только один родитель, и деревья это всегда направленный граф, причем направленный всегда в одном направлении. 

Мы никогда не сможем случайно провести поиск в одной папке несколько раз или запустить бесконечный цикл.

Этот важный вывод стоит запомнить:

$$
\text{В деревьях не бывает циклов!}
$$

Вообще, говоря о файловой системе, мы должны упомянуть о том, что есть такая сущность как символические ссылки. Так, в директории 2001 мы можем создать символическую ссылку на директорию pics. И тогда получится цикл. Но тогда данный участок файловой системы перестанет быть деревом. А мы рассматриваем деревья. 

Еще раз выполним задание, но на этот раз воспользуемся __рекурсией__

```js
function printNamesRecursive(dir) {
  // Получаем содержимое папки
  let files = fs.readdirSync(dir).sort();

  for (let file of files) {
    let fullPath = path.join(dir, file);

    if (fs.statSync(fullPath).isFile()) {
      console.log(file);
    } else {
      printNamesRecursive(fullPath);
    }
  }
}
```
В этот раз мы не используем очередь. Вместо этого, при обнаружении папки - мы сразу заходим в нее, чтобы поискать файлы там. 

По сути своей обе эти реализации делают одно и то же: выводят список файлов. Однако файлы выводятся в разном порядке. И этому есть причина.

Алгоритм поиска в ширину движется концентрически: попав в папку, он разбирает все имеющиеся в ней узлы. Файлы - отображает сразу. Вложенные папки - вносит в очередь проверки, чтобы вернуться к ним, когда закончит с текущей папкой. 

Рекурсия же действует иначе. Найдя папку, она приостанавливает перебор текущей папки, сохраняя все в стеке вызовов, и для найденной папки создает рекурсивный вызов нового экземпляра функции. 

По сути, ключевое отличие тут в структуре данных, с которой работает каждый из этих методов: 
* очередь это FIFO, а значит все, что попало в нее в начале (узлы папки pics) будет обработано в полном объеме, и только после этого в очередь будут добавлены узлы из вложенной папки 2001.
* стек вызовов это LIFO, а значит обработка узлов первой папки pics не будет завершена в полном объеме до тех пор, пока не завершатся все рекурсивные вызовы.

Но на самом деле автор немного схитрил. Файл в папке pics называется odyssey.png, в то время как папка называется 2001

Цифры идут до строковых названий (а передаваемые в функции данные у нас отсортированы по имени) поэтому рекурсивная функция, проверяя содержимое папки pics, вначале натыкается на вложенную папку 2001 и запускается рекурсивный вызов, а незавершенный первый вызов падает на дно стека. Называйся папка VeryCool2001, и мы бы не увидели разницы в порядке, в каком обе функции выводят ответы (так как рекурсивная функция сначала бы обработала файл, а потом наткнулась на папку)

Во втором (рекурсивном) решении используется алгоритм, называемый __Поиск в глубину__. Он тоже работает с графом, и представляет собой алгоритм обхода дерева. При обнаружении папки он сразу заходит в нее, вместо того, чтобы добавлять ее в очередь.

_Поиск в ширину_ и _Поиск в глубину_ тесно связаны друг с другом. И там, где упоминается один, будет упоминаться и другой. Оба алгоритма выводят все имена файлов, поэтому они оба подходят для нашего примера. Однако между ними существует важное различие: _Поиск в глубину_ не может использоваться для нахождения кратчайшего пути!

В примере с продавцом мы не могли применить поиск в глубину. Мы опирались на тот факт, что друзья первого уровня должны проверяться раньше друзей второго уровня. А _Поиск в глубину_ сразу заходит на максимальную глубину. Он может обнаружить самого удаленного продавца от нас и выдать результат, хотя __ближайший__ продавец может быть даже на первом уровне наших друзей. 

Таким образом, хотя оба алгоритма проверяют все узлы в графе, для задачи поиска __ближайшего__ узла подходит только _Поиск в ширину_. 

#### Правильное определение дерева

После рассмотренного примера можно привести более точное определение дерева

$$
\text{Дерево представляет собой }\textbf{связный ациклический граф}
$$

Напомним, что мы работаем только с корневыми деревьями, поэтому у всех наших деревьев всегда есть корень. Поэтому главное, что нам надо запомнить: в деревьях не может быть циклов. 

#### Бинарные деревья

Бинарные деревья используются очень часто. 

Бинарное дерево представляет собой дерево, узлы которого могут иметь __не более__ двух дочерних узлов (отсюда и название).

```
        8
       / \
      3   10
     / \     \
    1   6     14
       / \    /
      4   7  13

```

Дочерние узлы бинарного дерева традиционно называются __левым__ и __правым__ узлами.

Пример бинарного дерева - генеалогическое древо.

У узла может быть только один дочерний узел или ни одного, самое главное, чтобы у одного узла было __не больше двух дочерних узлов__.

#### Код Хаффмана

Код Хаффмана - хороший пример использования бинарных деревьев.

Он также лежит в основе алгоритма сжатия текста.

Небольшое введение в тему. Чтобы понять, как работает сжатие, нужно знать, сколько места занимает текстовый файл. 

Представим файл, содержащий всего одно слово tilt. Он занимает 4 байта, по одному на символ.

В двоичном формате текст tilt выглядит так:

```
00000000: 01110100 01101001 01101100 01110100
```

Здесь в игру вступает сжатие. Для слова tilt не нужны все 256 возможных букв. Нужны только 3. Таким образом, для представления буквы не нужны все 8 бит, можно обойтись только двумя. 

Можно было бы определить собственную двухбитную кодировку для этих букв:

```js
t = 00
i = 01
l = 10
```
Таким образом можно записать tilt в новой кодировке:

```
00 01 10 00
```
_Добавили пробелы для удобства_

Сравнив эти данные с таблицей получим исходное слово tilt

Именно так работает алгоритм Хаффмана: он ищет повторяющиеся символы и использует для их представления меньше 8 бит, в результате чего происходит сжатие данных. Код Хаффмана генерирует дерево.

```
        (*)
       /   \
     (*)     t
    /   \
   i     l

```

По этому дереву можно узнать код каждой буквы. Каждый раз, когда на пути вниз мы выбираем левую ветвь, к коду добавляется 0. Когда выбирается правая ветвь - добавляется 1. 

Когда мы упремся в букву, продвижение по дереву остановится. 

Таким образом, букве $L$ будет соответствовать код 01

Дерево определяет три кода:

```
i = 00
l = 01
t = 1
```

Обратим внимание, что код буквы $T$ состоит всего из одной цифры 1

В отличие от стандартизированных кодировок, _в кодировке Хаффмана коды не обязательно должны иметь одну и ту же длинну_. Это важный момент. Так как длинна кода для каждого символа может быть разной (2, 3 или 4 символа) разбить итоговый код на фрагменты для анализа невозможно.

Придется перебирать цифры по одной, словно просматривая пленку с цифрами. Первое число равно 0 - поэтому идем по дереву в левую ветвь. Далее 1 - идем направо. Снова 1 - опять направо и вот буква найдена. Потом берем оставшийся бинарный код и снова, идя от корневого узла, ищем букву. Еще раз отметим, что так как длины кодов непостоянны, то декодирование такого кода требует больших усилий по сравнению со стандартными кодировками. 

Но в то же время это дает большой выйгрыш в плане экономии объема памяти: чем чаще встречается буква, тем меньший набор битов алгоритм постарается использовать, чтобы закодировать ее. Для длинных текстов это дает большую экономию памяти. 

Теперь, когда мы в общих чертах понимаем принцип работы алгоритма Хаффмана, ответим на вопрос: Возможно ли наложение кодов. Возьмем следующий код:

```
a = 0
b = 1
c = 00
```

Имеется двоичная последовательность 001. Что она должна значить? $AAB$ или $CB$ ?

Буква $A$ встречается на пути к букве $C$, поэтому ответ неясен.

С кодами Хаффмана такой проблемы нет, потому что буквы помещаются только в листовых узлах.

От корня к каждому листовому узлу существует только один, уникальный путь - это одно из свойств деревьев. Это гарантирует, что наложения букв не будет.

Это так же гарантирует, что к каждой букве ведет только один путь, а значит каждой букве соответствует ровно один код. Разные коды не могут соответствовать одной букве. Ведь существование разных путей к одной букве означало бы, что за одной буквой закреплено несколько кодов, что совершенно излишне. 

Когда мы читаем код по одной цифре, предполагается, что в конце этого процесса мы придем к букве. Если бы в графе присутствовал цикл, то наше предположение сразу стало бы нереалистичным. Потому что вместо того, чтобы придти к букве мы бы попали в этот цикл и кружили в нем. 

Мы используем корневое дерево. У корневого дерева есть корневой узел. И это важно! мы ведь должны значть, с чего начинать декодирование. С другой стороны, не каждый граф имеет корневой узел. 

И наконец, в используемых нами деревьях каждый узел имеет не больше двух дочерних узлов. И это хорошо, потому что у нас бинарная система, и "левый" и "правый" могут быть закодированы 0 и 1. 

При наличии тертьего узла было бы неясно, какой цифрой его представлять.

### Сбалансированные деревья

В предыдущей главе мы познакомились с деревьями. 

Если массивы и связанные списки не дают нужной производительности, есть смысл присмотреться к деревьям. В этой главе мы поговорим о производительности, которой можно добиться с помощью дерева. Мы поговорим об особом дереве, которое обеспечивает исключительную производительность - __сбалансированные деревья__.

#### Балансировка

Вспомним _Бинарный поиск_, который позволял искать информацию со скоростью $O(\log n)$ вместо обычного $O(n)$, если бы мы использовали поиск перебором. 

Впрочем, есть одна проблема: вставка. Да, и массив должен быть отсортирован. Если потребуеся вставить новое число в отсортированный массив, то это займет время $O(n)$, потому что вставка в массив (если только дело не идет о его конце) приводит к переиндексации ряда элементов. 

Конечно, если нам нужна структура данных с быстрой вставкой элементов, то можно воспользоваться связанным списком. Вот только поиск в связанном списке занимает линейное время. 

Как бы нам получить все лучшее от обоих структур данных, избежав недостатков?

#### Деревья повышают скорость вставки

Итак, по сути нам нужна скорость поиска в отсортированном массиве, плюс быстрая вставка. 

И такая структура известна - это __сбалансированное дерево поиска__ (BST). 

BST - Это разновидность Бинарного дерева. 

```
        10
       /  \
      5    20
     / \      \
    2   7      25
```

Как и в бинарном дереве, каждый узел имеет до двух дочерних узлов: левый и правый. Но у этого дерева есть одно свойство, относящее его к BST: 

Значение левого дочернего узла __всегда меньше__, чем значение родительского узла. А значение правого дочернего узла __всегда больше__ значения родительского узла. 

Таким образом, для узла 10 значение левого узла 5 - меньше родительского, значение правого узла 20 - больше родительского. 

Более того, __все__ числа в поддереве _левого_ дочернего узла (такое поддерево, корнем которого является левый дочерний узел) меньше главного родительского узла. Числа 5, 2 и 7 из левого поддерева меньше, чем число родительского узла 10.

И, соответственно, __все__ числа в поддереве _правого_ дочернего узла больше значения родительского узла.

Это особое свойство обеспечивает факт того, что поиск будет выполнен очень быстро. 

Давайте посмотрим, содержится ли число 7 в этом дереве. 

Начнем с корневого узла. 7 меньше 10, поэтому будем проверять левое поддерево. Опускаясь в левое поддерево мы переходим к числу 5. Число 7 больше 5, поэтому нам следует направиться в правую ветвь. Число 7 найдено. 

Теперь поищем число 8. Будут проделаны все те же самые шаги. Дойдем до 7. Это лист, за ним ничего нет. Но если бы 8-ка была, она была бы в правом дочернем узле числа 7 (потому что 8 больше 7).

Это все подводка к рассмотрению вопроса производительности деревьев. Обсудим этот вопрос, но будем учитывать при рассмотрении высоту деревьев.

#### Короткие деревья работают быстрее

Рассмотрим два дерева. Оба дерева состоять из 7 узлов, но сильно различаются по производительности.

Вариант 1
```
        1
       / \
      2   3
     / \ / \
    4  5 6  7
```

Вариант 2
```
1
 \
  2
   \
    3
     \
      4
       \
        5
         \
          6
           \
            7
```
Лучшим случаем является Вариант 1. Он содержит в себе 2 уровня: это значит, что чтобы добраться от корневого узла до любого узла в дереве потребуется не более 2 шагов.

Высота дерева худшего случая, Вариант 2, составляет 6 уровней. Это значит, что к любому узлу от корневого можно добраться за 6 шагов.

Чтобы определиться с производительностью этих деревьев, быстро вспомним производительность _Простого поиска_ для 100 элементов: $O(n) = 100$ попыток, и для _Бинарного поиска_ для 100 элементов: $O(\log n) = \log 100 = 7$ попыток.

Нечто похожее происходит и с деревьями, в зависимости от их конфигурации:

Вариант 2 это 6 уровней, а значит 6 шагов для дерева из 7 элементов.

Вариант 1 это 2 уровня, а значит 2 шага для дерева из 7 элементов.

Дерево для худшего случая выше, и у него хуже производительность. В нем все узлы выстроены в одну линию. Дерево имеет высоту $O(n)$, а значит и время поиска для него будет $O(n)$. Это можно представить так: дерево в действительности напоминает связанный список, так как один узел содержит ссылку на другой и так далее. А поиск по связанному списку выполняется за время $O(n)$. 

Дерево для лучшего случая имеет высоту $O(\log n)$, соответственно время поиска для него займет $O(\log n)$. Таким образом, ситуация очень похожа на сравнение бинарного поиска с простым. 

Если можно обеспечить высоту дерева $O(\log n)$, то время поиска по нему займет $O(\log n)$. 

Но как добиться, чтобы высота составляла заветный $O(\log n)$?

В следующем примере мы построим дерево, которое оказывается деревом для худшего случая (а нам этого желательно избежать). Начнем с одного узла, затем добавим другой. 

```
10
  \
   20
     \
      30
```

Узлы мы добавляем справа, потому что каждый доченрий узел больше родительского. 

Получается дерево для худшего случая. Оно будет работать медленно. Чтобы добиться хороших показателей скорости, нам нужна другая конфигурация, заветной высотой $O(\log n)$. Чтобы ускорить BST дерево, его надо __сбалансировать__.

#### АВЛ - деревья: разновидность сбалансированных деревьев

АВЛ-дерево — это первое в истории самобалансирующееся бинарное дерево поиска. Его придумали в 1962 году два советских математика:

__Георгий Максимович Адельсон-Вельский__ (1922–2014)

Советский математик и кибернетик. Работал в области математической логики, искусственного интеллекта и дискретной математики. Был одним из первых в СССР, кто серьёзно занимался автоматическим доказательством теорем. Автор ряда книг по программированию и алгоритмам.

__Евгений Михайлович Ландис__ (1921–1997)

Советский математик, ученик Андрея Колмогорова. Занимался в основном дифференциальными уравнениями и математической логикой. Внёс вклад в теорию уравнений в частных производных, но в информатике известен именно благодаря АВЛ-деревьям.

Деревья АВЛ - __самобалансируемые__ бинарные деревья. Это означает, что АВЛ деревья сохраняют высоту $O(\log n)$. 

Каждый раз, когда дерево разбалансируется, тоесть его высота становится больше $O(\log n)$, оно корректирует само себя. 

В нашем примере дерево может перебалансироваться и принять вид

```
        20
       /  \
     10    40
          /  \
        30    50
```

АВЛ-дерево обеспечивает нужную высоту $O(\log n)$, которая достигается самобалансировкой и поворотами.

##### Повороты

Представим, что имеется дерево с 3 узлами A, B, C.

Каждый из этих узлов можно назначить корнем. 

Попробуем смоделировать эту ситуацию на реальных цифрах: 10, 20, 30
```
    10
      \
      20
        \
         30
```
```
        20
       /  \
     10    30
```
```
        30
       /
     20
    /
   10
```

На самом деле, это одно и то же дерево, просто с некоторыми изменениями. Первый и третий вариант - переворот дерева с ног на голову, просто с изменением ориентации ветви. Мы просто представим, что каждый узел - это шарнир. Верхний узел опустился вниз относительно 20, нижний поднялся вверх.

Средний вариан интереснее. Представим себе бусы, где узлы - это бусины. Представим, что мы "потянем вверх" за среднюю бусину, узел 20. Узел 30 опустится вниз, узел 10 тоже. Вот мы и получили нужное нам дерево минимальной высоты! 

Поворот - популярный метод балансировки деревьев.

Обозначим еще одно правило: Если при формировании АВЛ дерева возникает ситуация, при которой одна ветвь длиннее другой на 1 узел, то дерево __не считается__ разбалансированным. Разность в 1 уровень приемлема.

Теперь у нас вырисовывается некий алгоритм: Начинаем собирать дерево. Есть один узел, к нему добавляется второй. Дерево начинает расти вниз. Добавляем 3 узел ко второму, и вот у нас ситуация: одной ветви вообще нет, так что условно ее высота 0, вторая ветвь уже высотой в 2 уровня. Разность между ветвями больше 1 уровня, а значит _дерево разбалансировалось_ и настало время балансировки! "Потянем" за средний узел, получим классическое бинарное дерево из 3 элементов высотой 1 уровень

```
        20
       /  \
     10    30
```
Добавим еще один узел
```
        20
       /  \
     10    30
            \
             40
```
Разность высот составляет 1 уровень, это приемлемо, дерево считается __сбалансированным__.

Добавим еще один узел:
```
        20
       /  \
     10    30
            \
             40
              \
               50
```
Разность высот 2 уровня, дерево __разбалансировано__. Снова нужен поворот.

```
        20
       /  \
     10    40
          /  \
        30   50
```
Дерево снова __сбалансировано__.

##### Как АВЛ-дерево узнает, что требуется поворот?

Мы то визуально видим, что одна ветвь критически длиннее другой. Но как об этом узнает само АВЛ-дерево?

Чтобы дерево знало, когда требуется самобалансировка, оно должно хранить дополнительную информацию.

В каждом узле хранится один или два вида информации: значение высоты или значение, которое иногда называют __коэффициентом балансировки__. Этот коэфициент должен быть равен $-1, 0, 1$

-1 значит, что левая дочерняя ветвь на 1 длиннее.
0 значит, что обе ветви равны по длинне
1 значит, что правая дочерняя ветвь на 1 длиннее.

Мы привели коэффициенты балансировки для корневого узла, но нам может потребоваться хранить коэфициент балансировки в __каждом__ узле. 

Коэффициент балансировки сообщает родительскому узлу какая дочерняя ветвь длиннее другой и на сколько. 

По коэффициенту балансировки дерево может определить, когда проводить перебалансировку.

Значение 0 значит, что дерево полностью сбалансировано. Значения -1 и 1 тоже считаются нормальными. Но когда коэффициент балансировки падает ниже -1 или поднимается выше 1 значит дерево нуждается в перебалансировке. 

В каждом узле должна храниться либо высота, либо коэффициент балансировки. Либо и то, и другое. Но если мы храним высоты, то всегда можем получить из них коэффициент балансировки. 


