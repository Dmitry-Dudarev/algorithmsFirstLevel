Прочитаем книгу Грокаем алгоритмы и сделаем для себя выводы. 

Алгоритмом называется набор инструкций для выполнения некоторой задачи. 
Алгоритмы - это во многом про эффективность.

Первая тема, с которой автор книги предлагает познакомиться - Бинарный поиск. 

Предположим, мы ищем фамилию человека в телефонной книге. Фамилия начинается на К.
Конечно, можно поступить самым очевидным способом, говорит автор, и начать листать телефонную книгу с самого начала. Но тут же предлагает второй способ - раскрыть книгу на середине. Такое решение скорее всего продиктовано такой логикой: если буква К в середине алфавита, а телефонная книга содержит имена в алфавитном порядке - то можно провести параллель между этими двумя сущностями и экстраполировать наше знание о положении буквы К в алфавите на ее предполагаемое положение в телефонной книге: в середине в алфавите - в середине в телефонной книге. И аналогичные примеры, например поиск никнейма в базе данных социальной сети - тот же принцип. 

Такого рода задачи названы автором Типичной задачей поиска. На примере таких задач нам предлагают познакомиться с алгоритмом, который может быть использован для их решения: Бинарный поиск. 

Бинарный поиск - это алгоритм. На входе он получает __ОТСОРТИРОВАННЫЙ__ список элементов. На данном этапе автор не объясняет, почему он должен быть отсортирован, но я предположу, что дело как раз в том, чтобы можно было соотносить список элементов с некой последовательностью (так, если телефонная книга отсортирована по алфавиту, то на нее можно проецировать некоторые свойства алфавита - в частности расположение конкретных букв относительно общего объема алфавита - а значит и телефонной книги)
Принцип Бинарного поиска заключается в том, что если элемент, который мы ищем, найден - в качестве ответа нам должен вернуться _порядковый номер_, _позицию_ данного элемента в предоставленном для поиска отсортированном списке. А значит каждый элемент списка должен обладать информацией о своем местоположении в списке, чтобы ее вернуть. Если элемент не найден - то алгоритм бинарного поиска возвращает __null__ (ну или -1). Таким образом эти условия уже помогают познакомиться со стандартами: если мы реализуем бинарный поиск, значит должны организовать код так, чтобы в случае успеха возвращался тип данных, содержащих позицию элемента в списке, а не булевое значение или строка типа _"Успех!"_. И также вводится стандарт для ответа в случае, если элемент не найден.
Для примера приводится поиск загаданного числа от 1 до 100. Список таких чисел - уже __упорядоченный__ список, где каждый элемент самим своим значением содержит информацию о своем __положении__ в этом списке. Тоесть подходит для условий Бинарного поиска. Далее автор рассматривает концепцию Простого поиска - тоесть перебора значений по порядку, пока не будет достигнуто загаданное число. Этот подход, в теории, для данного списка, может содержать число проверок, равных длинне списка - например, если загадано 99. 
В качестве альтернативы автор предлагает Бинарный поиск - начинать поиск с середины списка - и ждать ответа. Загадавший может дать ответ 3 типов: Меньше, Больше и Попал. Не совсем то, что мы встретим в реальном поиске на ПК, но для модели сойдет. Итак, начав с середины, и даже не получив ответ Попал, а получив Больше или Меньше, мы добьемся невероятного результата - а именно сократим наш изначальный список в 2 раза! По сравнению с простым поиском это невероятный прогресс! Всего первый шаг, а мы уже сократили исходный список в 2 раза! А значит стоит придерживаться означенной логики далее: понимая, какая половина списка осталась, мы вновь выбираем _среднее_ значение, чтобы получив ответ сократить новый список опять вдвое. Или на 75% от исходного! Всего за 2 вопроса, за 2 итерации - мы сократили исходный список на три четверти! А это значит, что даже если бы мы вдруг прибегли теперь к простому поиску, он теоретически будет быстрее на 75%. Но нам нет нужды - мы вновь продолжим пользоваться Бинарным поиском. Это напоминает мне складывание листа бумаги пополам - каждый раз размер уменьшается вдвое. А так как любой список конечен, сколь бы велик не был исходный список - потребуется _небольшой_ (относительно его размера) набор шагов, а главное - _конечный_ набор шагов - чтобы в любом случае достичь искомого элемента списка. 

Далее автор декларирует: для поиска элемента в списке из 100 позиций потребуется не более 7 шагов Бинарного поиска. И уже сдесь мы можем попытаться предположить, что существует логика, по которой мы можем рассчитать: сколько шагов нужно, чтобы провести однозначно успешный поиск для списка конкретной длинны. Тоесть - зная длинну списка мы можем сказать, сколько максимум шагов Бинарного поиска потребуется, чтобы получить результат. 

Для списка из 240 000 элементов потребуется 18 шагов. 

В итоге для списка из n элементов потребуется $log_2n$ шагов, тогда как простой поиск будет выполнен за $n$ шагов. 

Логарифм - операция, обратная возведению в степень. Тоесть, если мы говорим о логарифме по основанию (число $а$) от числа $б$, то мы задаем вопрос: в какую степень мы должны возвести число $а$, чтобы получить число $б$. 
Это значит, что когда мы говорим о списке элементов определенной длинны $а$, и хотим узнать, сколько шагов потребуется Бинарному поиску чтобы однозначно найти в нем ответ, мы должны ответить на вопрос: в какую степень нужно возвести число 2, чтобы получить число $а$. 

#### Время выполнения - еще один важный фактор. 
Так, если мы будем искать элемент в списке из 100 позиций последовательным перебором, это займет у нас до 100 итераций. Если в списке из 240 000 - столько же итераций. Говоря о времени выполнения алгоритма, мы в данном случае говорим, что оно линейно: сколько элементов в списке, столько же и итераций.

Когда мы говорим о Бинарном поиске, то можем явно заметить, что списку из 240 000 позиций потребуется всего 18 итераций - что несопоставимо меньше размера списка. 
Говорят, что бинарный поиск выполняется за _логарифмическое время_. 

Итак, для описания скорости работы любого алгоритма используют специальную нотацию под названием $O-большое$.
$O-большое$ позволяет провести оценку скорости работы алгоритма. 
Автор приводит интересный пример: если одна итерация поиска занимает у компьютера 1мс, то для списка из 100 элементов линейный поиск составит 100мс, а бинарный поиск составит 7мс - потому что нужно 7 итераций. 
Если взять список размером 10 000 элементов, то линейный поиск займет 10с, а бинарный поиск 14мс! Уже колоссальная разница. Но когда мы берем список из 1 000 000 000 элементов, то для линейного поиска это займет 11 дней, а для бинарного поиска - 30мс. 
Впринципе, если мы выразим линейный поиск в виде функции $y = x$, где $у$ - это число итераций, необходимых для проверки списка размером x элементов, то для бинарного поиска мы получим функцию \[ y = \log_2 x \]. 
Если бы нам захотелось составить графики этих функций, то мы бы увидели, что график логарифмической функции с увеличением x становится почти параллельным оси $Ox$, в то время как линейная функция всегда будет проходить под углом в 45 градусов.

Вот почему недостаточно знать, сколько времени займет выполнение алгоритма для данного конкретного случая. Важно понимать, как время выполнения меняется с ростом размера списка элементов. Для такого понимания $O-большое$ и нужно. 
$O-большое$ описывает то, насколько быстро работает алгоритм. Для линейного поиска из n элементов $O-большое$ будет иметь вид $О(n)$. Для Бинарного поиска это значение будет \[ O(\log_2 n)\]

$O-большое$ не может однозначно предсказать количество операций, которые придется выполнить для решения поставленной задачи. Но оно поможет понять общую эффективность алгоритма:
$O(n)$ - приемлемо, $O(\log_2 n)$ - очень хорошо, $O(n^2)$ - прям совсем плохо, неприемлемо уже при n = 20.

Нужно понимать, что $O-большое$ определяет количество итераций при _**наихудшем**_ сценарии - тоесть если нам совсем не повезет, и ни одна итерация не приведет к правильному ответу, кроме последней. 

```
Наряду с временем худшего случая 
полезно бывает учитывать и среднее время 
выполнения. Не всегда все наши алгоритмы 
будут выполняться по худшему сценарию
```

##### Типичные примеры $O-большого$:
- $O(\log n)$ - или _Логарифмическое время_ - Бинраный поиск
- $O(n)$ - или _Линейное время_ - Простой поиск
- $O(n * \log n)$ - эффективные алгоритмы сортировки, например - _Быстрая сортировка_
- $O(n^2)$ - медленные алгоритмы сортировки - _Сортировка выбором_
- $O(n!)$ - очень медленные алгоритмы - Задача о коммивояжере

Существуют и другие варианты времени выполнения, но эти встречаются чаще всего. 

#### Существенные итоги:
- Скорость алгоритмов измеряется не в секундах, а в темпе роста количества операций
- Время выполнения алгоритма выражается как $O-большое$

Далее автор дает ряд задач для самостоятельного решения, но отдельно хочется выделить последнюю: Найти $O-большое$ для операции прочтения всех номеров людей в телефонной книге, чья фамилия начинается на А. 
_Решение_: Тут есть небольшой подводный камень - наш алгоритм не знает, что телефонная книга начинается фамилиями на А. Поэтому первой нашей задачей станет найти самую первую фамилию на А в телефонной книге. Тоесть задача найти фамилию - а ее время выполнения выражается как $O(\log_2n)$. А далее нужно последовательно прочитать столько номеров, сколько людей с фамилией на А. Значит вермя выполнения $O(k)$ - не n, потому что n - число всех фамилий в книге. Ну а потом просто сложим эти два времени выполнения и получим $O(\log_2 n + k)$. Где собственно основное время занимает $O(k)$ - последовательное чтение всех фамилий на А.

### Задача о коммивояжере

Никому не хотелось бы столкнуться с самым лютым верменем выполнения алгоритма, выражающимся $O(n!)$.
Говорят: __n факториал__.
__Факториал__ - это произведение всех целых чисел от 1 до n. Главная его особенность - он невероятно быстро растет. График $y=x!$ почти с самого начала идет практически параллельно оси y. Задача посчитать $20!$ уже фактически неподъемна.
Сама задача коммивояжера состоит в том, что коммивояжер хочет объехать 5 городов по самому короткому маршруту между ними. Для этого ему надо _перебрать_ все варианты маршрутов, а значит $5! = 1*2*3*4*5 = 120$ перестановок, вариантов маршрутов. Для 6 городов потребуется уже 720 перестановок на карте, а для 7 городов 5040. Время выполнения такого алгоритма называется __факториальным__, выражается с помощью $O-большого$ как $O(n!)$. 
Так, если мы попытаемся решить задачу для 100 городов - сделать это не удастся - Солнце погаснет раньше. 

Коммивояжер мог бы попытаться найти другое решение - но у него ничего не получится. Это одна из знаменитых нерешенных задач в теории вычислений. Для нее не существует известного быстрого алгоритма. Более того, математики считают, что такой алгоритм врядли когда-нибудь будет найден. В лучшем случае для нее можно поискать приближенное решение. 

### 2. СОРТИРОВКА ВЫБОРОМ

* Эта глава познакомит нас с массивами и связанными списками - двумя структрурами данных, которые используются практически повсеместно.
* Глава научит первому алгоритму сортировки (_мы ведь помним, что многие алгоритмы работают только с отсортированными данными_). В большинстве языков существуют встроенные алгоритмы сортировки, но принцип понимать надо.

#### Как работает память

Память физически разделена на ячейки. Каждая ячейка может хранить фиксированный объем информации. Каждая ячейка имеет свой адрес, чтобы к ней можно было обратиться. 
Каждый раз, когда мы хотим сохранить в памяти отдельное значение, нам предоставляется ячейка. А когда мы хотим хранить несколько значений, нам может потербоваться _массив_ или _список_.

#### Массивы и Связанные списки

Иногда в памяти требуется сохранить список элементов. 
Предположим, мы пишем приложение для управления текущими делами. Описания задач должны храниться в виде списка в памяти.
При использовании __массива__ все задачи хранятся в памяти _непрерывно_, тоесть рядом друг с другом.
Предположим, мы захотим добавить новую задачу - но выделенное под наш массив место - _непрерывная область памяти_ - уже закончилось. Потому что за нашим массивом расположились другие данные. А значит придется запросить у компьютера блок непрерывной памяти, куда влезет наш новый список, и переместить его на новое место. И так всякий раз, когда добавляется новая задача. Если каждый раз придется переносить все возрастающий массив в новую, пока еще свободную непрерывную область памяти, то добавление новых элементов станет крайне медленной операцией.
Одно из решений - _**Бронирование места**_. Мы заранее просим выделять под наши массивы место с запасом, например не 3 ячейки а сразу 10. И тогда добавление новых элементов будет производиться в незанятую, зарезервированную для этого массива непрерывную область памяти. Но у данного подхода есть несколько вполне очевидных недостатков:
* Лишнее место может и не понадобиться - тогда память будет расходоваться неэффективно. Много свободного места, которым нельзя воспользоваться. 
* Если в массив будет добавлено более 10 задач - перемещать все равно придется.

##### Связанные списки

Элементы связанных списков не требуют непрерывной области памяти - они могут размещаться где угодно. 
Каждый элемент памяти выделяет немного свободного места для хранения у себя адреса следующего за ним элемента памяти. Таким образом, набор произвольных адресов памяти объединяется в _цепочку_. Со связанными списками ничего перемещать в памяти не нужно. Нет нужды так же выделять непрерывную область памяти - данные могуть занять свободные места везде, где они есть. 
Но у связанных списков есть одна объективная проблема: Допустим, мы хотим получить _последний_ элемент всего спска. Но получить его сразу не получится - мы не знаем, по какому адресу хранится последний элемент. Поэтому нап придется двигаться по всей цепочке от первого элемента ко второму и далее, пока мы не дойдем до последнего элемента. 
Отсюда выходит главная особенность связанных списков: __Связанные списки отлично подходят для ситуаций, когда данные должны читаться последоватьельно__. Сначала один элемент, потом следующий и так далее. 

Но если мы намерены прыгать по элементам туда-сюда - связанные списки нам не подходят. 

С __массивами__ дела обстоят иначе - работая с массивом мы сразу знаем адрес каждого элемента. 

Говоря про эти типы данных, мы конечно же будем иметь в виду базовые операции с ними: а именно чтение и добавление элементов. И нас будет интересовать время выполнения операции - $O-большое$. 

__Для массива__
_Чтение_ будет иметь $O-большое$ $O(1)$ для списка из n элементов: не важно, какой длинны массив. Чтобы обратиться к любому его элементу нужно выполнить операцию доступа по известному индексу - а значит фиксированное время, условная еденица, для любого элемента. 

_Вставка_. Для определения времени выполнения операции нам нужно взять самый, условно говоря, неблагоприятный случай. В случае массива это вставка элемента в начало списка, что вынужденно приведет к переиндексации всех остальных элементов на +1. Таким образом, при добавлении одного элемента в _начало_, нам приходится переиндексировать _каждый_ элемент массива, а значит $O-большое$ для операций добавления в массив для массива длинной n - элементов составит $O(n)$.

__Для связанного списка__
_Чтение_ составит $O(n)$ - потому что если мы захотим прочитать последний элемент, нам придется последовательно продвигаться по _каждому_ элементу связанного списка длинною n, чтобы добраться до последнего

_Вставка_ составит $O(1)$ - нам нет нужды ничего перезаписывать для каждого элемента связанного списка длинною n. Нам достаточно изменить адрес _следующего_ элемента в предыдущем элементе на адрес нового элемента, а новому элементу указать тот самый адрес, который мы изменяли. 

Для операции удаления, при прочих равных, значения $O-большое$ будут аналогичны таковому для операции вставки. 

Еще нам необходимо ввести термин __доступ__ к элементу
Всего существует 2 типа доступа: __*Последовательный*__ и __*Произвольный*__. Последовательный мы разобрали на примере _связанного списка_, а произвольный доступ видели у _массива_.

#### Какая структура данных используется чаще

В JS используются массивы, всегда. Они крайне хорошо оптимизированы, лишены многих критических недостатков по сравнению с другими языками программирования. А используя приемы Кучи: Последний пришел Первый ушел мы буквально сводим операции чтения и записи к $O(1)$. Но даже __дорогостоящие__ для классических массивов операции в JS реализованы лучше.

В остальном - многие задачи реального программирования требуют произвольного доступа, поэтому массивы используются очень часто. 

Однако, даже безотносительно произвольного доступа, массивы работают быстрее потому что используют __*кеширование*__. 

###### Кеширование

Почему некое кеширование делает массивы еще быстрее?

Тут мы немного отвлечемся на архитектуру ЭВМ.
Процессор работает __Очень быстро__. А вот данные для обработки он получает из памяти RAM. Получение данных из RAM по-сравнению со скоростью работы процессора можно назвать медленным. 
Чтобы несколько сгладить этот разрыв, существует встроенная в процессор очень быстрая память: __CPU cache__ - _кэш ЦПУ_. 
Этот кэш очень быстрый, но маленький по объему. 
Когда процессор собирается обработать какой-то элемент массива, он загружает не только сам этот элемент, но и несколько соседних - целый __cache line__ - обычно это 64 байта. Это такакя оптимизация - программисты знали, что с большой вероятностью, при работе с массивом, потребуется не только конкретный элемент но и близлежащие - поэтому и настроили такое поведение памяти при загрузке элемента массива. 

Вот тут и раскрывается в полной мере тот факт, что массивы хранятся в непрерывной области памяти: подгрузив некоторою область массива процессор очень быстро может обработать несколько элементов подряд. В случае же со связанными списками каждые элемент может находиться в отдельной области памяти, а значит для обработки каждого из них придется лезть в RAM. 

Еще одним преимуществом массивав может быть тот факт, что при прочих равных хранить данные в массиве экономичнее, даже не смотря на то, что массив резервирует под себя определенную область памяти и могут оставаться незанятые куски, недоступные для хранения других данных. Дело в том, что пока массив хранит последовательность элементов, каждый элемент связанного списка должен хранить в себе еще и ссылку на следующий элемент. А значит для хранение небольших элементов однозначно выгоднее в массиве. С другой стороны хранение очень тяжелых элементов в массиве может привести к тому, что моссив потеряет свои преимущества и объем неиспользуемой, но зарезервированной под него памяти будет _существенным_.

##### А что в JS?

А в JS в дело вступает талант разработчиков, прекрасно организовавших работу с _массивами_ даже в мелочах. 

Движки JavaScript и многие языки выделяют массиву блок памяти с запасом, чтобы избежать частого перераспределения при добавлении элементов.
Это действительно может приводить к неиспользуемым, но зарезервированным участкам.
Но, этот запас обычно __не огромный__ и растёт динамически (например, в V8 массив может удваивать выделенную память при нехватке). Даже с этим запасом массив часто всё равно компактнее, чем связанный список, если элементы мелкие.

Что касается __тяжелых элементов__, то тут есть нюанс:
В JS, если элемент — это _объект_, в массиве хранится не сам _объект_, а _ссылка_ на него.
Поэтому размер элемента в массиве всегда фиксирован (размер ссылки, например 8 байт), а не зависит от «тяжести» объекта.
Объекты сами хранятся в __куче__ (__heap__) отдельно, и массив лишь хранит на них _указатели-ссылки_.

То есть тяжёлые элементы не делают массив хуже с точки зрения памяти, если речь идёт о JS.
В языках вроде C++ или Java с массивами объектов внутри — там да, объект может храниться прямо в массиве, и тогда «тяжёлый» элемент может увеличить блок памяти.
Но в JS — нет.

Автор книги в упражнениях приводит очень интересную, гибридную структуру данных. Для примера он предлагает нам представить процесс, по которому социальная сеть работала бы со списком имен пользователей. В частности, если необходимо провести быстрый поиск имени по большому набору элементов, то нам было бы сподручнее воспользоваться бинарным поиском - а значит нужен упорядоченный массив. А вот если нужно быстро добавлять или удалять данные, то тут связанный список с его $O(1)$ выглядит очень привлекательно. Но когда надо делать все виды операций, причем быстро, то невозможно удовлетвориться какой-то одной структурой данных. И тут на помощь может придти _гибридная структура_: _В упрощенном виде_: Пусть массив хранит связанные списки имен на одну букув. Теперь когда мы ищем конкретное имя вначале выполняется бинарный поиск буквы в массиве, а это очень быстро. Переходя к работе со связанным списком имен на конкретную букву мы теряем скорость, но при этом наша скорость не $O(n)$, где n - количество всех имен вообще, а $O(k)$, где k - количество имен на конкретную букву. Условно, если в алфавите больше 20 букв и условно принять, что имена примерно одинаково распределены между всеми буквами, то k это порядка 5% от n, а 
значит мы ускорили поиск на 95%. Ну а операция добавления/удаления уже найденного элемента для связанного списка составляет $O(1)$, самый благоприятный вариант. А значит получаем: поиск в массиве из z букв + поиск в списке + добавление/удаление найденного элемента в списке = $O(\log z) + O(k) + O(1)$. Да, линейный поиск это не самых удачный вариант, а поэтому мы стремимся максимально сократить его, разбив исходный пакет данных на мини-подгруппы, которые хранятся в удобной для поиска структуре - упорядоченном списке. Таким образом, разделив структуру данных, мы разделили операции между удобной для каждой операции структурой. 

#### Coртировка выбором

Допустим, у нас на компьютере хранится музыка. Для каждого исполнителя ведется счетчик воспроизведений. 

| Исполнитель   | Счётчик |
| ------------- | ------- |
| The Doors     | 450     |
| Black Sabbath | 1500    |
| Юрий Антонов  | 600     |
| Газманов      | 0       |

Допустим, мы хотим отсортировать исполнителей по количеству прослушиваний так, чтобы самые любимые стояли на первых местах.

Для выполнения этой задачи попробуем представить себе следующий алгоритм действий:
* Пройдемся по списку в поисках исполнителя с самым большим количеством прослушиваний. Список еще не отсортирован, поэтому проверить необходимо каждый элемент списка, чтобы иметь возможность сравнивать прослушивания и найти самое большое число. После нахождения такового занесем этого исполнителя первым номером в новый список, который будет отражать результаты сортировки. В итоге, учитывая необходимость для обнаружения самого прослушиваемого исполнитьеля "просмотреть" __каждый__ элемент списка n, получаем время выполнения как $O(n)$
* Теперь нам нужно найти следующего по популярности исполнителя - тот же алгоритм действий, то же время выполнения $O(n)$. 
* Начинает складываться понимание - чтобы произвести сортировку (по заданному параметру) списка элементов длинною n, нам необходимо пройтись по __каждому__ элементу списка $O(n)$ такое число раз, которое точно равно количеству элементов в списке - n раз, а значит время выполнения $O(n)$. 

Получается, что для сортировки списка мы потратим
 \[O(n) * O(n) = O(n*n) = O(n^2)\]

Алгоритмы сортировки очень полезны. 
Они могут помочь отсортировать:
- Имена в телефонной книге
- Даты событий
- Сообщения электронной почты по дате
  
__Уменьшение количества проверяемых элементов__
Нельзя не заметить одну особенность приведенной выше последовательности действий: На каждом новом цикле поиска по элементам число тех элементов, по которым нужно проводить поиск уменьшается. Если мы уже прошли пару раз по списку, значит нашли первых двух наиболее часть прослушиваемых исполнителей, а значит их проверять уже не нужно при поиске третьего, а значит список неотсортированных элементов условно сократился на 2. Тоесть чем больше итераций поиска мы провели - тем меньше стал наш исходный список: сначала шла проверка по n-списку, потом по n-1 списку, n-2, n-3 и т.д. В итоге будет проверен список из $\frac{1}{2} n$ элементов. 
Но мы все равно указываем при оценке времени этого алгоритма $O(n^2)$, как-будто не учитываем вышеозначенную особенность и каждый раз проводим проверку по полному списку n-элементов, хотя на самом деле время выполнения можно оценить как:
\[
  O(n\times \frac{1}{2} \times n)
\]

Но коэфициенты наподобие $\frac{1}{2}$ при оценке $O-большое$ не учитываются.

Алгоритм __сортировки выбором__ работает _медленно_. 

##### Пример кода 

Для примера мы создадим логику, которая будет исследовать массив и сортировать его в порядке возрастания элементов - тоесть сначала ищем наименший элемент, потом следующий за ним и завершается сортировка нахождением наибольшего элемента.

Для начала мы создадим функцию, которая будет искать наименьший элемент в предоставленном массиве. 
Внутри этой функции объявляется 2 переменные. Первая, smallest, принимает в себя исследуемый элемент массива. 
Вторая, smallestIndex, хранит индекс этого элемента. Функция запускает цикл, который проходит последовательно по всем элементам массива. 


И тут возникает вопрос: в книге автор пользуется циклом for...in, что позволят ему перебирать элементы по показателю индекса, так как сам цикл перебирает индексы. Но в JS для массивов и вообще итерируемых объектов существует цикл for...of, который перебирает не индексы, а сами элементы. Этот цикл лучше оптимизирован для перебора итерируемых объектов, поэтому является правильным выбором для массивов. При попытке перебрать массив с помощью for...in мы будем работать с ним как с обычным JS объектом и потераяем главное преимущество массива - скорость. Отсюда вытекает и его ограничение - цикл не предоставляет доступа к индексу, только к самому элементу. Поэтому мы воспользуемся классическим циклом for, который будет перебирать элементы по индексам.

```js
// Напишем функцию для поиска НАИМЕНЬШЕГО
// элемента в предоставленном массиве
function findSmallest(arr) {
  // Ведем 2 переменные:
  // smallest - для наименьшего элемента
  // smallestIndex - для его индекса
  // по-умолчанию зададим значения переменных
  // как первый элемент исследуемого массива
  let smallest = arr[0];
  let smallestIndex = 0;
  // Пройдем циклом по всем элементам массива
  // начиная со второго, и будем сравнивать 
  // каждый элемент с тем, что хранится в 
  // переменной smallest
  for (let i = 1; i < arr.length; i++) {
    // если ислледуемый элемент меньше того,
    // что хранится в smallest, то перезапишем
    // smallest новым, наименьшим значением
    if (arr[i] < smallest) {
      smallest = arr[i];
      smallestIndex = i;
    }
  }
  // после завершения цикла вернем индекс 
  // наименьшего найденного элемента
  return smallestIndex;
}
```

Далее наша задача - перейти к созданию самой функции сортировки, которая будет принимать массив и возвращать отсортированный массив. Будем возвращать __новый__ массив, чтобы избежать побочных эффектов, позаботиться о чистоте кода. Но вообще иногда имеет смысл изменять исходный массив, это экономит память. 

Создадим фукцию selectionSort, которая принимае массив. Внутри функции создадим новый, пустой массив, который будет на каждой итерации пополняться новым элементом в порядке возрастания из величины. И создадим копию исходного массива - нам ведь придется удалять из него по одному найденному элементу, чтобы вести поиск наименьшего значения только среди тех, которые еще не попали в отсортированный массив. 

```js
// Функция сортировки выбором
function selectionSort(arr) {
  // Копия исходного массива
  let arrCopy = arr.slice();
  // Массив для отсортированных данных
  let sortedArr = [];
  // Сортируем массив, удаляя найденные элементы
  // пока элементы для сортировки не кончатся
  while (arrCopy.length > 0) {
    let smallestElemIndex = findSmallest(arrCopy);
    sortedArr.push(arrCopy[smallestElemIndex]);
    arrCopy.splice(smallestElemIndex, 1);
  }
  return sortedArr;
}
```

### 3. Рекурсия

Рекурсия - элегантный метод решения задач. (_По мнению автора_)

Итак, допустим, нам нужно найти колюч от чемодана. 
Ключ от чемодана лежит в большой коробке с вещами. 
Большая коробка содержит в себе коробки поменьше.
А те, в свою очередь, может быть содержат еще меньшие коробки, а может и нет. 
Для решения задачи по поиску ключа автор предлагает 2 варианта:
1. Выделим место, назовем его _кучей коробок_. Задача _кучи коробок_ - хранить в себе все имеющиеся у нас неоткрытые коробки. Пока у нас только одна такая - первая большая коробка. Положим ее в _кучу_. Теперь перейдем к куче и возьмем нашу неоткрытую коробку с целью ее открыть. После открытия нас интересуют только 2 варианта: найдем ключ или найдем новые неоткрытые коробки. Если найдем ключ - поиск закончен. Если найдем новые, меньшие, неоткрытые коробки - сложим их в _кучу коробок_, чтобы открыть позже. Когда с первой коробкой покончено а ключа нет, идем к куче коробок, берем новую коробку и открываем ее - повторяем так до тех пор, пока не найдем ключ. 
Если мы говорим о реализации этой логики с помощью языка программирования, то нам необходимо: создать _кучу коробок_: переменную, которая будет хранить структуру данных, содержащую коробки. Задать условие: _пока куча не пуста_. И пока куча не пуста брать из нее по одной коробке, открывать ее и последовательно анализировать каждый лежащий в ней элемент: Если это коробка - добавить ее в _кучу коробок_. Если это ключ - завершить поиск. Когда элементы в коробке закончатся а ключ не найден повторять все, потому что _куча не пуста_. 

```js
// Аналог рекурсии с помощью классических циклов
function findAKey(data) {
  //тут будем хранить все неисследованные элементы
  let boxesToCheck = [];
  // первым элементом добавим наши исходные данные
  boxesToCheck.push(data);

  while (boxesToCheck.length > 0) {
    //берем последнюю коробку
    let box = boxesToCheck.pop();

    for (let item of box) {
      if (item === 'ключ') {
        return "Ключ найден!"
      } else if (Array.isArray(item)) {
        // это вложенная коробка, 
        // кладем ее в стек
        boxesToCheck.push(item);
      }
      // другие предметы игнорируем
    }
  }

  // если цикл закончился, значит ключа нет
  return "Ключ не найден"
}
```

Второй способ основан на рекурсии. __Рекурсией__ называют вызов функцией самой себя. 

```js
//Решение с помощью рекурсии
function findKeyUsingRecursion(bigBox) {
  for (let item of bigBox) {
    if (Array.isArray(item)) {
      let result = findKeyUsingRecursion(item);
      if (result === "Ключ найден!") {
        return result;
      }
    } else if (item === 'ключ') {
      return "Ключ найден!"
    }
    //другие предметы игнорируем
  }
  return "Ключ не найден"
}
```

Оба варианта решения задачи выдают один и тот же результат. Но автор полагает, что решение с помощью рекурсии выглядит более понятным. 

__Рекурсия__ используется во многих нужных алгоритмах, поэтому важно понимать ее концепцию. 

#### Базовый случай и рекурсивный случай

Так как рекурсивная функция вызывает сама себя, легко ошибиться и написать функцию так, что возникает бесконечный цикл. 

Приведем пример. Допустим, мы хотим написать функцию для вывода обратного отсчета:
\[3, 2, 1\]
Ее можно написать в рекурсивном стиле

```js
function countdown(i) {
  console.log(i);
  countdown(i - 1);
}
countdown(3)
// Приведет к бесконечному циклу и 
// переполнению стека
```

Когда мы пишем __рекурсивную__ функцию в ней необходимо указать в какой момент прервать рекурсию. 
Вот почему _каждая рекурсивная функция состоит из двух частей: __базового__ случая и __рекурсивного__ случая_.

В __рекурсивном__ случае функция вызывает сама себя. 
В __базовом__ случае функция себя не вызывает. Чтобы исключить зацикливание. 

Добавим базовый случай в функцию countdown:
```js
// исправленный вариант
function countdown(i) {
  console.log(i);
  if (i <= 1) {
    return
  } else {
    countdown(i - 1);
  }
}
```

#### Стек

В этом разделе мы поговорим про _стек вызовов_. 
Концепция стека вызовов играет важную роль в программировании вообще и при использовании рекурсии в частности. 
Предположим, мы устраиваем вечеринку. Планируя все заранее, мы составляем список дел и пишем их на небольших листках. Листки мы складываем в стопку. Наша стопка работает по очень простому принципу: новые элементы добавляются в начало стопки - на верх. И чтобы прочитать о каком-то запланированном деле нам надо взять листок, но взять его мы можем только сверху. Таким образом, наша структура данных поддерживает _занесение_ (вставка элемента в список) и _извлечение_ (чтение элемента с его последующим удалением), и все с одного края стопки. 

Такая структура данных называется __стеком__. 
__Стек__ - это простая структура данных. 

#### Стек вызовов

Компьютеры используют стек вызовов. 

Чтобы познакомиться с принципом его работы напишем функцию приветствия:

```js
// функция приветствия и стек
function greet(name) {
  console.log(`hello, ${name}!`);
  greet2(name);
  console.log(`getting ready to say bye...`);
  bye();
}
```
Эта функция выводит приветствие 'hello, ... !', а потом вызывает еще 2 функции прямо из себя. Вот эти функции:

```js
function greet2(name) {
  console.log(`how are you, ${name}?`)
}

function bye() {
  console.log(`ok bye!`)
}
```

Разберемся, что происходит при вызове функции

Примечание: для простоты опустм механику вывода сообщений в консоль

Допустим, мы вызвали функцию greet("maggie")
Сначала компьютер выделяет блок памяти для этого вызова.
Затем выделенная память заполняется данными, которые потребуются функции чтобы корректно выполнить код своего тела. В нашем случае функция ожидает аргумент __name__, который нужен ей для вывода сообщений в консоль. В выделенной для функции области памяти создается переменная __name__, которой присваивается значение переданного при вызове аргумента, а именно "maggie":

- Память для вызова __greet__: name = _"maggie"_;

Каждый раз, когда мы вызываем функцию, компьютер сохраняет в памяти значения всех переменных, используемых при данном вызове. Все все аргументы, с которыми была вызвана функция, становятся переменными в контексте выполнения этой функции и сохраняются в отдельной, выделенной для функции области памяти. 

Далее следует показ сообщения в консоли: hello, maggie!

После чего следует вызов другой функции приветствия, greet2("maggie")

Произошел вызов новой функции - значит компьютер обязан выделить блок памяти для этого вызова. 
Причем, так как первая функция еще не завершена, ее персональный блок памяти никуда не исчезает:

- Память для вызова __greet__: name = _"maggie"_;
- Память для вызова __greet2__: name = _"maggie"_;

И так как вторая функция приветствия подразумевает, что ей передадут параметр name, то в ее персональном блоке памяти тоже создается переменная, которая хранит значение переданного при вызове аргумента. В данном случае он такой же, как и для первой функции, но это не имеет значения. 
Теперь у нас два блока памяти для вызовов функций. Компьютер объединяет их в __стек__. Причем блок той функции, что была вызвана последней, попадает на самый верх. 
У нас вызвалась функция greet2, а значит поток выполнения перешел в ее тело. Функция воспользуется переданной ей переменной name и выведет в консоль сообщение:
_how are you, maggie?_
После чего функция greet2 завершает свое выполнение и возвращает поток выполнения в первую функцию. 

Когда поток выполнения возвращается в первую функцию, то в стеке, с его вершины убирается блок памяти, выделенный под функцию greet2, и самым верхним блоком стека вновь становится относящийся к greet. Сама функция продолжает выполняться с того места, где она была прервана. А значит ей пора вывести в консоль сообщение
_getting ready to say bye..._
А после поток выполнения наткнется на вызов функции bye. Тогда выполнение функции greet будет опять приостановлено, для выполнения функции bye будет выделено место в памяти. Этот блок памяти, выделенный для bye, попадет на вершину стека. Начнется выполнение функции bye, мы увидим сообщение
_ok bye!_
Блок данных для функции bye будет удален с вершины стека, управление вновь вернется в greet, а так как в теле greet больше нет команд то выполнение и этой функции завершится и ее контекст выполнения будет удален из стека. 

##### Стек вызовов с рекурсией

Рекурсивные функции исполизуют стек вызовов. 

Рассмотрим функцию вычисления факториала
```js
function fact(x) {
  if (x === 1) {
    return x
  }
  return x * fact(x - 1)
}
```

Допусим, мы хотим посчитать факториал числа 3. Посмотрим, что будет происходить, если за дело вазьмется наша рекурсивная функция. 

Мы вызываем функцию и передаем ей аргумент 3. 
* В _стеке вызовов_ создается контекст выполнения функции fact(3).
* Условная проверка не проходит, так как 3!==0
* Выполнение идет в _return x * fact(x - 1)_
А это значит, что директива return запускает функцию fact с аргументом x-1, тоесть 2.

* В _стеке вызовов_ создается контекст выполнения функции fact(2)
* Условная проверка вновь не проходит
* Выполнение опять идет в директиву return
А это значит, что директива вновь рекурсивно вызывает fact(x-1), что в данном случае будет fact(1)

* В _стеке вызовов_ создается контекст выполнения функции fact(1)
* Условная проверка проходит! 1===1 - true, а значит функция возвращает текущий x, тоесть 1.

Теперь посмотрим, что произошло с нашим стеком вызовов к текущему моменту:

fact(1)
fact(2)
fact(3)

На вершине стека у нас контекст выполнения функции fact(1). Под ним - контекст выполнения fact(2) - функция ожидает завершения. В самом низу - контекст выполнения fact(3) - функция ожидает завершения. 

Таким образом, у нас стек содержит 3 контекста, так как 3 функции еще не завершили свою работу.

Теперь функция fact(1) возвращает 1. Эта единица попадает в функцию fact(2), где выполнение зависло на строке return 2 * 1. Вычисляется результат умножения, 2, этот функция завершается, контекст ее удаляется из стека вызовов, результат отправляется в исходную функцию (которая и запустила цепочку рекурсивных вызовов) fact(3). Там выполнение кода зависло на строке return 3 * 2, вычисляется результат 6 - функция его возвращает, ее работа завершена, ее контекст выполнения удаляется из стека вызовов. 

Каждый рекурсивный вызов функции fact создает свою копию x, которая хранится в собственном контексте выполнения, индивидуальном для каждого вызова, а значит переменная x индивидуальна для каждой рекурсивно вызванной функции. 

Если мы вернемся к примеру с кучей коробок, то заметим, что в случае рекурсивного решения этой задачи мы не создавали особую струкру _куча коробок_, куда при итеративном решении складывали все неоткрытые коробки. В рекурсивном решении это не нужно - сама структура _стека вызовов_ выполняет эту роль кучи. Проверка открытой коробки не завершается, но откладывается в _стек вызовов_ до тех пор, пока в ней находятся другие коробки. 
А когда коробки кончатся - закрытие уже открытых коробок лавинообразно пойдет в обратном их открытию порядке. 
Это несомненно элегантный способ решения задач. Единственное, чем он ограничен - это размером _стека вызовов_. Для каждого языка, для каждой среды исполнения он разный. А значит ограничена и глубина рекурсии. 

И если мы понимаем, что решение конкретной задачи может привести к переполнению стека, у нас всегда остается вариант воспользоваться итеративным подходом: переписать рекурсию в виде цикла. Или попробовать создать комбинированный вариант. Или понадеяться на хвостовую рекурсию - но в случае с JavaScript хвостовые рекурсии хоть и заявлены как поддерживаемые, на практике работают плохо.

### 4. Быстрая сортировка

#### Разделяй и властвуй

Говоря о стратегии "Разделяй и властвуй" разберем несколько примеров. 

Представим, что мы - фермер. У нас есть участок, его длинна 1680м, а ширина 640м. Мы должны разделить эту землю на квадратные участки, но с условием: мы должны определить максимальный размер такого квадратного участка. Тоесть, стратегия разделить поле на кучу мелких участков не пройдет. 

Решение данной задачи методом "Разделяй и властвуй" состоит из 2 шагов:
1. Сначала определим _базовый_ случай. Это должен быть простейший случай из всех возможных. 
2. Задача будет разбиваться и сокращаться до тех пор, пока не сведется к базовому случаю. 

Для начала определимся с базовым случаем для нашей задачи. Для этого взглянем на наш участок и констатируем, что у него одна сторона больше другой. Следовательно, когда мы хотим разделить участок подобной конфигурации, мы можем принять _меньшую_ сторону за сторону квадрата и посмотреть, сколько таких квадратов содержит наш прямоугольный участок. 
А __базовым__ случаем будет такой, при котором одна сторона кратна другой, тоесть когда прямоугольник можно разбить на ряд квадратов без остатка. 

Теперь нужно вычислить __рекурсивный__ случай. 
Тут нам поможет стратегия _разделяй и властвуй_. Попробуем разбить имеющийся у нас участок на раяд квадратов: посмотрим, не сведется ли наша задача сразу к базовому случаю. При длинне участка в 1680м при разбиении его на квадраты со стороной 640м получим 2 квадрата и нераспределенную площадь размером 640м на 400м.
Итак, задача не свелась к базе, но теперь у нас есть новый участок, к которому мы можем применить тот же подход: попробуем разбить его на квадраты, сторона которых будет равна меньшей стороне прямоугольника. Придерживаясь этого принципа, будем производить деление на квадраты отстатков до тех пор, пока остаток не пропадет - что значит, что мы достигли __базового__ случая - стороны кратны. 
И эта сторона кврадрата будет нашим ответом. 

__Алгоритм Евклида__
_Если мы найдем самый большой участок, подходящий для такого размера, это будет значить, что мы нашли самый большой участок, подходящий и для всей фермы_

В итоге, выполнияя шаги вышеозначенного алгоритма мы придем к прямоугольному участку размером 160*80
Это наша __база рекурсии__
И этот прямоугольник с кратными сторонами! Его можно разделить на 2 квадрата по 80м без остатка. А это значит, что для всейго большого участка самый большой размер кврдрата составляет 80м.

Еще раз про стратегию __"Разделяй и Властвуй"__ применительно к данной задаче:
1. Определим простейший, базовый случай. 
2. Придумаем, как свести задачу к этому базовому случаю.

__"Разделяй и Властвуй"__ - не простой алгоритм, с помощью которого можно решить задачу. Скорее это подход к решению задачи. 
```js
function surveyor(data) {
  let length = data.length;
  let width = data.width;
  let remainder = length % width;
  console.log(`
  length: ${length}, 
  width: ${width}, 
  remainder: ${remainder}`)
  if (remainder === 0) {
    length = width;
    return { length, width }
  } else if (length <= 0 || width <= 0) {
    return "нет рационального решения"
  }
  length = width;
  width = remainder
  return surveyor({ length, width })
}
```

Рассмотрим еще один пример
Имеется массив чисел [2, 4, 6]

Нужно __суммировать__ все числа и вернуть __сумму__
Сделать это в цикле просто
```js
function cycleSum(arr) {
  let sum = 0;
  for (let int of arr) {
    sum += int
  }
  return sum
}
```
Но наша задача сделать то же самое с помощью рекурсии

Если мы попробуем воспользоваться стратегией __разделяй и властвуй__, то нам, во-первых, необходимо будет определить _базовый случай_, базу рекурсии. 
Какой самый простой, самый базовый случай, когда мы говорим о массиве с числами? Либо пустой массив, либо массив с одним элементом. Когда мы говорим про массив чисел, то базовым случаем для него вполне может стать пустой массив: элементов нет, их сумма равна 0. Можно рассмотреть как базовый случай, когда в массиве всего один элемент, но как тогда быть, если попросят найти сумму элементов пустого массива?

Далее мы должны определить, как __рекурсивный вызов__ будет приближать нас к __базовому случаю__ - тоесть к пустому массиву. 

Чтобы размер задачи постепенно уменьшался, введем логику:
Пусть если размер массива больше нуля, то возьмем элемент массива и прибавим к нему сумму остальных элементов массива:

$sum( [2, 4, 6] ) = 2 + sum( [4, 6] )$

Логично? Вроде да. Продолжим эту логику, чтобы посмотреть, к чему она нас приведет

sum( [2, 4, 6] ) = 
2 + sum( [4, 6] ) = 
2 + (4 + sum( [6] )) =
2 + (4 + (6 + sum( [] )))

И вот мы добрались до нашего __базового случая__, до _базы рекурсии_ - пустой массив, сумма элементов которого вернет 0.

Примененную схему можно попытаться описать так: 

__Логика суммы элементов полученного массива__:
1. Если полученный массив пуст - вернуть 0
2. Если он не пуст - вернуть Элемент А массива плюс __Логика суммы элементов полученного массива__ без Элемента А.

Если бы мы захотели создать _рекурсивную_ функцию __sum__ на основе этой логики, и проследили, что происходит со стеком вызовов, то увидели бы, что:
1. Вызывается функция sum( [2, 4, 6] ). В стеке вызово создается ее контекст выполнения и помещается на верх. Так как переданный массив __не пуст__ - функция должна вернуть 6 + sum( [2, 4] ). Так как у нас вызов функции из тела функции, то процесс выполнения текущей функции приостанавливается и ...
2. Вызывается функция sum( [2, 4] ). В стеке вызово создается ее контекст выполнения и помещается на верх. Так как переданный массив __не пуст__ - функция должна вернуть 4 + sum( [2] ). Так как у нас вызов функции из тела функции, то процесс выполнения текущей функции приостанавливается и ...
3. Вызывается функция sum( [2] ). В стеке вызово создается ее контекст выполнения и помещается на верх. Так как переданный массив __не пуст__ - функция должна вернуть 2 + sum( [] ). Так как у нас вызов функции из тела функции, то процесс выполнения текущей функции приостанавливается и ...
4. Вызывается функция sum( [] ). В стеке вызово создается ее контекст выполнения и помещается на верх. Так как переданный массив __пуст__ - функция должна вернуть 0. Мы достигли __базы рекурсии__. Функция возвращает 0 и контекст ее выполнения удаляется из стека вызовов. На вершине стека оказывается контекст выполнения предыдущей функции ...
5. sum( [2] ). Она возвращает 2 + 0 = 2. Контекст ее выполнения удаляется с вершины стека вызовов, на вершине оказывается контекст выполнения предыдущей функции ...
6. sum( [2, 4] ) 
... и так далее. Функции возвращают результаты суммы, завершаются, их контексты выполнения удаляются из стека вызовов, пока в итоге мы не доходим до материнской функции, запустившей процесс: sum( [2, 4, 6] ), которая возвращает 6 + 6 = 12. Все контексы выполнения удалены из стека вызовов, работа функций завершена, результат получен. 

__СОВЕТ__
Когда мы пишем рекурсивную функцию, в которой задействован массив, базовым случаем часто оказывается пустой массив или массив из одного элемента. Если неизвестно, с чего начать - всегда можно попробовать этот вариант. 

Попробуем реализовать описанную рекурсивную функцию на JS

```js
function sum(arr) {
  // базовый случай - пустой массив
  if (arr.length === 0) {
    return 0
  }
  // шаг рекурсии
  return arr.pop() + sum(arr)
}
```
Функция работает с концом массива, так как это более экономичный подход с точки зрения ресурсов компьютера

Интересная задача ставится автором книги:
Нас просят написать рекурсивную функцию, которая будет искать наибольший элемент из переданного списка. 

Чтобы найти логику решения этой задачи, на необходимо воспользоваться принципом __"Разделяй и властвуй"__.
1. Надо найти _Базовый случай_ - _базу рекурсии_
2. Надо определиться с рекурсивным случаем - логикой, которая будет видоизменять переданные исходные данные, пошагово приближая нас к _Базовому случаю_.

```js
function findMax(arr) {
  // базовый случай
  if (arr.length === 1) {
    return arr[0]
  }
  let last = arr.pop()
  let subMax = findMax(arr)
  return last > subMax ? last : subMax
}
```
На каждой итерации переменная last сохраняет в себе последний элемент и помогает сократить список на один элемент с конца. Что приближает нас к базовому случаю - когда в списке останется только один элемент. 

Но для сравнения нам нужно 2 элемента. Поэтому введем вторую переменную subMax и будем ожидать, что в нее будет записан результат рекурсивного вызова нашей функции. Пока в списке остается больше одного элемента, переменная subMax будет ожидать результата рекурсивного вызова. Когда в списке останется один элемент, функция вернет его - так как сработает условие:

```js
if (arr.length === 1) {
    return arr[0]
  }
```

Вернется самый первый элемент списка. Этот элемент будет записан в контексте вызова предыдущей функции в переменную subMax, и код тела станет выполняться дальше, а там нас ждем директива return, которая должна произвести сравнение элемента из переменной last и того элемента, что вернулся из предыдущей функции. Большее значение вернется в предыдущий рекурсивный вызов и опять попадет в сравнение, из которого наверх попадет большее, и так далее...
... Пока самая первая функция не проведет сравнение первого элемента с самым большим элементом из предыдущих элементов списка. И не вернет большее значение всего списка. 

В последней задаче автор интересуется у нас, каков будет базовый случай для бинарного поиска, доведись нам реализовать его с помощью рекурсии. 

#### Быстрая сортировка

Быстрая сортировка - это алгоритм сортировки. Она работает быстрее сортировки выбором и часто применяется в реальных проектах. 
Она основана на стратегии _Разделяй и Властвуй_

Итак, попробуем воспользоваться быстрой сортировкой для упорядочивания массива. 

__Базовый случай__ - представим себе такой простейший массив, в котором сортировать элементы вообще не нужно. Очевидно, что это либо пустой массив, либо массив из 1 элемента. 
Такие массивы можно просто возвращать в исходном виде - это и будет наш _базовый случай_

```js
function quicksort(arr) {
  if (arr.length < 2) {
    return arr
  }
}
```

__Рекурсивный случай__ - теперь пора поговорить о массивах подлиннее. Массив из 2 элементов сортируется без особых проблем: сравниваем 2 элемента. Если первый _больше_ второго, то просто меняем их местами. 
Но такая логика в отншении массива из 3 элементов работает уже не так хорошо. 
Алгоритм __Быстрой сортировки__ работает так: сначала из всего массива выбираем один элемент. Он называется __опорный элемент__. 
При выборе __опорного элемента__ стоит придерживаться _особой_ логики, чтобы выбрать _хороший опорный элемент_, но пока просто выберем первый. 
Теперь наша задача найти элементы, которые _меньше_ опорного и те, которые _больше_ опорного. Этот процесс называется __Разделением__
В итоге мы должны получить: 
* массив элементов, которые меншьше опорного
* сам опорный элемент
* массив элементов, которые больше опорного
Заметим, что получившиеся 2 подмассива _не отсортированы_. Они просто выделены из исходного массива. 

Но вот если бы они были отсортированы, то тогда нам бы только оставалось объединить их в порядке: левый подмассив, опорный элемент, правый подмассив. И мы бы получили полностью отсортированный массив. 
Но как этого добиться? Как сделать неотсортированные подмассивы отстртированными? 
На самом деле можно применить к неотсортированным массивам рекурсивный вызов быстрой сортировки. И всякий раз, когда подмассив получается достаточно большим, рекурсивно вызывать быструю сортировку для такого подмассива, пока функция быстрой сортировки в каждом отдельном случае не натолкнется на базовый случай, с которым она знает как работать. Тогда стек вызовов функций начнет рекурсивно схлопываться, функции будут возвращать базовые случаи, которые будут расставляться в правильном порядке, чтобы в конце получить полностью отсортированный массив. 

Для примера возьмем массив [33, 15, 10]

В качестве опорного элемента возьмем первый: 33. 
Теперь функции быстрой сортировки надо распределить оставшиеся элементы в 2 подмассива: меньше 33 и больше 33. В левый массив(который меньше 33) попадут [15, 10]. В правый массив ничего не попадет, так как у нас нет чисел больше 33, поэтому он останется пустым. 
Получаем: 
[15, 10] 33 []

Так как у нас есть _неотсортированный_ подмассив из 2 элементов, мы просто рекурсивно вызовем для него нашу функцию сортировки. Она проделает все то же самое для этого массива, тоесть вычленит из него _опорный_ элемент и относительно него расположит второй элемент. А значит придет к базовому случаю. 
Затем рекурсивные вызовы __схлопнутся__, выбрасывая элементы в отсортированном виде.
В конечном итоге мы получим отсортированный массив: 
[10, 15, 33]

Здесь автор подводит нас к интересной мысли. Исходя из примеров выше мы можем утверждать, что наша функция __быстрой сортировки__ гарантированно справляется с массивами из 0, 1, (это вообще базовые случаи), 2 и 3 элементов. Но справится ли она с массивом из 4 элементов? Если мы передадим нашей функции такой массив, то, после того, как она возьмент _опорный элемент_, в каждом из подмассивов окажется от 0 до 3 элементов. А с таким размером массива наша функция точно справляется, просто надо рекурсивно вызвать ее для этого подмассива. А значит функция работает с массивом из 4 элементов. По той же логике теперь мы можем доказать, что функция справится с массивом из 5 элементов. И так далее. 

__ДОКАЗАТЕЛЬСТВО ПО ИНДУКЦИИ__
Мы познакомились с __доказательством по индукции__. Это один из способов доказать, что алгоритм работает. Каждое индуктивное доказательство состоит из __базы__ и __индуктивного перехода__. Допустим надо доказать, что возможно подняться по лестнице. Если удалось описать набор дейтсвий, которые гарантированно позволят подняться с первой ступеньки на вторую, то можно утверждать, что у нас есть способ на каждом этапе подняться на еще одну ступеньку. Со ступеньки 2 на ступеньку 3. Вне зависимости от того, на какой ступеньке мы стоим. Базовый случай - переход от ступеньки 1 на ступеньку 2. 
Аналогично, мы можем говорить об алгоритме быстрой сортировки. Работоспособность алгоритма для базового случая - работа с массивами длинной 0 и 1 элемент была продемонстрирована. В __индуктивном переходе__ мы доказывали, что если алгоритм работает для массива из 1 элемента, то он сработает для массива из 2 элементов. Мы __перешли__ от базового случая к более комплексному. Так же нам удалось доказать, что для массива из 3 элементов наш алгоритм будет работать именно потому, что он работает для массива из 2. Это важная особенность: мы доказали, что сама природа нашего алгоритма сведет рекурсивное решение к случаям, одним из которых может стать подмассив из 2 элементов - а мы __уже доказали__, что наш алгоритм справляется с таким случаем, а значит в доказательстве работоспособности для массива из 3 элементов можно сослаться на доказательство для 2 элементов, которое в свою очередь ссылается на доказательство работоспособности для базовых случаев. 
И когда перед нами станет задача доказать работоспособность алгоритма для массива из 4 элементов, мы будем ссылаться в доказательстве на работоспособность алгоритма для 3 элементов. 
А смекалка позволит нам сделать предсказание, что чтобы доказать работоспособность алгоритма для массива из 100 элементов нам не нужно идти в своем доказательстве последовательно от базового случая до 99.

Осталось только реализовать нашу логику в виде простейшего кода. 

Мы говорили о базовом случае
```js 
function quickSort(arr) {
  if (arr.length < 2) {
    return arr
  }
}
```
Он возвращает исходный массив, если в нем от 0 или 1 элемент. 

Теперь реализуем оставшуюся логику.
Нам необходимо выбрать _опорный_ элемент. Отсортировать остальные элементы массива относительно опорного элемента. Вернуть массив, в котором элементы отсортированы относительно опорного элемента. 

```js
// выделяем ОПОРНЫЙ ЭЛЕМЕНТ
// пусть это будет первый элемент массива
let pivot = arr[0]
```

Теперь пришла пора сортировать остальные элементы массива в подмассивы больше\меньше _опорного_ элемента. 

Для этого нам нужно сравнить каждый элемент с _опорным_: 
elem > pivot или elem < pivot. 
В сортировке нам поможет метод массивов .filter(func)
На основе переданной ему функции сортировки он выберет только подходящие элементы из массива. И очень удобно, что метод возвращает массив.
Но помним: так как первый элемент мы взяли в качестве _опорного_, то производить фильтацию надо по всем элементам кроме первого. А значит воспользуемся методом .slice()

```js
// получим массив элементов, которые МЕНЬШЕ опорного
let less = arr.slice(1).filter(i => i < pivot);
// получим массив элементов, которые БОЛЬШЕ опорного 
let greater = arr.slice(1).filter(i => i > pivot);
```

А в конце передадим подмассивы less и greater нашей функции быстрой сортировки, чтобы она разобралась с правильным порядком их элементов. 
И вернем результат, обязательно в правильном порядке: меньшие элементы, опорный элемент, большие элементы.
Так как наша функция возвращает массив, но вызывается рекурсивно, позаботимся о том, чтобы на выходе получить не вложенные массивы, а один массив из отсортированных элементов. Для этого воспользуемся оператором ... который раскороет на каждом шаге результат рекурсивног подвызова.

```js
return [...quickSort(less), pivot, ...quickSort(greater)];
```
В итоге получаем:
```js
function quickSort(arr) {
  if (arr.length < 2) {
    return arr
  }
  // выделяем ОПОРНЫЙ ЭЛЕМЕНТ
  let pivot = arr[0];
  // получим массив элементов, которые МЕНЬШЕ опорного
  let less = arr.slice(1).filter(i => i < pivot);
  // получим массив элементов, которые БОЛЬШЕ опорного 
  let greater = arr.slice(1).filter(i => i > pivot);

  return [...quickSort(less), pivot, ...quickSort(greater)];
}
```

##### Снова об "О - большом"

Алгоритм __быстрой сортировки__ уникален тем, что его скорость зависит от выбора _опорного_ элемента. 

Но прежде, чем разъяснить истинность и нюансы этого утверждения нам стоит вновь обратиться к "О-большому" для некоторых алгоритмов

- $O(\log n)$ - или _Логарифмическое время_ - Бинраный поиск
- $O(n)$ - или _Линейное время_ - Простой поиск
- $O(n \times \log n)$ - эффективные алгоритмы сортировки, например - _Сортировка слиянием_
- $O(n^2)$ - медленные алгоритмы сортировки - _Сортировка выбором_
- $O(n!)$ - очень медленные алгоритмы - Задача о коммивояжере

Возьмем к примеру скорость работы алгорима _Сортировка выбором_: $O(n^2)$. - Это когда нам надо пройтись по массиву число раз, равное количеству элементов в самом массиве. Это довольно медленный алгоритм. 

А вот алгоритм Сортировка слиянием работает со скоростью $O(n \times \log n)$. Гораздо быстрее!

С _Быстрой сортировкой_ все обстоит сложнее. В __худшем__ случае она работает за время $O(n^2)$ - ничем не лучше _Сортировки выбором_. 
Но это худший случай. А в среднем быстрая сортировка выполняется за время $O(n \times \log n)$.

Исходя из представленной информации напрашиваются 2 вопроса:
* что значит __лучший__ случай и __худший__ случай?
* если _Быстрая сортировка_ показывает время $O(n \times \log n)$ только в каком-то __лучшем__ случае, а _Сортировка слиянием_ __гарантированно__ работает с таким временем, не лучше ли _всегда_ использовать _Сортировку слиянием_?

###### Сортировка слиянием и Быстрая сортировка

Представим себе функцию, которая получает список и последовательно выводит в консоль каждый элемент этого списка

```js
function showItems(arr) {
  for (let item of arr) {
    console.log(item);
  }
}
```
Так как такая функция перебирает весь список длинною n, то она выполняется за время $O(n)$.
Предположим, что мы изменим функцию так, чтобы она делала секундную паузу перед каждым выводом элемента. 
И если нам нужно будет решить, какую функцию использовать для быстрого вывода в консоль группы элементов, логично будет не модифицировать функцию добавлением в нее секундной задержки.

Но обратим внимание, что даже с учетом секундной задержки время выполнения нашей функции оценивается как $O(n)$, хотя очевидно, что она выполняется дольше. 
Однако более корректно было бы учесть секундную задержку при учете времени выполнения. Чтобы отразть в "О-большом" ту реальную разницу между функцией и ее модифицированным вариантом:

$$O(c \times n)$$
Где c - это наш коэфициент секундной задержки. Он называется _константой_.


Так, если мы предположим, что для вывода одного элемента в консоль компьютеру потербуется 10мс (это условная величина которая не отражает реальной скорости работы компьютера), а для вывода с задержкой 1с, то у нас появляются 2 константы:
* $c_1 = 0.01$ секунды - для аппаратной задержки в 10мс
* $c_2 = 1$ секунда - для пользовательской задержки в 1с

__Обычно константа игнорируется__

Если два алгоритма имеют разное "О-большое", то считается, что константа не имеет значения. 
Чтобы продемонстрировать это на примере, возьмем 2 алгоритма: _Простой поиск_ и _Бинарный поиск_.
И для _Бинарного поиска_ добавим пользовательскую константу $c_2$ в целую секунду: $O(c_1 \times n) = O(10ms \times n)$. А для _Простого поиска_ возьмем нашу наименьшую константу $c_1$: $O(c_2 \times \log n) = O(1s \times \log n)$.

На первый взгляд _Простой поиск_ приобрел некоторую заманчивость в плане времени выполнения благодаря нашей наименьшей константе. 

Теперь предположим, что поиск ведется по списку из 4 000 000 000 элементов (4 миллиарда).

Получаем следующие значения:
* Для _Простого поиска_: $10мс \times$ 4 миллиарда = 463 дня
* Для _Бинарного поиска_: $1с \times \log(4 000 000 000) = 1с \times 32$ = 32 секунды

Как видим, бинарный поиск работает намного быстрее, не смотря на константы, как и предсказывало "О-большое"

Однако, в некоторых случаях, константа __может иметь значение__.
Примеры подобного рода - _Быстрая сортировка_ и _Сортировка слиянием_.

Обе сортировки характеризуются временем выполнения $O(n \times \log n)$.
Но у _Быстрой сортировки_ __константа__ меньше. _Быстрая сортировка_ работает __быстрее__. 

А на практике _Быстрая сортировка_ работает быстрее, потому что __средний__ случай встречается намного чаще __худшего__. 

Как выглядит __средний__ случай и чем он отличается от __худшего__?

###### Средний и худший случай

Быстродействие _Быстрой сортировки_ напрямую зависит от выбранного _опорного_ элемента. 
Предположим, что _опорным_ всегда выбирается первый элемент, а на сортировку приходит уже отсортированный массив. Быстрая сортировка не проверяет, отсортирован входной массив или нет и пытается его сортировать. 

В данном случае мы столкнемся с тем, что на каждом шаге рекурсии в одном подмассиве у нас окажется весь переданный массив за исключением _опорного_ элемента. 

[1,2,3,4,5,6,7,8]

[] 1 [2,3,4,5,6,7,8]

[] 2 [3,4,5,6,7,8]

[] 3 [4,5,6,7,8]

[] 4 [5,6,7,8]

[] 5 [6,7,8]

[] 6 [7,8]

[] 7 [8]

Размер стека вызовов в данном случае составит 8

Но предположим, что в качестве _опорного_ мы выбираем элемент из __середины__. Тогда:

[1,2,3,4,5,6,7,8]

[1,2,3] 4 [5,6,7,8]

[1] 2 [3] ::: [5] 6 [7,8]

 [] 7 [8]

Стек данного рекурсивного вызова очевидно короче, его высота составляет 4.

Массив всякий раз делится надвое, поэтому количество рекурсивных вызовов, равное количеству элементов, излишне. 

В первом случае __ВЫСОТА СТЕКА ВЫЗОВОВ__ может быть описана как $O(n)$ - это худший вариант развития событий, _худший_ сценарий, по сути повторяющий собой решение _последовательным перебором_. А во втором случае __ВЫСОТА СТЕКА ВЫЗОВОВ__ может быть описана как $O(\log n)$ - это лучший вариант развития событий, _лучший_ сценарий.

Тут необходимо сделать отступление:
Если мы посчитаем вручную, то увидим, что во втором случае нам пришлось сделать 5 вызовов всего. При этом левая ветка от вершины к остнованию 3 вызова, правая ветка от вершины к основанию 4 вызова. Но первые 2 шага на схеме для обоих веток будут общими, поэтому фактически после 2 шагов будет выполнен 1 шаг в левой ветке и 2 шага в правой ветке:
$$
2 + 1 + 2 = 5
$$

Тут есть принципиальный момент. Да, сумма вызовов по всем веткам не равна сумме вызовов в самой длинной ветке. 

Однако обратим внимание вот на что:

При линейном переборе массива у нас одна длинная цепочка действий. Каждый шаг проводит работу с подмножеством, практически идентичным подмножеству предыдущего шага. Суммарное время $n + (n-1) + (n-2) + ... + 1 = \frac{n(n-1)}{2} = O(n^2)$ - это как раз ситуация нашего __худшего__ случая, когда 8 элементов массива дали линейную цепочку стека вызовов длинною 8 вызовов. Каждый из этих вызовов __полностью__ просматривает весь переданный ему массив.

Разделяй и властвуй дает нам сбалансированное разбитие. 
* На верхнем уровне дерева стека рекурсивных вызовов мы работаем с $n$ элементов, разделяя их на части. 
* На следующем уровне у нас 2 подзадачи размером $\frac{n}{2}$ и каждая обрабатывает свои $\frac{n}{2}$ элементов --> но если мы сложим все эти обработки то получим те же самые $n$ элементов: $\frac{1}{2} n + \frac{1}{2} n = O(n)$
* На следующем уровне 4 подзадачи, каждая размером $\frac{1}{4} n$, общее время обработки всех 4 задач составит $4 \times \frac{1}{4} n = O(n)$
* И так до тех пор, пока размер подзадачи не достигнет уровня базы рекурсии.

Получается, что если мы сложим не все ветки разом, а будем складывать только количество элементов, обрабатываемых на каждом __уровне__ дерева стека рекурсивных вызовов, то на каждом уровне мы как-бы тоже просматриваем весь массив $n$. 

На каждом уровне суммарная работа $O(n)$. 

Но число уровней теперь не $n$, а $\log n$, что дает $O(n\times \log n)$ !!!

_Вот почему мы в праве говорить, что глубина стека рекурсивных вызовов, или размер дерева стека рекурсивных вызовов, определяется __самой длинной веткой__, а не суммой веток._

Сумма веток превратит нашу разветвленную сруктуру в линейную, но для такой структуры количество выполняемых операций будет неоднородным! НЕ равным $O(n)$, а значит подсчитьать О-большое будет не в пример сложнее.

__Ключевая идея:__
* _Для каждой рекурсии -- работа линейна по размеру массива_
* _Для всей рекурсии -- мы суммируем такие линейности для разных размеров массива_

Таким образом, суммируя все вышесказанное:
__Худший случай__

Высота стека вызовов составит $O(n)$, алгоритму каждый раз придется работать с $O(n)$ элементами переданного массива, а значит общее время рабты в худшем случае составит 

$$
O(n)\times O(n) = O(n^2)
$$

__Лучший случай__

Высота стека вызовов составит $O(\log n)$. Да, алгоритму все так же придется работать с $O(n)$ элементами переданного массива, но в итоге мы получим более заманчивую формулу времени работы:

$$
O(n) \times O(\log n) = O(n \times \log n)
$$

А сюрприз в том, что лучший случай зачастую является средним. Если мы всегда будем выбирать в качестве опорного случайный элемент массива, то в подавляющем большинстве случаев время работы алгоритма составит $O(n \times \log n)$. Исключение - если все элементы массива одинаковы время рабты алгоритма будет как у худшего сценария, если мы не введем дополнительную логику. 

Итак, алгоритм _Быстрой сортировки_ -- один из самых __быстрых__ среди всех существующих алгоритмов сортировки. И заодно является хорошим примером стратегии __разделяй и властвуй__. 

Стратегия __разделяй и властвуй__ и __рекурсия__ это понятия, которые необходимо разделять. 

__Рекурсия__

Сама по себе рекурсия не гарантирует никакого ускорения. Мы можем решить задачу о суммировании элементов массива через _рекурсию_, а можем с помощью простого цикла, и рекурсивное решение не будет самым быстрым! Но это будет классическое решение с помощью рекурсии. Рекурсия допускает, что время ее работы будет $O(n)$, это вполне нормально для рекурсии. 

Рекурсия может быть выбрана как синтаксически более понятный для чтения и написания способ решения задачи по сравнению с циклом - и в этом будет ее преимущества, а не в скорости. 

Преимущество рекурсии - понятность кода при работе со вложенными структурами или задачами, которые естественно определяются через самих себя. 


__Разделяй и властвуй__ 

Это про скорость. Когда нам не подходит линейный перебор каждого элемента массива, потому что это слишком __долго__. Когда мы хотим ускориться. Эта стратегия позволяет разбить одну задачу как-бы на несколько (например две) __ветвящихся__ подзадачи. Не последовательный рекурсивный подвызов функции для __каждого__ следующего элемента, а 2 __ветвящиеся__ задачи, которые тем не менее никто не запрещает решать рекурсивно. Но! За счет разветвления этих задач мы и получаем ситуацию, когда высота дерева стека рекурсивных вызовов разительно отличается от таковой высоты при последовательном вызове функций для каждого элемента обрабатываемого списка. 

Именно тут отражен момент, когда мы смогли говорить о том, что для быстрого поиска есть __хороший__ и __плохой__ сценарий. 

В __плохом__ сценарии нам никак не удавалось __разветвить__ задачу, потому что всегда получался пустой массив и массив из всех остальных элементов, что практически сводило всю нашу стратегию к итеративному подходу (наподобие того, что мы использовали при подсчете всех элементов массива рекурсией): сколько элементов - такова и высота стека вызовов. Вот почему мы и оценивали ее как $O(n)$

В хорошем же сценарии, когда мы выбирали удачный опорный элемент, мы наконец смогли добиться __разветвленности__ процессов: два подмассива, две __независимые__ подзадачи. И именно за счет разветвленности мы смогли сократить высоту дерева стека вызовов на величину, которую уже оценили как $O(\log n)$. 

Это была история про ускорение, которого мы смогли добиться за счет сокращения высоты дерева стека рекурсивных вызовов.


### Хеш - таблицы

Допустим, мы продавец в магазине. Каждый раз, когда клиент покупает товар, мы должны узнать его цену. У нас для этого есть специальная книга. Если записи в книге не упорядочены, то теоретически, чтобы найти цену нужного товара, нам нужно просмотреть все записи в книге. И такая задача сравнима с _простым поиском_, а значит займет $O(n)$ времени. 

Если же записи упорядочены, то задача сведется к _бинарному поиску_, а значит поиск товара займет $O(\log n)$.

Но даже при таких раскладах, поиск займет время, зависящее от размеров нашей гипотетической книги. Клиетны могут начать нервничать.

Неплохо было бы иметь помощника, который бы помнил все цены на товары наизусть. Тогда он сразу бы подсказывал нам цену на товар. 

Такой помощник сообщает время сразу, _вне зависимости от размеров книги_, а значит это будет еще быстрее, чем использовать бинарный поиск.

Мы хорошо знакомы с 2 типами данных: __списки__ и __массивы__. 
Допустим, мы выберем массив для хранения данных о наших товарах. Каждый элемент массива должен содержать название товара и его цену. Допустим, мы отсортируем массив по __названиям__ товаров. Тогда мы сможем провести по такому массиву _бинарный поиск_. Но если мы хотим, чтобы поиск занимал время, не зависящее от размера данных, тоеть если мы стремимся к $O(1)$, то нам пригодятся __хеш - функции__. 

#### Хеш - функции

Хеш - функция представляет собой функцию, которая принимает строку и возвращает число. 

Говорят, что _хеш - функции отображают строки на числа_. 

Хеш - функция должна соответствовать некоторым требованиям:
* Она должна быть последовательной. Получая строку "Апельсин" и преобразуя ее в число 4 мы должны быть уверены, что в следующий раз, когда передадим этой функции строку "Апельсин" то снова получим на выходе число 4. 
* Разным словам должны соответствовать разные числа

Итак, хеш - функция преобразует строки в числа. Это поможет нам с задачей хранения данных в массиве. 
Как мы помним, у массивов произвольный доступ к элементам. Это значит, что в не зависимости от длинны массива мы можем получить любой его элемент по индексу. 

Передав хеш - функции название товара, вроде "Апельсин", мы можем получить число, обозначающее товар. Пусть 3. Теперь берем наш массив и в позицию с индексом 3 записываем цену апельсина. 

Помните, чем мы были ограничены раньше? В каждом элементе нам приходилось хранить и название товара, и его цену. А потом упорядочивать все элементы массива по названиям, чтобы получить возможность проводить бинарный поиск. 
Теперь мы лишились этого ограничения. Хеш-функция преобразует название (строку) в число (индекс), а храним мы только цену. И получаем возможность мгновенного доступа к элементу. 

Хеш-функция неизменно связывает название с одним индексом. В первый раз, когда мы передаем ей название товара, она возвращает число, которое мы будем использовать в качестве индекса в массиве. В последующие разы, когда мы передаем хеш-функции то же самое название, она будет возвращать нам индекс, по которому в массиве хранится цена товара. 

Хеш-функция связывает разные строки с разными индексами. Таким образом, каждое оригинальное название товара получает оригинальный индекс. 

Хеш-функция знает размеры массива и возвращает только действительные индексы. Таким образом, если длинна массива 5, хеш-функция не вернет 100, потому что это значение не является действительным индексом в массиве. 

Когда мы свяжем воедино _хеш-функцию_ и _массив_, мы получим структуру данных, называемую __хеш-таблицей__.

Массивы и списки напрямую отображаются на адреса памяти, но хеш-таблицы устроены хитрее. Они определяют место хранения элементов при помощи хеш-функций. 

Они также известны под другими названиями: "Ассоциативные массивы", "Словари", "Отображения", "Хеш-карты" или просто хеши. 

Хеш-таблицы исключительно быстро работают, и все благодаря тому что в основе их работы лежит скорость получения данных из массива. 

Важно оговориться, что мы обсуждаем __идеальную__ хеш - функцию. Она вносит _каждый_ новый элемент в _отдельную_, _собственную_ ячейку. На практике __идеальных__ функций не существует. Часто выходить так, что для нескольких __разных__ строк логика хеш - функции выдает __одинаковые__ числовые результаты, что приводит к тому, что на __одну__ ячейку массива претендуют несколько __разных__ элементов. Это вопрос __коллизий__, а такое _взаимно-однозначное_ связывание называется _инъективной функцией_. Красивый термин, подойдет чтобы флексить им перед пацанами за гаражами.

Самостоятельная реализация _хеш - таблиц_ задача довольно редкая, по той причине что практически каждый язык программирования предоставляет их готовую реализацию "_из коробки_". 

#### Использование хеш-таблиц для поиска

Представим телефонную книгу в телефоне. Имена людей в ней связаны с их номерами телефонов. Такая книга должна поддерживать следующие функции:
* Добавление имени человека и номера, связанного с этим именем
* Получение номера телефона, связанного с введенным именем

Эта задача идеальна для хеш-таблиц. Они отлично работают, когда мы хотим:
* Создать связь, __отображающую__ один объект на другой. 
* Найти значение в списке.

(Тут автор прибменил терминологию, скорее характерную для математики. Поясним. Если мы возьмем абстрактнуб функцию $f(x)=y$, то тем самым мы как бы скажем: _множество значений $x$ __отображается__ на множество значений $y$ согласно некому правилу_, которое и описывает функция. Так, $f(x) = 2x$ говорит о том, что _любому значению из множества $x$ соответствует такое значение из множества $y$, которе больше $x$ в 2 раза_.

Применительно к словам автора мы можем сказать: В нашем примере любому добавленному в телефонную книгу имени соответствует лишь один номер телефона, а правило, по которому конкретное имя связано с конкретным номером описывается логикой, заложенной в хеш-функцию. Тоесть множество имен телефонной книги __отображается__ на множество номеров телефонной книги согласно правилу, которое связывает __конкретное имя__ с __конкретным номером__.)

Преимущество хеш-таблиц для задач подобного рода становится очевидным, если мы попытаемся решить ту же задачу с использованием массивов. Ведь хеш-таблицы упрощают моделирование __отношений между объектами__. 

Хеш-таблицы используются для поиска соответствий в гораздо большем масштабе. 

Так, для любого посещаемого веб-сайта его имя преобразуется в IP - адрес. 
Связать символьное имя с IP - адресом это задачка для хеш-таблиц. Этот процесс называется __преобразованием DNS__. 
















###### ИТОГИ:

Хеш - функция работает с массивам. Она знает его размер. Получая строки, она преобразует их в индексы для этого массива, записывает значения в массив по этим индексам. 

Похожим образом в JS реализованы Объекты. Когда мы передаем в них новое свойство в формате __ключ - значение__, запускается хеш функция.  Она берет строковые ключи и преобразует их в индексы массива. По этим индексам в массив записываются __значения__. Это позволяет обращаться к свойствам объектов со скоростью $O(1)$, что сопоставимо со скоростью доступа к элементам массива. Произвольный доступ во всей красе. 

Но мы знаем, что у нас всегда есть возможность получить все ключи свойств объекта. Что же получается, хеш - функция берет индексы и преобразует их обратно в строки? Вовсе нет, хеш - функция однонаправлена, она так не умеет. Но решение простое: каждый элемент массива хранит не только __значение__ свойства, но и его __ключ__, в строковом формате. Это позволяет при необходимости пройтись по всем подряд свойствам объекта, собрать из них названия ключей и вывесть их. Да, так как это итеративный подход то скорость такой операции скорее сторит оценивать как $O(n)$, но операция не частая и это приемлемо. 




